<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Logging in Azure API Management | Azure Blog</title>

    <!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Logging in Azure API Management | Azure Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Logging in Azure API Management" />
<meta name="author" content="svenmalvik" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post is a complete step-by-step guide on how to send logs from Azure API Management to Azure Event Hub with PowerShell. We start by creating an instance of APIM, Event Hubs Namespace together with an Event Hub, and finish by watching incoming events with help of a VS Code Plugin." />
<meta property="og:description" content="This post is a complete step-by-step guide on how to send logs from Azure API Management to Azure Event Hub with PowerShell. We start by creating an instance of APIM, Event Hubs Namespace together with an Event Hub, and finish by watching incoming events with help of a VS Code Plugin." />
<meta property="og:site_name" content="Azure Blog" />
<meta property="og:image" content="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-video-1.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-11T00:00:00+02:00" />
<script type="application/ld+json">
{"datePublished":"2020-04-11T00:00:00+02:00","author":{"@type":"Person","name":"svenmalvik"},"mainEntityOfPage":{"@type":"WebPage","@id":"/https://www.svenmalvik.com/azure-apim-with-eventhub/"},"url":"/https://www.svenmalvik.com/azure-apim-with-eventhub/","image":"https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-video-1.jpg","description":"This post is a complete step-by-step guide on how to send logs from Azure API Management to Azure Event Hub with PowerShell. We start by creating an instance of APIM, Event Hubs Namespace together with an Event Hub, and finish by watching incoming events with help of a VS Code Plugin.","headline":"Logging in Azure API Management","dateModified":"2020-04-11T00:00:00+02:00","@type":"BlogPosting","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="shortcut icon" type="image/x-icon" href="https://www.svenmalvik.com/">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

    <!-- Google Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">

    <!-- Bootstrap Modified -->
    <link rel="stylesheet" href="https://www.svenmalvik.com/assets/css/main.css">

    <!-- Theme Stylesheet -->
    <link rel="stylesheet" href="https://www.svenmalvik.com/assets/css/theme.css">

    <!-- Jquery on header to make sure everything works, the rest  of the scripts in footer for fast loading -->
    <script
    src="https://code.jquery.com/jquery-3.3.1.min.js"
    integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>

    <!-- This goes before </head> closing tag, Google Analytics can be placed here --> 


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-28518177-5"></script>
    <script>
          window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-28518177-5');
</script>





<!-- Google Analytics -->
<script>
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-28518177-5', 'auto');
    ga('send', 'pageview');
</script>
<!-- End Google Analytics -->


    
    <script data-ad-client="ca-pub-5867637072125128" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

</head>

<body class="">
    

    <!-- Navbar -->
    <nav id="MagicMenu" class="topnav navbar navbar-expand-lg navbar-light bg-white fixed-top">
    <div class="container">
        <a class="navbar-brand" href="https://www.svenmalvik.com/index.html"><strong>Azure Blog</strong></a>
        <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarColor02" style="">
            <ul class="navbar-nav mr-auto d-flex align-items-center">
               <!--  Replace menu links here -->

<li class="nav-item">
    <a class="nav-link" href="https://www.svenmalvik.com/index.html">Home</a>
</li>
<li class="nav-item">
    <a class="nav-link" href="https://www.svenmalvik.com/categories.html#azure%20api%20management">APIM</a>
</li>
<li class="nav-item">
    <a class="nav-link" href="https://www.svenmalvik.com/aboutme">Me</a>
</li>
<li class="nav-item">
    <a class="nav-link" href="https://www.svenmalvik.com/contact.html">Contact</a>
</li>
<li class="nav-item">
    <a class="nav-link" href="https://www.svenmalvik.com/privacy-policy.html">Privacy</a>
</li>
<li class="nav-item">
    <a class="nav-link" href="https://www.dpbolvw.net/click-100299205-14411736">Apress books (10% off)</a>
</li>

            </ul>
            <ul class="navbar-nav ml-auto d-flex align-items-center">
                <script src="https://www.svenmalvik.com/assets/js/lunr.js"></script>

<script>
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 1000 );
        $( "body" ).removeClass( "modal-open" );
    });
});
    

var documents = [{
    "id": 0,
    "url": "/404/",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "/aboutme",
    "title": "Sven Malvik",
    "body": "	                              {{page. title}} Connect:                       My name is Sven Malvik, and I am an Azure MVP who . . .                                 loves to speak at tech conferences            listens to techno music while coding :)                                At daytime, I'm heading the Cloud Platform department in Vipps, a Norwegian payment service.                                                   {% include articleAd. html %}      Speaking Engagements: Jan 2021: Azure API Management at Austin Meetup (virtual)Dec 2020: Azure API Management at Norway at DEVREAL. io (virtual)Nov 2020: Understanding Azure App Configuration at Azure Meetup Oslo/Mumbai (virtual)Nov 2020: Azure API Management (APIM) with Sven Malvik at Microsoft Azure Latin America (virtual)Nov 2020: Workshop: Azure API Management at an external company (virtual)Oct 2020: Understanding Azure App Configuration at Azure User Group Denmark (virtual)Sep 2020: Understanding Azure App Configuration at Norwegian . NET User Group (virtual)Sep 2020: Understanding Azure App Configuration at Azure Meetup Oslo/New York/Mumbai (virtual)Sep 2020: Workshop: Understanding Azure API Management at NDC Minnesota (virtual)Jun 2020: From Traditional Ops to Cloud-Native in Azure at NDC Oslo (virtual)Jun 2020: From Traditional Ops to Cloud-Native in Azure at Confer Conf 2020 (virtual)Mai 2020: How Vipps uses Azure API Management at Azure Meetup Oslo (virtual)Apr 2020: Workshop: Azure API Management 101 at an external company (virtual)Mar 2020: From Traditional Ops to Cloud-Native in Azure at itSMF Conference NorwayFeb 2020: Workshop: Azure API Management 101 at an external company (virtual)Jan 2020: Workshop: Azure API Management 101 at an external company (virtual)Jan 2020: Workshop: Azure API Management 101 at Azure Meetup OsloNov 2020: The Rise of the Citizen Developer at Microsoft TechX Oslo (Keynote Guest)Oct 2019: Integrating Bot Framework with external services, LUIS and a human touch at Azure Meetup OsloSep 2019: How Vipps uses Azure to become the No. 1 payment service in Norway at JavaZone NorwayJun 2019: We Build an Intelligent Azure Q&amp;A Bot at Azure Meetup Oslo at Global Azure Bootcamp Norway      {% include articleAd. html %}"
    }, {
    "id": 2,
    "url": "/authors-list.html",
    "title": "Authors",
    "body": "{{page. title}}:     {% for author in site. authors %}                                         {{ author[1]. name }} :       (View Posts)      {{ author[1]. bio }}                          &nbsp;       &nbsp;                                    {% endfor %}  "
    }, {
    "id": 3,
    "url": "/buy-me-a-coffee.html",
    "title": "Buy me a coffee",
    "body": "Hi! I am Sal, web designer &amp; developer at WowThemes. net. The free items I create are my side projects and Mundana for Jekyll is one of them. You can find all the work I release for free here. You have my permission to use the free items I develop in your personal, commercial or client projects. If you’d like to reward my work, I would be honored and I could dedicate more time maintaining the free projects. Thank you so much! Buy me a coffee "
    }, {
    "id": 4,
    "url": "/categories.html",
    "title": "Categories",
    "body": "	            Categories          {% for category in site. categories %}     {{ category[0] }}:              {% include articleAd. html %}                {% assign pages_list = category[1] %}    {% for post in pages_list %}    {% if post. title != null %}     {% if group == null or group == post. group %}           {% include main-loop-card. html %}     {% endif %}    {% endif %}    {% endfor %}    {% assign pages_list = nil %}    {% assign group = nil %}    {% endfor %}                  {% include sidebar-featured. html %}          "
    }, {
    "id": 5,
    "url": "/contact.html",
    "title": "Contact",
    "body": "You can email me or find me on LinkedIn if you want to get in touch. I love meeting new people so don’t hesitate to send a message!     If you’d like to get in touch and are very old-school, you can send a letter to:Trettåsen 50, 2008 Fjerdingby, Norway{% include articleAd. html %} "
    }, {
    "id": 6,
    "url": "/",
    "title": "Azure Blog by Sven Malvik | Microsoft MVP",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 250px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 300 }}               Ad                             {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       {{ fourth_post. date | date: '%b %d, %Y' }}                                                                                                AdA good study guide for the Azure Fundamentals exam AZ-900: 						Microsoft Azure                        {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 7,
    "url": "/privacy-policy.html",
    "title": "Privacy Policy",
    "body": "”{{site. name}}” takes your privacy seriously. To better protect your privacy we provide this privacy policy notice explaining the way your personal information is collected and used. Collection of Routine Information: This website track basic information about their visitors. This information includes, but is not limited to, IP addresses, browser details, timestamps and referring pages. None of this information can personally identify specific visitor to this website. The information is tracked for routine administration and maintenance purposes. Cookies: Where necessary, this website uses cookies to store information about a visitor’s preferences and history in order to better serve the visitor and/or present the visitor with customized content. Advertisement and Other Third Parties: Advertising partners and other third parties may use cookies, scripts and/or web beacons to track visitor activities on this website in order to display advertisements and other useful information. Such tracking is done directly by the third parties through their own servers and is subject to their own privacy policies. This website has no access or control over these cookies, scripts and/or web beacons that may be used by third parties. Learn how to opt out of Google’s cookie usage. Links to Third Party Websites: We have included links on this website for your use and reference. We are not responsible for the privacy policies on these websites. You should be aware that the privacy policies of these websites may differ from our own. Security: The security of your personal information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage, is 100% secure. While we strive to use commercially acceptable means to protect your personal information, we cannot guarantee its absolute security. Changes To This Privacy Policy: This Privacy Policy is effective and will remain in effect except with respect to any changes in its provisions in the future, which will be in effect immediately after being posted on this page. We reserve the right to update or change our Privacy Policy at any time and you should check this Privacy Policy periodically. If we make any material changes to this Privacy Policy, we will notify you either through the email address you have provided us, or by placing a prominent notice on our website. Contact Information: For any questions or concerns regarding the privacy policy, please contact us here. "
    }, {
    "id": 8,
    "url": "/tags.html",
    "title": "Tags",
    "body": "	          Tags          {% for tag in site. tags %}     {{ tag[0] }}:           {% assign pages_list = tag[1] %}    {% for post in pages_list %}    {% if post. title != null %}     {% if group == null or group == post. group %}           {% include main-loop-card. html %}     {% endif %}    {% endif %}    {% endfor %}    {% assign pages_list = nil %}    {% assign group = nil %}    {% endfor %}                  {% include sidebar-featured. html %}          "
    }, {
    "id": 9,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 10,
    "url": "/page2/",
    "title": "Azure Blog by Sven Malvik | Microsoft MVP",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 250px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 300 }}               Ad                             {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       {{ fourth_post. date | date: '%b %d, %Y' }}                                                                                                AdA good study guide for the Azure Fundamentals exam AZ-900: 						Microsoft Azure                        {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 11,
    "url": "/page3/",
    "title": "Azure Blog by Sven Malvik | Microsoft MVP",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 250px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 300 }}               Ad                             {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       {{ fourth_post. date | date: '%b %d, %Y' }}                                                                                                AdA good study guide for the Azure Fundamentals exam AZ-900: 						Microsoft Azure                        {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 12,
    "url": "/page4/",
    "title": "Azure Blog by Sven Malvik | Microsoft MVP",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 250px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 300 }}               Ad                             {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       {{ fourth_post. date | date: '%b %d, %Y' }}                                                                                                AdA good study guide for the Azure Fundamentals exam AZ-900: 						Microsoft Azure                        {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 13,
    "url": "/page5/",
    "title": "Azure Blog by Sven Malvik | Microsoft MVP",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 250px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 300 }}               Ad                             {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       {{ fourth_post. date | date: '%b %d, %Y' }}                                                                                                AdA good study guide for the Azure Fundamentals exam AZ-900: 						Microsoft Azure                        {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 14,
    "url": "/page6/",
    "title": "Azure Blog by Sven Malvik | Microsoft MVP",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 250px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 300 }}               Ad                             {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       {{ fourth_post. date | date: '%b %d, %Y' }}                                                                                                AdA good study guide for the Azure Fundamentals exam AZ-900: 						Microsoft Azure                        {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 15,
    "url": "/azure-ddos-2020-review/",
    "title": "Insights & Trends of DDoS Attacks in 2020 on Azure",
    "body": "2021/02/07 - 2020 was a rough year for the Azure DDoS Protection team in Microsoft. DDoS attacks has grown with 50% in 2020. We are all working from home and the internet traffic has exploded which makes it a lot easier for an attacker to launch a DDoS attack. {% include articleAd. html %} DDoS stands for Distributed Denial-of-Service and means that multiple machines are working together to attack one target. Since we all work from home we are all helping attackers to generate traffic and bring down services. Companies can hardly distinguish between a friendly visiter and a DDoS attack. Still, the Azure DDoS Protection team mitigated an average of 500 attacks a day. In Mars and April the number was even higher and around 800 to 1000 attacks a day. The top targets are protocols that are used in IoT-connected devices such as DNS, NTP, CLDAP, WSD, SSDP, memcached, and OpenVPN.  The top source that start DDoS attacks are the United States with 45%. Targets are Europe, Asia, and the US. It’s also observed that many DDoS attacks are initiated to cover up bigger network intrusions. If you are victim of a DDoS attack, there might be going on something more. {% include articleAd. html %}  Source: Azure DDoS Protection—2020 year in review Components of a DDoS response strategy"
    }, {
    "id": 16,
    "url": "/what-is-azure/",
    "title": "What is Azure?",
    "body": "2021/02/06 - When I started my career as a developer in a start up company, we build a website that we hosted on a physical server that was running in a separate room with all of its infrastructure. That’s what we did back then, all companies did this. A business had its web server running on its own server hardware. When a business got more users onto their website more power was needed. The business would have to purchase more server hardware. More server hardware means more people that can maintain the server hardware and administrate all of its software running on the servers hardware. Another option was (still is - don’t know why), to outsource everything to a hosting company and pay them for their services. {% include articleAd. html %} Azure works differently. Rather than running your own server hardware and all of its infrastructure by yourself, you use the massive pool of computing resources that Azure provides. Azure got everything, virtual machines, databases, storage, and 200+ more products and services that you can use out of the box. The best, you pay only for what you need at a given time. If you need one virtual machine and one database today you will just pay for these instances. Tomorrow, when you run 10 instances you pay for 10 instances. You can decommission all your resources whenever you want and pay only for the time they where up and running. Azure is the name of Microsoft’ cloud platform. It was first announced under the name Windows Azure in 2008 but was renamed to Microsoft Azure in 2014. Today, Azure provides over 200 products and cloud services for building, managing and deploying your applications. Azure cloud is essentially a set of physical servers that run in over 150 data centers around the globe. You choose where you want to run your workload. Simplified, Azure is a large collection of servers and networking hardware running a complex set of distributed applications. These applications orchestrate the configuration and operation of virtualized hardware and software. It’s this orchestration that makes Azure powerful. Users don’t need to maintain and upgrade any hardware. They can focus on their domain while Azure does the rest. {% include articleAd. html %} Azure covers 4 Different Areas:  Infrastructure as a service (IaaS) - You deploy data onto a server in Azure that you control. Microsoft takes care of the physical hardware.  Platform as a service (PaaS) - You manage your applications and databases, while Microsoft manages all other services required to run your application like middleware, virtual machines, storage and networking.  Software as a service (SaaS) - You use an application like Office 365 or Salesforce. Microsoft manages the actual application.  Serverless Computing - You write and deploy your application code without worrying about the underlying infrastructure. {% include articleAd. html %} Useful Links:  What is Azure? Create your Azure free account today"
    }, {
    "id": 17,
    "url": "/azure-arm-asm/",
    "title": "How Virtual Machine Classic is Different to (Normal) VM in Azure",
    "body": "2021/02/06 - Have you ever wondered what a “classic” Virtual Machines in Azure is? Some virtual machines are classic and some others are not. Why is that? The short answer is that it’s the same virtual machine. What’s different is the way it was deployed. This post will explain the history behind classic virtual machines in Azure and what you need to know. {% include articleAd. html %} Two Different Deployment Models: Until recently in February 2020, a year ago, you could choose whether you wanted to deploy a VM with “classic” or with the “Resource Manager”. The Azure Resource Manager that we call ARM is the current deployment model in Azure where we describe the resources we are going to deploy in a JSON format called ARM template. ARM templates exists since 2014. One of the greatest features that came with ARM was Resource Groups that groups resources that share the same lifecycle. This wasn’t always possible in Azure. Before ARM was introduces, the deployment model was called Azure Service Management (ASM). When you had a set of 10 resources that shared the same lifecycle, you had to deploy all resources independently. Managing all resources independently was a lot of complexity to handle which wasn’t so much fun. ARM takes this burden away from us and make life easier. Today, we see classic deployed resources almost only for some VMs. It’s because it took some time to migrate all Azure resources from ASM to ARM. More specifically it means that resources that were deployed through the ASM API had to be changed to use the ARM API. This process took some years and will be finished soon. The complete retirement starts March, 2023. {% include articleAd. html %} ASM vs ARM: The ASM API had limited capabilities. It lacked access control, resource groups, dependency management, tags and more. With ARM you got the following capabilities that we are so used to today:  Deploy, manage, and monitor all resources as one group.  Deploy resources in a consistent state.  Apply access control to all resources.  Apply tags to resources.  Describe your infrastructure in JSON, the ARM template.  Define dependencies between resources to ensure the correct order. {% include articleAd. html %} Useful Links:  Azure Resource Manager vs. classic deployment: Understand deployment models and the state of your resources"
    }, {
    "id": 18,
    "url": "/azure-app-configuration-vs-key-vault/",
    "title": "How Azure Key Vault is Different to Azure App Configuration",
    "body": "2021/02/05 - We store certificates and sensitive data as secrets in Azure Key Vault. I know that many store their application configuration there as well - just because it’s easy and close to the secrets. This post discusses why you should use Azure App Configuration for your non-sensitive configurations instead. {% include articleAd. html %} First things first - Azure App Configuration and Azure Key Vault are complementary services that should be used side by side. Azure App Configuration stores insensitive data like key-value pairs but also references secrets in Azure Key Vault. An entry in App Configuration that references such a secret stores the URI of a Key Vault value rather than the value itself. An App Configuration client provider that comes as an SDK for your application retrieves the Key Vault value reference of an entry, just as it does for any other keys stored in App Configuration. The client provider recognizes the keys as Key Vault references based on the content-type that every App Configuration entry gets. The client provider then asks the Key Vault to retrieve their secrets. Azure App Configuration and Azure Key Vault don’t communicate with each other and means that an application is still responsible for authenticating to both App Configuration and Key Vault. {% include articleAd. html %} Benefits of Azure App Configuration over Key Vault for Insensitive Data: Below is a list of features I came up with that distinguishes Azure App Configuration from Azure Key Vault. Compared to Azure Key Vault - App Configuration …  avoids Duplication supports feature flags supports flat and hierarchal key management categorizing keys using labels does point-in-time snapshots that can be replayed stores a complete timeline in key-value changes supports compare configuration values for different points in time integrates with Azure DevOps does data encryption at rest or in transitUseful Links:  Azure App Configuration Introduction Tutorial: Use Key Vault references in a Java Spring app"
    }, {
    "id": 19,
    "url": "/azure-apim-key-vault/",
    "title": "How to Reference Key Vault Secrets in Azure API Management",
    "body": "2021/02/05 - In an enterprise, an Azure API Management instance is often shared by many teams and many developers. The developers may all have access to all secrets stored in named values for using in policies for JWT token validation or because for sending passwords in authentication headers. It’s therefore best practice to store secrets in Azure Key Vault and not in named values. Azure API Management can then use its Managed Service Identity to access the secrets from this Azure Key Vault by referencing secrets. This post will show how to set a secret as the value in a response header. {% include articleAd. html %} Enable Managed Identity in APIM: In Azure, an AD identity can be assigned to a managed resource such as a Azure Function, App Service and also an instance of Azure API Management. A Resource with an identity has the capabilities to work with other resources that leverage Azure AD for authentication. We can easily enable a managed system identity (MSI) in APIM. Enable managed system identity in Azure API Management {% include articleAd. html %} Key Vault: To demonstrate how to access a secret from APIM, let’s first create a secret mysecret with a value secretaccesscode. Create secret in Azure Key Vault Just to show you the value of the secret, here it’s visible. Show secret value in Azure Key Vault We need now to tell our Key Vault that our apim instance has permission to Get mysecret. We do this by adding a new access policy as shown below. Add access policy in Azure Key Vault {% include articleAd. html %} Set the secret permission to Get and select the identity of your Azure API Management instance. Configure access policy in Azure Key Vault Now we can see that we set up a new access policy. Remember to save :). Save access policy in Azure Key Vault {% include articleAd. html %} Referencing a Key Vault Key in Azure API Management: Add a new named value in your APIM instance and select the type Key Vault. A new pane opens where you can select the key vault and secret you want to reference. In my case it’s mysecret. Reference secret in apim named values If everything went well you will see a green Success icon. Referenced secret in apim named values Let’s now select a random API operation and open the policy so we can add a response header. Edit API policy I add a basic header with the named value that I called secret-from-kv. Add customer header with secret value to API policy {% include articleAd. html %} Finally, we test this endpoint and can see the value in the response. Retrieve customer header with secret value from API  Developers that have access to this instance may be able to debug a policy, hence retrieve the secret. Conclusion: Referencing secrets from Azure Key Vaults in Named Values was introduced December 2020. That means that we don’t need to follow tutorials from many blog posts that were written before. {% include articleAd. html %} Useful Links: Use named values in Azure API Management policies - Key vault secrets "
    }, {
    "id": 20,
    "url": "/azure-nsg-vs-firewall/",
    "title": "How is Azure Firewall different from Network Security Groups?",
    "body": "2021/02/04 - Azure provides two security features in Azure for managing inbound and outbound traffic to and from Azure resources like virtual machines that are running an SQL Server, web applications, or domain services: Azure Firewall and Network Security Groups (NSGs). This post will discuss how the two differ from each other and how they can be paired up to secure traffic to resources in Azure. {% include articleAd. html %} Network Security Groups (NSG): Azure Network Security Groups (NSGs) is an OSI layer 3 &amp; 4 network service for refining traffic to and from an Azure Virtual Network (VNet). They can be associated with subnets or network interfaces of Azure VMs. It’s recommended to associate NSGs to subnets or network interfaces, but not both. The same NSG can be applied to many subnets. A NSG consists of rules that allow or deny network traffic based on 5-tuple information:  Protocol (TCP, UDP, ICMP) Source IP address Source port Destination IP address Destination portAzure Firewall: Azure Firewall is a highly available, managed firewall service that filters network and application level traffic. It detects the workload in a VNet and protects Azure resources from malicious traffic. It has the ability to process traffic across subscriptions and VNets that are deployed in a hub-spoke model. This managed firewall service can filter and analyze OSI layer 3, 4 and 7 traffic. Azure Firewall provides the same capabilities as an NSG and more. This firewall service also eliminates the need for Load Balancer. Configuring two availability zones will give us a SLA of 99. 99%. {% include articleAd. html %} Feature Comparison: Service Tags: Azure Firewall and NSG support service tags which are labels that represent a range of IP addresses for particular services such as Azure Key Vault, Data Lake, Container Registry, etc. These are managed by Microsoft and cannot be customized. FQDN Tags: Only Azure Firewall supports FQDN Tags. They represent a group of fully qualified domain names of Microsoft services such as Windows Update or Azure Backup. Like service tags, they are managed by Microsoft, one tag to rule them all :) SNAT: Only Azure Firewall supports Source Network Address Translation (SNAT). It’s possible to configure Azure Firewall with a public IP address that can be used to masked the IP address of Azure resources that are sending out via the Firewall. DNAT: Only Azure Firewall supports Source Destination Address Translation (DNAT) which is used to translate incoming traffic to the firewall’s public IP address to the private IP addresses of a VNet. {% include articleAd. html %} When to use what?: NSGs and Azure Firewall work great together and should be used complimentary. We use NSGs for protecting incoming and outgoing traffic of a subnet. Azure Firewall is the service for filtering traffic to a VNet from the outside-world. It should be deployed in it’s own VNet and be isolated from other Azure resources. Azure Firewall is a highly available solution that can automatically scale. Useful Links:  Azure Firewall documentation Network security groups"
    }, {
    "id": 21,
    "url": "/azure-icons/",
    "title": "Secret Behind Pretty Azure Architecture Diagrams",
    "body": "2021/02/04 - One of my fellow cloud engineers in my team asked today in the morning about these pretty architecture diagrams that we nowadays have and what the secret behind is. That was a great question, and easy to answer. I think that if one person asks a question, then there will be more people asking the same question. So here’s the “Secret” behind Pretty Architecture Diagrams in Azure”. {% include articleAd. html %} Updated Azure Icons: Creating architecture diagrams can be fun when we manage to make them in a way that others understand them quickly. If they are at the same time pretty to look at, it’s even more fun :) Earlier last year Microsoft Azure refreshed its icons and made them prettier. Now in January 2021 they added even ~26 more beautiful icons. You can download all Azure Icons from the documentation. Here is what you CAN DO with the icons:  Use the icon to illustrate how products can work together In diagrams, Microsoft recommends to include the product name somewhere close to the icon Use the icons as they would appear within AzureHere is what you CAN NOT DO with the icons:  Don’t crop, flip or rotate icons Don’t distort or change icon shape in any way Don’t use Microsoft product icons to represent your product or serviceClean Azure Architecture Diagrams: Pretty icons is just half of the story to make an Azure architecture diagrams great. Even more important is structure. A diagram should show as few elements like icons, rectangular and lines as possible. There is one thing that I see often and that should never ever be done in an Architecture Diagrams in general. That is crossing lines. When ever there are crossing lines it can be a sign of a bad architecture. I suggest to take some extra rounds and revisit a diagram where you can’t get rid of crossing lines. {% include articleAd. html %} Examples: Here are some examples of clean Azure architecture diagrams.  Image above: Hub-spoke network topology in Azure Image above: Intelligent product search engine for e-commerce {% include articleAd. html %} Image above: Run a Jenkins server on Azure Image above: SQL Server 2008 R2 failover cluster in Azure -Sven "
    }, {
    "id": 22,
    "url": "/azure-az900/",
    "title": "AZ-900 Self-Study Guide for Azure Fundamentals",
    "body": "2021/02/03 - There are many good reasons to become Microsoft Azure Certified and take the Microsoft Azure AZ-900 exam. If you are reading this blog post, you might already have decided that you want to take a I want to share how to prepare for this exam and pass. Free Online Microsoft Learn AZ-900 Exam Study Guide resources:  Azure Fundamentals part 1: Describe core Azure concepts Azure Fundamentals part 2: Describe core Azure services Azure Fundamentals part 3: Describe core solutions and management tools on Azure Azure Fundamentals part 4: Describe general security and network security features Azure Fundamentals part 5: Describe identity, governance, privacy, and compliance features Azure Fundamentals part 6: Describe Azure cost management and service level agreementsDescribe cloud concepts (20-25%): Identify the benefits and considerations of using cloud services: Identify the benefits of cloud computing, such as high availability, scalability, elasticity, agility, and disaster recovery  Top benefits of cloud computing Examples of cloud computingIdentify the differences between Capital Expenditure (CapEx) and Operational Expenditure (OpEx) &gt; Capital expenditure (CapEx) versus operational expenditure (OpEx) Describe the consumption-based model &gt; Azure pricing Describe the differences between categories of cloud services: Describe the shared responsibility model &gt; Shared responsibility in the cloud Describe Infrastructure-as-a-Service (IaaS) &gt; What is IaaS? Describe Platform-as-a-Service (PaaS) &gt; What is PaaS? Describe serverless computing &gt; Serverless computing Describe Software-as-a-Service (SaaS) &gt; What is SaaS? Identify a service type based on a use case &gt; What are the different types of cloud computing services? Describe the differences between types of cloud computing: Define and describe cloud computing &gt; What is cloud computing? Describe private cloud &gt; What is a private cloud? Describe hybrid cloud &gt; What is a hybrid cloud? Compare and contrast the three types of cloud computing &gt; What are public, private, and hybrid clouds? Describe core Azure services (15-20%): Describe the core Azure architectural components: Describe the benefit and usage of Regions and Region Pairs  Azure global infrastructure Azure geographiesDescribe the benefit and usage of Availability Zones &gt; What are Availability Zones in Azure? Describe the benefit and usage of Resource Groups &gt; Resource groups Describe the benefit and usage of Subscriptions &gt; Azure subscription and service limits, quotas, and constraints Describe the benefit and usage of Management Groups &gt; What are Azure management groups? Describe the benefit and usage of Azure Resource Manager &gt; What is Azure Resource Manager? Explain Azure resources &gt; Azure resource providers and types Describe core resources available in Azure: Describe the benefits and usage of Virtual Machines, Azure App Services, Azure Container Instances (ACI), Azure Kubernetes Service (AKS), and Windows Virtual Desktop  Compute Virtual Machines App Service Container Instances Azure Kubernetes Service (AKS) Windows Virtual Desktop (WVD)Describe as the benefits and usage of Virtual Networks, VPN Gateway, Virtual network peering, and Express Route  Networking Virtual Network About Azure VPN gateway Virtual network peering Azure ExpressRouteDescribe the benefits and usage of Container (Blob) Storage, Disk Storage, File Storage, and storage tiers  Storage Blob Storage Disk File Azure Blob storage: hot, cool, and archive access tiersDescribe the benefits and usage of Cosmos DB, Azure SQL Database, Azure Database for MySQL, and Azure Database for PostgreSQL, and SQL Managed Instance  Welcome to Azure Cosmos DB Azure SQL Database Azure Database for MySQL Azure Database for PostgreSQL What is Azure SQL Managed Instance?Describe the benefits and usage of Azure Marketplace &gt; Azure Marketplace Describe Core Solutions and Management Tools on Azure (10-15%): Describe core solutions available on Azure: Describe the benefits and usage of IoT Hub, IoT Central, and Azure Sphere  IoT Hub IoT Central Azure SphereDescribe the benefits and usage of Azure Synapse Analytics, HDInsight, and Azure Databricks  Azure Synapse Analytics HDInsight Azure DatabricksDescribe the benefits and usage of Azure Machine Learning, Cognitive Services, and Azure Bot Service  Azure Machine Learning Cognitive Services Azure Bot ServiceDescribe the benefits and usage of serverless computing solutions that include Azure Functions and Logic Apps  Azure Functions Logic AppsDescribe solutions for software development including Azure DevOps, GitHub, GitHub Actions, and Azure DevTest Labs  Azure DevOps GitHub GitHub Actions Azure DevTest LabsDescribe Azure management tools: Describe the functionality and usage of the Azure Portal, Azure PowerShell, Azure CLI, Cloud Shell, and Azure Mobile App  Azure Portal Azure PowerShell Azure CLI Cloud Shell Azure Mobile AppDescribe the functionality and usage of Azure Advisor &gt; Introduction to Azure Advisor Describe the functionality and usage of Azure Resource Manager (ARM) templates &gt; What are ARM templates? Describe the functionality and usage of Azure Monitor &gt; Azure Monitor Describe the functionality and usage of Azure Service Health &gt; Azure Service Health Describe General Security and Network Security Features (10-15%): Describe Azure security features: Describe basic features of Azure Security Center, including policy compliance, security alerts, secure score, and resource hygiene &gt; What is Azure Security Center? Describe the functionality and usage of Key Vault &gt; Key Vault Describe the functionality and usage of Azure Sentinel &gt; Azure Sentinel Describe the functionality and usage of Azure Dedicated Hosts &gt; Azure Dedicated Hosts Describe Azure network security: Describe the concept of defense in depth &gt; Azure network security overview Describe the functionality and usage of Network Security Groups (NSG) &gt; Network Security Groups (NSG) Describe the functionality and usage of Azure Firewall &gt; Azure Firewall Describe the functionality and usage of Azure DDoS protection &gt; Azure DDoS Protection Describe Identity, Governance, Privacy, and Compliance Features (20-25%): Describe core Azure identity services: Explain the difference between authentication and authorization &gt; Windows Authentication Concepts Define Azure Active Directory &gt; Azure Active Directory Describe the functionality and usage of Conditional Access, Multi-Factor Authentication (MFA), and Single Sign-On (SSO)  Conditional Access Multi-Factor Authentication (MFA) What is single sign-on (SSO)?Describe Azure governance features: Describe the functionality and usage of Role-Based Access Control (RBAC) &gt; Role-Based Access Control (RBAC) Describe the functionality and usage of Azure Policy &gt; Azure Policy Describe the functionality and usage of resource locks &gt; resource locks Describe the functionality and usage of tags &gt; Azure tags Describe the functionality and usage of Azure Blueprints &gt; Azure Blueprints Describe the Cloud Adoption Framework for Azure &gt; What is the Microsoft Cloud Adoption Framework for Azure? Describe privacy and compliance resources: Describe the Microsoft core tenets of Security, Privacy, and Compliance  Introduction to Azure security Strengthen your security posture with Azure Azure data privacy and protection Azure complianceDescribe the purpose of the Microsoft Privacy Statement, Online Services Terms (OST) and Data Protection Amendment (DPA)  Microsoft Privacy Statement Online Services Terms (OST) Privacy: It’s all about youDescribe the purpose of the Trust Center &gt; Microsoft Trust CenterDescribe the purpose of the Azure compliance documentation &gt; Azure compliance documentation Describe the purpose of Azure Sovereign Regions (Azure Government cloud services and Azure China cloud services)  National clouds Microsoft Azure operated by 21Vianet What is Azure Government?Describe Azure cost management and Service Level Agreements (10-15%): Describe methods for planning and managing costs: Identify factors that can affect costs (resource types, services, locations, ingress and egress traffic) &gt; Azure pricing Identify factors that can reduce costs (reserved instances, reserved capacity, hybrid use benefit, spot pricing) &gt; Tutorial: Optimize costs from recommendations Describe the functionality and usage of the Pricing calculator and the Total Cost of Ownership (TCO) calculator  Pricing calculator TCO calculatorDescribe the functionality and usage of Azure Cost Management &gt; What is Azure Cost Management + Billing? Describe Azure Service Level Agreements (SLAs) and service lifecycles: Describe the purpose of an Azure Service Level Agreement (SLA)  Service Level Agreements SLA summary for Azure servicesIdentify actions that can impact an SLA (i. e. Availability Zones) &gt; Overview of the reliability pillar Describe the service lifecycle in Azure (Public Preview and General Availability)  Lifecycle FAQ – Microsoft Azure Supplemental Terms of Use for Microsoft Azure PreviewsHappy studying :) "
    }, {
    "id": 23,
    "url": "/devreal-diversity-inclusion/",
    "title": "Diversity & Inclusion Tech Conversation",
    "body": "2021/02/03 - How are organizations like Vipps, Microsoft and Tata Consultancy Services (TCS) establishing a diverse and inclusive workplace? What initiatives are they driving and how can we all work together to create a positive impact? Join this free online event. {% include articleAd. html %} This event is about real experiences. We want to know why this topic matters so much to employees, students and companies. Join this free online event This event is split into 2 sections. In the first section the speakers will tell about their experiences. In the second section we’ll have a real conversation where we will get a lot of valuable insights. Thanks so much to the speakers for participating. It really means a lot to many that want to know more about the topic. I also want to send a special thanks to Ellie King who will moderate this event. This episodes guests are from well-known companies. In addition we have a student with us which will tell about what she expects from life.  Ellie King (Diversity &amp; Inclusion Advocate) Alex Warris (Male Engagement Strategist) Sibin Philip (TCS/Vipps) Aneesh MN (TCS/Vipps) Sherry List (Microsoft) Helena Løvdal Bjørbekk (NTNU)Join this free online event {% include articleAd. html %} "
    }, {
    "id": 24,
    "url": "/azure-apim-function-msi/",
    "title": "How to Secure Azure Functions App with Azure API Management",
    "body": "2021/02/02 - How to use an Azure Managed Identity to authenticate against an Azure Functions app that is exposed through Azure API Management. Our Function App is by default public available to everyone. There are two things we can do to prevent this. Either by enabling Azure AD authentication or by IP whitelisting. This post discusses authentication with Azure AD authentication with Managed Identities. Public available Azure Function App Enabling Azure AD authentication on a Functions App means Azure API Management (APIM) needs to authenticate itself. This is where Managed Identities comes into play. {% include articleAd. html %} A system-assigned Managed Identity is enabled directly on the Azure resource. When the identity is enabled, Azure creates an identity for the instance in the Azure AD tenant. After the identity is created, the credentials are provisioned onto the instance. The lifecycle of a system-assigned identity is directly tied to the Azure resource that it’s enabled on. If the resource is deleted, Azure automatically cleans up the credentials and the identity in Azure AD. There’s no need to save passwords, no need to rotate credentials etc. Everything is done automatically for your in the background. Let’s make this happen now. Setup: I created an instance of Azure API Management with the Consumption tier and an Azure Function App that I can access as you can see in the picture above. Azure API Management and Function App setup Enabling Managed Identity on Azure API Management: Enabling a Managed Identity for Azure API Management takes about 5 minutes. Click on Managed Identity and then enable it as shown below. Enabling Managed Identity in Azure API Management Enabling AAD Authentication in Azure Functions: We can now continue and enable Azure AD authentication in the Functions App. Follow the steps as shown. Enabling AAD Authentication in Azure Functions 1 Select Azure Active Directory as the authentication provider, not Facebook :) Enabling AAD Authentication in Azure Functions 2 Now we try to access the Function App once again … and we can see that we need to authenticate. Azure Function App enabled authentication with AAD Azure API Management Policy using Managed Identity: {% include articleAd. html %} For Azure API Management to authenticate against AAD and receive a bearer token we need add some code in the inbound section of the API or Operation (Endpoint) of the Function App that I already have in APIM. We will use the authentication-managed-identity policy to authenticate with our Azure Functions App using the managed identity of APIM. This policy uses the managed identity to obtain an access token from AAD for accessing the specified resource. After successfully obtaining the token, the policy will set the value of the token in the Authorization header using the Bearer scheme. First, we get the Application ID of the Function App in AAD as shown below. Application ID of Function App in AAD Second, we open the policy we want to change. In this example I chose the API level policy. Opening Editor of Azure API Management API Policy Third, we add authentication-managed-identity to the inbound section and pointing to the application for the Function App. That’s the Application ID of Function App in AAD. Editing Azure API Management Policy Now we can test the endpoint from within the portal directly …Azure API Management … or from a browser. I disabled the requirement of a subscription key to make it simpler. Azure API Management Conclusion: {% include articleAd. html %} Managed Identities make life easier and more secure. "
    }, {
    "id": 25,
    "url": "/azure-naming-conventions/",
    "title": "Azure Naming Convention Best Practices",
    "body": "2021/02/02 - Structure helps us to be in control. That is very true also in Azure. Especially in larger organizations where many cloud engineers create, remove, update and delete (CRUD) resources all the time. One tool that supports us to keep control is Naming Standards. This post discusses this topic. {% include articleAd. html %} Keep it Simple, Stupid - KISS: Simplicity helps us to structure knowledge, ideas and thoughts better. When it comes to naming, I think short names supports this idea. Instead of having descriptive and somehow long names, I suggest short resource names. There might also be technical justifications. A Windows VM name has a maximum character limit of 15. Keeping it short and simple allows us to re-use the same logic regardless of resource type, location or service. Use Prefix and Postfix: One option is to use prefix or suffix to add clarity to resource names. I’m a fan of having at least the following elements as part of a resource name: environment, resource type and workload. Another option is to use a suffix and a randomized string that is based on the resource group. Use tags complementary for context like environment, etc. This will help for resources which needs global unique names. As infrastructure as code is nowadays a common approach to manage resources, naming conventions are easy to implement.  Get more details about how naming conventions can look like. Policy: Azure Policies can help to ensure new Azure resources follow your naming conventions. Create policies that are scoped to resource types that will deny a deployment of a resource if a naming convention isn’t compliant to your policies. Here’s an example of a policy for VMs: {    properties : {      displayName :  VM naming convention ,      description :  Naming convention for VMs.  ,      mode :  All ,      policyRule : {        if : {          allOf : [           {              field :  type ,              match :  Microsoft. Compute/virtualMachines            },           {              not : {                field :  name ,                match :  az-???-##-vm  // ? for letters and # for numbers.             }           }         ]       },        then : {          effect :  deny        }     }   } }More about Azure Policy {% include articleAd. html %} The above policy checks the Name if it matches the format az-???-##-vm, otherwise it will deny. The match pattern is defined using standard Azure Policy conditions. Next steps: We use naming conventions to make life easier for us. The thing is that we can’t put all important information into a name. That’s where tagging can help. Adding metadata to resources will reduce the complexity of names and can be viewed complimentary to a naming convention. Tagging conventions can also be set as Azure Policy. "
    }, {
    "id": 26,
    "url": "/azure-az304/",
    "title": "AZ-304 Self-Study Guide for Becoming an Azure Solution Architect Expert",
    "body": "2021/02/01 - Microsoft updated it’s role based exam for AZ-301. It’s now called AZ-304 and launched last year. This certification is a great proof for why organizations should hire you. Some say it’s the most difficult exam certification path as it is one of only two Expert level certifications for Azure. This post will provide you with tons of links that you should go through so you will master the exam for AZ-304. {% include articleAd. html %}  Candidates for this exam are Azure Solutions Architects who advise stakeholders and translate business requirements into secure, scalable, and reliable solutions. Candidates should have advanced experience and knowledge of IT operations, including networking, virtualization, identity, security, business continuity, disaster recovery, data platform, budgeting, and governance. This role requires managing how decisions in each area affects an overall solution. Candidates must have expert-level skills in Azure administration and have experience with Azure development processes and DevOps processes. A good place to start is Microsoft Learn. There are many interactive learning paths that you can work through, all free. It’s a good way to study and gain a good understanding of the services by actually using them. I’ve listed a collection of links that are important to study and that are part of the skills measured for this exam. These are guide links and you should put some effort into all these topics. I really hope these guides will help you to pass the exam for AZ-304 and become an Azure Solution Architect. Design Monitoring (10-15%): Design for cost optimization:  Quickstart: Explore and analyze costs with cost analysis Tutorial: Optimize costs from recommendationsDesign a solution for logging and monitoring:  Azure Monitor Logs overview Azure security logging and auditing Overview of Azure platform logs What is Azure Event Grid? Security Control: Logging and MonitoringDesign Identity and Security (25-30%): Design authentication:  What is single sign-on (SSO)? What is Azure Active Directory authentication? What is Conditional Access? Using the location condition in a Conditional Access policy What is Azure AD Connect? Plan an Azure Active Directory self-service password reset deployment What is guest user access in Azure Active Directory B2B?Design authorization:  Authentication vs. authorization Identity and access management Management group and subscription organizationDesign governance:  Develop your naming and tagging strategy for Azure resources Conduct a cloud policy review Deploy a CAF Foundation blueprint in AzureDesign security for applications:  Azure Key Vault keys, secrets and certificates overview Best practices to use Key Vault What are managed identities for Azure resources? Integrating Azure Active Directory with applications getting started guideDesign Data Storage (15-20%): Design a solution for databases:  Azure data platform end-to-end Azure Data Architecture Guide Azure encryption overviewDesign data integration:  Mapping data flows in Azure Data Factory What is Azure Data Factory? What is Azure Databricks? What is dedicated SQL pool (formerly SQL DW) in Azure Synapse Analytics?Select an appropriate storage account:  Access tiers for Azure Blob Storage - hot, cool, and archive Authorizing access to data in Azure Storage Optimize costs by automating Azure Blob Storage access tiersDesign Business Continuity (10-15%): Design a solution for backup and recovery:  About Site Recovery General questions about Azure Site Recovery Moving Azure VMs to another Azure region What is the Azure Backup service?vManage Azure VM backups with Azure Backup service Rehydrate blob data from the archive tier Disaster recovery and storage account failover Azure Storage compliance offeringsDesign for High Availability:  Building solutions for high availability using Availability Zones Autoscaling High availability and disaster recovery scenarios for IaaS apps Use geo-redundancy to design highly available applicationsDesign Infrastructure (25-30%): Design a compute solution:  Choose an Azure compute service for your application Choosing Azure compute platforms for container-based applications An introduction to Azure AutomationDesign a network solution:  Azure networking services overview The virtual datacenter: A network perspective Plan virtual networks What is Azure Load Balancer?Design an application architecture:  Building microservices on Azure Azure Container Instances and container orchestrators About API ManagementDesign migrations:  Build migration plan with Azure Migrate Add migration tools What is Azure Database Migration Service?Conclusion: Having achieved both AZ-303 and this AZ-304 is amazing and I really hope you will pass both and become an Azure Solution Architect Expert! Let me know how it went. Maybe you would even like to tell your story. Send me a message. -Sven "
    }, {
    "id": 27,
    "url": "/azure-az303/",
    "title": "AZ-303 Self-Study Guide for Becoming an Azure Solution Architect",
    "body": "2021/02/01 - Microsoft updated it’s role based exam for AZ-300. It’s now called AZ-303 and launched last year. This certification is a great proof for why organizations should hire you. Some say it’s the most difficult exam certification path as it is one of only two Expert level certifications for Azure. This post will provide you with tons of links that you should go through so you will master the exam for AZ-303. {% include articleAd. html %}  Candidates for this exam are Azure Solutions Architects who advise stakeholders and translate business requirements into secure, scalable, and reliable solutions. Candidates should have advanced experience and knowledge of IT operations, including networking, virtualization, identity, security, business continuity, disaster recovery, data platform, budgeting, and governance. This role requires managing how decisions in each area affects an overall solution. Candidates must have expert-level skills in Azure administration and have experience with Azure development processes and DevOps processes. A good place to start is Microsoft Learn. There are many interactive learning paths that you can work through, all free. It’s a good way to study and gain a good understanding of the services by actually using them. I’ve listed a collection of links that are important to study and that are part of the skills measured for this exam. These are guide links and you should put some effort into all these topics. I really hope these guides will help you to pass the exam for AZ-303 and become an Azure Solution Architect. Implement and Monitor an Azure Infrastructure (50-55%): {% include articleAd. html %} Implement cloud infrastructure monitoring: Monitor Security:  Azure security management and monitoring overview Strengthen your security posture with Azure Security CenterMonitor Performance:  Create diagnostic settings to send platform logs and metrics to different destinations Metric Baseline - Get Tutorial: Optimize costs from recommendations Azure Monitor overview Visualizing data from Azure MonitorMonitor Health and Availability:  Network monitoring solutions What is Azure Service Health?Monitor Cost:  Use cost alerts to monitor usage and spending Tutorial: Create and manage exported dataConfigure Advanced Logging:  What is monitored by Azure Monitor? Create a Log Analytics workspace in the Azure portalConfigure logging for workloads:  Azure Monitor Logs overviewAction Groups:  Create and manage action groups in the Azure portalAdvanced Alerts:  Manage alert instances with unified alerts Create, view, and manage log alerts using Azure Monitor{% include articleAd. html %} Implement storage accounts:  Introduction to the core Azure Storage services Planning for an Azure Files deployment Storage account overview Configure Azure Storage firewalls and virtual networks Grant limited access to Azure Storage resources using shared access signatures (SAS) Authorize access to blobs and queues using Azure Active Directory Manage storage account access keys Azure Storage redundancy Disaster recovery and storage account failoverImplement VMs for Windows and Linux:  Tutorial: Create and deploy highly available virtual machines with Azure PowerShell Introduction to Azure managed disks Sizes for virtual machines in Azure Azure Dedicated Hosts What are virtual machine scale sets? Azure Disk Encryption for virtual machines and virtual machine scale setsAutomate deployment and configuration of resources:  Single and multi-resource export to a template in Azure portal Understand the structure and syntax of ARM templates Tutorial: Create and deploy your first ARM template Using disks in Azure Resource Manager Templates Tutorial: Deploy a local ARM template Create an Azure Automation runbookImplement virtual networking:  Tutorial: Connect virtual networks with virtual network peering using the Azure portal Configure a VNet-to-VNet VPN gateway connection using PowerShell Create, change, or delete a virtual network peeringImplement Azure Active Directory:  Add your custom domain name using the Azure Active Directory portal What is Identity Protection? How it works: Azure AD self-service password reset Building a Conditional Access policy Enable per-user Azure AD Multi-Factor Authentication to secure sign-in events Configure Azure AD Multi-Factor Authentication settings What is guest user access in Azure Active Directory B2B? Understand how multiple Azure Active Directory organizations interactImplement and manage hybrid identities:  What is Azure AD Connect? Identity synchronization and duplicate attribute resiliency Implement password hash synchronization with Azure AD Connect sync Azure AD Connect sync: Understanding the architecture Azure Active Directory Seamless Single Sign-On: Quickstart Azure Active Directory Connect Health operationsImplement Management and Security Solutions (25-30%): {% include articleAd. html %} Manage workloads in Azure:  Create an Azure VM assessment Deploy workloads and assets (infrastructure, apps, and data) Prepare on-premises machines for migration to Azure An overview of Azure VM backup Quickstart: Set up disaster recovery to a secondary Azure region for an Azure VMImplement load balancing and network security:  Azure Load Balancer algorithm How an application gateway works What is Azure Web Application Firewall? Tutorial: Deploy and configure Azure Firewall using the Azure portal What is Azure Front Door? What is Traffic Manager? Network security groups Application security groups What is Azure Bastion?Implement and manage Azure governance solutions:  Organize your Azure resources effectively What is Azure role-based access control (Azure RBAC)? Azure custom roles Tutorial: Grant a user access to Azure resources using the Azure portal Manage access to Azure management with Conditional Access Best practices for Azure RBAC List Azure role assignments using the Azure portal Review access to Azure AD roles in Privileged Identity Management What is Azure Policy? Quickstart: Define and assign a blueprint in the portalManage security for applications:  Azure Key Vault basic concepts What are managed identities for Azure resources? Quickstart: Register an application with the Microsoft identity platformImplement Solutions for Apps (10-15%): {% include articleAd. html %} Implement an application infrastructure:  App Service overview Run a custom container in Azure Azure App Service plan overview Configure an App Service app in the Azure portal Integrate your app with an Azure virtual network Set up staging environments in Azure App Service Quickstart: Create your first Logic Apps workflow - Azure portal Introduction to Azure FunctionsImplement container-based applications:  Tutorial: Build and deploy container images in the cloud with Azure Container Registry Tasks Tutorial: Prepare an application for Azure Kubernetes Service (AKS) Push your first image to a private Docker container registry using the Docker CLI Tutorial: Create a container image for deployment to Azure Container InstancesImplement and Manage Data Platforms (10-15%): {% include articleAd. html %} Implement NoSQL databases:  What is Azure Table storage? Welcome to Azure Cosmos DB Introduction to the Azure Cosmos DB Cassandra API Distribute your data globally with Azure Cosmos DBImplement Azure SQL databases:  Getting started with single databases in Azure SQL Database Getting started with Azure SQL Managed Instance Creating and using active geo-replication - Azure SQL Database Quickstart: Create a server-level firewall rule using the Azure portalConclusion: I really hope that you find the time to dive into all these topics and pass the AZ-303 exam for becoming an Azure Solution Architect. It really can boost your career and makes it a lot easier to get the job you want. "
    }, {
    "id": 28,
    "url": "/azure-apim-introduction/",
    "title": "Introduction to Azure API Management",
    "body": "2021/01/25 - Azure API Management (APIM) is a way to create consistent and modern API gateways for existing backend services. It provides an interface for your backend services and APIs while making sure they’re secured, monitored, maintained, well documented and published in the cloud. This post is a brief introduction into Azure API Management. An overview of what you get with APIM:  Rate-limiting: Control the amount of incoming requests. You know your APIs and you know that it might not make sense that a requester pays a bill 10 times in a minute. Rate-limiting can be set based on keys that you choose yourself.  Monitor APIs: Identify issues like slow responses.  Unify backend APIs: Azure API Management works as an orchestration tool of your backend APIs whether they are in Azure or on-premise. A unified API interface is simple to use for your clients.  Analytics: Do you want to monetize your services? Azure API Management got an interface for that. It can also be integrated with Application Insights. You’ll get a full dashboard to see all the data you need.  Security: An security breach can ruin your organization. Azure API Management provides OAuth 2. 0 user authorization and can be integrated with Azure Active Directory. It can validate JWT token and much more.  Transform Data: Policies in Azure API Management let you transform payload into different formats like xml to json. That’s just one feature. As you code policies with . NET Core in C# you got all the flexibility you want.  Performance: Caching let you improvement the performance of requests and make your clients happy.  Cost Management: There are different pricing options for Azure API Management. Hopefully, this gave you a somewhat overview of what APIM can do and what the platform has to offer. Now we’re going to dive deeper into the different tools and talk about some of the functions and advantages in detail. {% include articleAd. html %} Abstract your back-end implementation &amp; API documentation: Azure API Management supports several API formats. Let’s take a look: Azure API Management API Format Overview       Type   Details         Blank API   Create a blank API definition and then specify all required parameters.        OpenAPI   OpenAPI was called Swagger is a specification that document all endpoints and all parameters.        WADL   Web Application Description Language is a xml description of Http-based web services. It’ lighter that WSDL.        WSDL   Web Service Description Language is a xml description of any network type. WADL focuses only on http.        Logic App   Logic Apps orchestrate and automate workflows and integrations with many data sources.        App Service   APIs hosted in an App service.        Function App   Serverless code that can be triggered.    Azure API Management comes with a Developer Portal for you clients. It’s a web portal where API clients can learn about your APIs. It contains of the APIs that are deployed in your Azure API Management instance. The content is generated based on the APIs. You have the option to customize the developer portal and adjust the look and feel so it fits better to your organization. {% include articleAd. html %} System groups: APIM has 3 build-in groups:  Administrators: Members of this group are the Azure subscription administrators. The administrators can manage APIM service instances and create the APIs, operations, and products that are used by the developers.  Developers: Authenticated developer portal users are members of this group. Developers are the customers that build applications using your APIs. The developers can access the developer portal and build applications that call the operations of an API.  Guests: Unauthenticated developer portal users, such as prospective customers visiting the developer portal of an API Management instance are members of this group. They can be granted certain read-only access, such as the ability to view APIs but not call them. You are not limited to these 3 groups and can create your own custom groups or use existing groups in Azure Active Directory. APIM policies let you change the behavior of APIs. These are statements executed on the request or response. You can perform access management based on http headers. Authentication policies, cross-domain validations, and any other security measure can be checked before reaching your backends. Learn all details policies in Azure APIM. Data Manipulation: Azure API Management let you transform data like back and forth from xml to json. But APIM has a lot more features that can be used within policies. Take a look: Azure API Management Policy Snippets Monitor APIs: APIM provide metrics that may help to analyze backend calls, errors and performance by using Azure Monitor with diagnostic settings. Azure API Management Metrics {% include articleAd. html %} Cost Management: Azure API Management has 5 different pricing tiers to choose from:  Developer, Premium: The developer tier is great for developers that use the premium tier in production as both share the same features like vnet integration.  Basic, Standard: Both are production level tiers that go from entry-level production to medium-volume production.  Consumption: The serverless consumption tier lets you pay for what you use - 1M calls for free. It deploys within 2 minutes compared to the others of approx. 45 minutes so it’s great for testing out APIs. For production use it’s great as it has a built-in high availability and autoscaling. Switching between consumption and dedicated SKU tiers (Developer, Basic, Standard, and Premium) is not supported as this plan has not all the features as the rest. Take a look at Azure API Management Key Parameters for a more detailed overview of all tiers. Conclusion: Azure API Management is a great tool for unifying your backend API landscape, especially if you have them mixed in different Azure services like AKS, Functions and App Service but also if some are running still on-premise. "
    }, {
    "id": 29,
    "url": "/azure-apim-policy-debugging/",
    "title": "How To Debug Policies in Azure API Management. A Step-by-Step Guide.",
    "body": "2021/01/16 - In this post I want to briefly go through the Azure API Management extension for VSCode and how we can debug policies. It’s one of the questions I get a lot when holding workshops on APIM. How to effectively develop policies in Azure API Management. The post is a collection of screenshots that will explain in detail what you need to do step-by-step.  Install Extensions Testing Azure API Management Extension Setting Up a new API Debugging Policy Useful linksInstall Extensions: Before we start we need 2 VSCode extensions. The C# extension is useful for getting IntelliSense support for the VCCode Azure API Management extension. You get both by following the links under Useful links. VSCode extension for Azure API Management VSCode extension C# This is my configuration of the VCCode Azure API Management extension. I disabled Show Save Promp as it irritates me getting asked every time I save Are you sure you want to do this?. Configuring VSCode extension for Azure API Management Before I do anything I tried the VCCode Azure API Management extension first and look at all the commands that it gives me. This post focuses on policies, so I won’t need much of the rest. Commands overview So, I know that the extension is up and running and I check out its capabilities. {% include articleAd. html %} Testing Azure API Management Extension: I have already provisioned an instance of Azure API Management with Developer-SKU. The documentation says that debugging policies is supported only in this SKU. Select the Azure icon on the left side and choose the instance you want to play with. I will copy the master subscription key first because I know I will need it. This master-key is only for testing. Do never give it away since it allows access to all APIs. Copy Master Subscription Key Right-click on a GET endpoint of the one Echo API that is available and hit Test Operation. Then replace &lt;Subscription Key&gt; with the master- subscription key from the previous step. Then click on Send Request. It’s not very visible but you should find it :). Testing API The response is presented in a separate VSCode row. API Response in VSCode Setting Up a new API: I start by importing the public available Conference API with the help of the Azure API Management extension and select Import from OpenAPI link. Import API from URL into Azure API Management {% include articleAd. html %} Follow the steps 1-4 for importing an API from a URL. Step 5 is just to show you how it should look at the end. Import API from URL into Azure API Management 2 Click on the ConferenceAPI and change the value for subscriptionRequired from true to false. This way it’s easier to test. Setting Subscription Key requirement to false Debugging Policy: Now we can finally debug a policy. But first, let’s create/change the policy for the operation getTopics. I use this endpoint because it doesn’t require any parameters when sending a request. You can just write your policy now. In this example, I started by writing set-va and the extension will show you all the policies that start with this text. Click enter, and vóila, the code for set-variable is automatically inserted. I do the same with set-header. I set a variable iin the inbound-section that I will read in the outbound-section and set it as the value for the response header. Changing API Operation Policy in Azure API Management {% include articleAd. html %} I right-click on the operation and hit Test Operation and Send Request as I’ve done previously to make sure it works. Testing API Operation Policy Now I will again right-click on the operation I hit Start Policy Debugging and then Send Request. Start Debugging Policy in Azure API Management What happens in debug-mode now is that the request is being stopped at the top if the inbound-section. On the left side we can see all the information and data of the request. In the top we see the usual commands for debugging. I set a breakpoint at line 15+7=23. Hitting Breakpoint when Debugging Policy in Azure API Management {% include articleAd. html %} As we continue debugging by clicking on the Play-button, the request will stop at the next breakpoint. We can now see in the Variables-window our variable test. Variables in Debugging Policy in Azure API Management We have now seen how we can debug policies. This is of course a simple example with one policy. You can go on from here and implement your product-, api- and global- policies in a much simpler way than before. I really hop this post helped you a bit. Useful links:  API Management policies Azure API Management Extension for Visual Studio Code"
    }, {
    "id": 30,
    "url": "/it-culture/",
    "title": "People as the 1st Order Project Drivers",
    "body": "2021/01/14 - I’m very lucky, being a leader of an engineering team in a great Norwegian organization. The reason for that is simple. I can make things happen that are very important to me and where I have very strong opinions about, “Agile”. What does Agile even mean? In this blog post, I want to briefly discuss why I think Scrum and Kanban make us unhappy and slow us down, but also what’s important. The video below highlights some points of this post. {% include yt. html %} Why I dislike Scrum: “Scrum is a framework within which people can address complex adaptive problems, while productively and creatively delivering products of the highest possible value. ” What’s funny is that the explanation of Scrum uses the word people. To its defence, it also sets the focus on deliveries, not the people. One trait of Scrum is to time box a set of tasks, typically 2 weeks. That requires from us to spend time on estimating the tasks and then agree within the team to commit to them, meaning We get the tasks done no matter what. What we forget is that estimates are estimates, not facts. Estimating takes time, but it’s invested time. We make sure that everyone is onboard and understands the tasks. There are a few problems with this approach. People get bored locked up in a room for some hours and get surly not motivated by such process. When the time comes and One or Two developers want to work with a task, we need to deep dive again, a second time. The rest of the team doesn’t really care because they work on different tasks. {% include articleAd. html %} At the end of a 2 weeks sprint, we run a demo showing stakeholders and other teams what we have build. The key stakeholders have already seen everything by then in most cases. Also, many developers don’t feel comfortable speaking in front of people either. I didn’t. I didn’t like Scrum, especially those standup meetings in the morning where a team leader ask everyone 3 questions. What did you do yesterday, what are you going to do today, and do you have any problems where we can help you. This is poor leadership. Instead of giving everyone the feeling of being watched, we should prefer to show trust by being interested in the people and there work. Tasks are not important. The end goal is important. But the end goal can only be accomplished when everyone is happy and feels valued and being trusted. I run daily voluntary checkins. Everyone can talk but nobody needs to. As a leader, I know what’s important and I’m only interested in the status quo, not at this point. Kanban has similar challenges as Scrum: “Kanban aims to manage work by balancing demands with available capacity, and by improving the handling of system-level bottlenecks. ” I like Kanban better even though it doesn’t even mention people. As if they don’t exist. The idea is to shift prioritized tasks as fast as possible from the most left column to the right one, from Todo to Done. It implies that one column should not have too many tasks. In such a case we, the developers, need to focus our attention on those tasks. I once was in a team where the team leader made one of the developers responsible for watching the Kanban board and got the title “Work in Progress Guard”. The same day I decided to leave this company. {% include articleAd. html %} Developers, developers, developers: The following article is a good but very dry read. It highlights the people as the 1st order project drivers. No system and no methodology gets work done. Work gets only done by the developers and the people around, and work gets even faster done and in better quality when we like to work at your place and have meaningful work to do. The following 3 sections are extracted out of the great article Characterizing people as non-linear 1st order components in software development. Developers are Communicating Beings: Exhaustive written documentation is not engaging, and it is a poor communication medium. The writer must guess at the audience. There’s no feedback to the writer, and the writer does not get to use timing or emphatic signals, vocal or gestural inflections. For those who still think a book is best, consider the excellent but difficult book Design Patterns. Imagine that instead of trying to extract the meaning of the Decorator pattern from the paper, you could click on the page and see one of the authors explaining the pattern in a video clip. They would, of course, rely on tonal inflections, gestures, and timing to get the idea across. The same is true for the documentation we produced for building our complex systems. Developers Tend to Inconsistency: Lack of consistency is a common failure mode of us developers. Methodologies that require consistency of action are high-discipline methodologies. The thing is that we are struggling being consistent which implies consistent over a long time.  People that were interviewed on projects were asked what caused them to succeed in the end. The single most common answer was, “A few good people stepped in at key moments and did whatever was needed to get the job done. ” {% include articleAd. html %} Developers Are Not Static Elements: Some developers like to make lists, some don’t. Some work best nights, some work best in the morning. Some like deadlines, some don’t. Groups vary similarly. Some cultures prize public self-scrutiny, others shelter people from embarrassment, and so on. Methodologies are largely group coordination rules, and so a recommendation appropriate for one person or group will be rejected by another. What applies to a consensus-minded group might not apply to a culture in which people wait for the boss to make a pronouncement. Conclusion: {% include articleAd. html %} These are my experiences, and I totally understand that other developers have made different experiences. We are different, and that’s why there is no system that can fix everything. We are the 1st order, not systems. Useful Links:  Characterizing people as non-linear 1st order components in software development Driving Cultural Change Through Software Choices"
    }, {
    "id": 31,
    "url": "/reducing-it-costs/",
    "title": "8 Actions to Cut Infrastructure Costs in 2021",
    "body": "2021/01/10 - 8 Actions to Cut Infrastructure Costs in 2021 is the result of a research I did. I wanted to know more about the impact of the pandemic for IT organizations. What I found were discussions and ideas about the opportunities rather than the negative impacts. This post is a collection of actions and ideas that I have divided into 3 areas, reduce costs, optimize spending and increase value. Reduce Costs: An obvious opportunity is to focus on reducing the costs and to look at the spending. To do so, we need to know what we have and find out why. Then we can start o do something and action. Take Inventory: {% include articleAd. html %} I know from the past and my experience working in large organizations that it’s not always obvious what tools and services are in place across all departments. Neither is it always clear to everyone why a tool or service was bought in the first place and if it still fulfills the same requirements and serves the purpose it was intended to. Having a list of it and its owners is a great start before asking questions about the “Why”. Identify Tools: Knowing what tools and services you use in your organization is a first step in reducing costs. To give you an example when we once identified our tools and services within the CI/CD area. We saw that we used many different CI/CD tools across the entire organization, Azure DevOps, GitHub Actions, Jenkins and Atlassian Bamboo. Being aware of this will already give you some value because you’ll be able to have conversations about the “Why”. It might be obvious to those people working with the tools, but for the rest, the “Why” is probably unclear. Why is team A using Jenkins while team B uses Bamboo and team C uses Azure DevOps? What’s the history behind and does it make sense to migrate to one common solution with the goal to reduce costs like maintaining i. e. Jenkins or paying Atlassian. Examine Coverage: The second step in taking inventory is to examine the tools and to check if there is some overlapping. In the previous example about CI/CD tools it’s obvious that all 4 tools serve the same purpose. You need to examine how those features that aren’t covered by other tools can be overcome in case you decide to go for only One of CI/CD tool. The same is true for other areas as well like Monitoring tooling. Do you use Splunk, Kibana and Azure Log Analytics? Why? What are the reasons for that? Check Contracts: {% include articleAd. html %} It’s not always the case that departments work tightly together and sign contracts in cooperation. Often they do this on their own and operate independently. The downside is that different departments may sign similar contracts and pay twice the amount of what they actual need to. Knowing what you have and then combining vendor contracts from different departments is another way of reducing costs. In some cases you can consider to extend the length of a contract and reduce costs as well. In case of Microsoft Azure the developers themselves can take action and reserve instances of virtual machines for Azure Kubernetes Service (AKS) or reserve some capacity for Azure Cosmos DB for some time. This may save you up to 72% or more. Think Open Source: Open source technology also reduces costs, at least it will save you the initial costs that you have when signing licenses. There are other advantages as well as disadvantages depending on the project. Open source technology can be a good choice if you have the right people that know the technology well. Otherwise your savings can get very costly over time hiring consultants supporting you. Compared to open source, there are also open standards that are, typically, specifications. They may be formal descriptions of software or interfaces sometimes also reference implementations. Open standards do not just deliver savings, but they may help to improve the quality and efficiency. Open standards tries to ensure value-driven services and to maximize the cost efficiency of a solution. Adopt Cloud Native: The cloud is not a mirror of your old datacenter. The cloud wants to support you. A lift and shift of your old VMs doesn’t support you. The idea of the cloud is to manage infrastructure, and to take care of updates, security, and so much more. Adapting cloud native means to fully embrace the cloud and to give away some control so you have time to focus on your core business. Instead of running your services on a Kubernetes cluster that you maintain on your VMs, why not letting Azure take care of it by using Azure Kubernetes Service. That doesn’t mean you don’t have to do anything. Some cloud services will still need some attention of you. It always depends on the service and to what degree you want to give away control. {% include articleAd. html %} Optimize Spending: Once you know your inventory, it can be a good idea to ry to get he most out of it by automating repetitive tasks and learning from the data you get. Automate: The research and advisory company Gartner says that 53% invest today in automation for cost optimization. The reason for that is simple. Automation means doing repeatable tasks once. Automation means improved security. It means you got code that others can review and improve. Automation is a catalyst that drives consistent quality and business agility to deliver faster value, improve efficiency and optimize costs. Embrace AIOps: AIOps means artificial intelligence for IT operations. AIOps enhances IT operations such as monitoring and automation with insight that you can use to scale and adapt your infrastructure and operations and to reduce costs. Read about advancing Azure service quality with artificial intelligence: AIOps. Increase Value: Working smarter by focusing on the core business is another aspect to examine. Consider Outsourcing: You should spend most of your time within your domain where you are the expert. Nobody else can do your work as good as you anyway. Outsourcing can make sense for work where you are not the expert and that doesn’t define the purpose of your organization. It can also be a way to pay only for what you need in case you operate with a smaller budget. Furthermore, outsourcing may be good for creating new business relationships that can lead to something great in the future. Align business goals and engineering work: Service Level Objectives (SLOs) provide a common language between business and engineers to set aligned goals. You can think of an SLO as an SLA without contractual consequences. It expresses the service level of infrastructure and operations you need to achieve for keeping our customers happy. SLOs allow you to measure customer satisfaction, which impacts your business. The question then is which metrics to use as service-level indicators (SLIs) track user experience. A good start is to create an overview of user journeys and order them by business impact. Use a small number of alerts grounded in customer pain—i. e. , violation of SLOs. This lets you focus alerts on scenarios where you can confidently assert that customers are experiencing, or will soon experience, significant pain. Useful links:  Advancing Azure service quality with artificial intelligence: AIOps What are Azure Reservations?"
    }, {
    "id": 32,
    "url": "/azure-site-recovery-virtual-machines/",
    "title": "How to do a Failover of a Windows Server VM with Azure Site Recovery",
    "body": "2021/01/04 - In this post I will create a Windows Server 2016 Datacenter and then do an automatic failover to another region with Azure Site Recovery. Azure Site Recovery is part of the AZ-303 exam for becoming an Azure Solution Architect. {% include yt. html %} I have already created a Windows Server 2016 Datacenter in Azure. Checkout a previous post about how to Create a Windows Server 2016 Datacenter VM. After that we need the IIS Server. Here is how you can do this: Installing Internet Information Service (IIS). I will first make a minor change in the IIS Server so we are sure that we did a correct failover later. Open iisstart. html I make a minor text change and add ` - DR` in the title. Minor html change in IIS Server {% include articleAd. html %} I took the public IP address that we can see in the overview of the virtual machine. If you don’t have a public IP address, you can watch the Video about Azure Site Recovery where I will walk through this. Everything works fine. Testing changed IIS server Switch now over to the Azure portal and select your virtual machine. In the menu you’ll find Disaster Recovery where you can choose the target region. It’s the region that Azure will use to deploy a failover VM for you. Target region for failover of Azure Site Recovery Set your target settings. Target settings The Cache storage account is where the source VM data will be stored. Storage settings for Azure Site Recovery Replication Settings is where you tell Azure what Recovery Vault Service you would like to use. Replication Settings for Azure Site Recovery I also set Extension settings with an Azure Automation Account so the entire failover flow will be managed by Azure. Extension settings for Azure Site Recovery {% include articleAd. html %} Now when we take a look in the Backup Service Vault that we use, we see that an initial job for replication is in progress. Enable replication for Azure Site Recovery Enable replication for Azure Site Recovery takes time, in my case 25 minutes. I will now go over to my VM and initiate a test failover. Start test failover You will get asked to set the virtual network. Remember that we do a test failover and it might be a good idea to choose a different virtual network the current region. Test failover After some while, the test failover VM is ready to test. What’s still missing is a public IP address. Follow the Video about Azure Site Recovery where I will walk through this. VM with private IP address VM with public IP address Finally I test the failover VM with the new IP address. Test of failover VM Useful links:  Run a test failover (disaster recovery drill) to Azure Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 33,
    "url": "/azure-cli-update/",
    "title": "How To Automatically Update Azure CLI",
    "body": "2021/01/01 - Here is a brief introduction on how to keep the Azure CLI up to date on your local machine. I use the Azure CLI for 80% of all my interactions with Azure. I mean the portal is great but the CLI is awesome. The reason I keep the Azure CLI always up to date is for having always new features as we as all all bug fixes. The Azure command-line interface (Azure CLI) is a set of commands used to create and manage Azure resources. The Azure CLI is available across almost all Azure services and is designed to get you working quickly with Azure. {% include articleAd. html %} The Azure CLI is simple update and you can do this by opening a PowerShell or Bash script window and type the following command: az upgrade Instead of going this way you can also keep the CLI up to date without having to do this manually and regularly. Try this command instead and you never need to worry again: az config set auto-upgrade. enable=yes Ok, not 100% developer-friendly yet because you get asked if you are really sure that you want to update. That is annoying. Keep the Azure CLI up to date without EVER being prompted: az config set auto-upgrade. prompt=no That’s it. You no longer need to worry about latest updates of Azure CLI. Useful Links: Update the Azure CLI "
    }, {
    "id": 34,
    "url": "/azure-backup-service/",
    "title": "How to Recover a Virtual Machine with Azure Backup Service",
    "body": "2020/12/29 - This episode is about the Azure Backup Service, and how we can restore a virtual machine. I have already a Windows Server 2016 Datacenter VM created, so we will continue from there and create a file, run a backup, and then restore the file system. Azure Backup Service is part of the AZ-303 exam for becoming an Azure Solution Architect. {% include yt. html %} Make sure you have a Windows Server up and running. Go first into the overview of the VM and open the menu. You will find Backup there. Backup of VM in Azure Portal The first you will be asked is to provide a Recovery Service Vault. If you don’t have one, you can create it from here. When I did this, I had some issues later, and I had to create a new VM and use the Recovery Service Vault that I created before. The same happened to others as well, just so you know. Next, click on Create a new policy. Recovery Service Vault In this pane you can set up when you want Azure to take a backup of your VM, daily or weekly and what time. You can now specify the retention of backup points, weekly, monthly, or yearly. Backup Schedule of VM {% include articleAd. html %} Let’s now login to the Windows Server first. I got a public IP address, so I won’t use Azure Bastion as I usually do. Login to Windows Server VM I open the file explorer and create a text file that I name Test. My goal is to restore this file later after I have deleted it. Create file I have opened the Azure portal from within the Windows Server because we will soon install a tool that we will download from here. But first I clicked on Backup in the menu of the VM and hit on Backup now. Backup VM in Azure You will get asked for how long you need the backup. I stick to the default. Retention time of VM backup Just to show you that the backup is in progress. I clicked on View all jobs which you also find under the Backup-menu. View all jobs in VM backup We see that the backup is on its way. The backup took about an hour, and I didn’t install anything there, I just created a file. Backup of VM in progress Let’s now switch back to the Windows Server, and into the file explorer to delete the file I just created. We want to restore the file-system and see if we get the file back. Delete a text file in Windows I’m back in the portal, and ready for running a file recovery. File recovery in Azure {% include articleAd. html %} We get asked about what recovery point we would like to restore. As we just have one, the choice is easy. Then we click on Download Executable. This takes about a minute. It’s not only an executable we get, but also a password that we need to run the executable. Download executable for file recovery Once ready, we click on Download, and copy the password. Download, and copy the password The executable we reside in the Downloads-folder of the VM. Double-click to run. Run the installation Use now the password you copied. Proceed with installation A PowerShell window opens, and tell you to wait a moment. Once finished, we get two new drives. PowerShell runs the installation So, we got two drives. One is reserved for the installation process, and the other (G:) has the restored file-system which includes the file we created and deleted. File recovery mounted two new drives Useful links:  What is the Azure Backup service? An overview of Azure VM backup Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 35,
    "url": "/azure-friday-in-pictures-purview/",
    "title": "Azure Friday in Pictures &#35;1",
    "body": "2020/12/27 - [Source: Microsoft Azure] Azure Purview is a unified data governance service that helps you manage and govern your on-premises, multi-cloud, and software-as-a-service (SaaS) data. Gaurav Malhotra joins Scott Hanselman to show how easy it is to create a holistic, up-to-date map of your data landscape with automated data discovery, sensitive data classification, and end-to-end data lineage so that you can empower your data consumers to find valuable, trustworthy data. Watch Azure Purview on Azure Friday Azure Purview with Gaurav Malhotra: {% include articleAd. html %}{% include articleAd. html %}{% include articleAd. html %}{% include articleAd. html %}{% include articleAd. html %} {% include articleAd. html %} Useful links:  Azure Purview overview Azure Purview docs Azure Purview blog on Tech Community Azure Purview discussion on Tech Community"
    }, {
    "id": 36,
    "url": "/azure-vm/",
    "title": "How To Manage Azure Virtual Machines",
    "body": "2020/12/26 - I will go through the first steps for managing Virtual Machines. We will create a Windows VM, start the Internet Information Service IIS, attach a new disk, resize the vm, create new network interface, and finally create a new image from our custom VM. Managing Azure Virtual Machines is part of the AZ-303 exam for becoming an Azure Solution Architect. Watch AZ-303: Azure Virtual Machines Agenda:  Create a Windows Server 2016 Datacenter VM Installing Internet Information Service (IIS) Managing Disks Attach new Network Interface Changing the Size of a VM Custom Image Useful links{% include articleAd. html %} Create a Windows Server 2016 Datacenter VM: I will start by creating a Windows Server 2016 Datacenter VM … Creating Windows Server 2016 Datacenter VM … and setting some basic parameters, Resource group, Name, Availability options, and Image. I will stick to the default values where I can. Configuring VM The subnet get the default range of /24. I will also create a public IP address and keep the inbound RDP port 3389. Configuring VM 2 If you want you can ignore all the remaining settings and stick to the defaults. Click Create and waaaiiit. This will take some minutes. Once created, we will connect to it with RDP, download the file and click on it. If you are on a Mac you will need to install the Microsoft Remote Desktop application first. Connect to the Windows Server 2016 Datacenter VM Installing Internet Information Service (IIS): I will now install the Internet Information Service (IIS). You can do this with the Server Manager. {% include articleAd. html %} Start Server Manager Click on Add roles and features so we can add the Web Server IIS. Add roles and features Keep the selection Role- based or feature- based installation, and click Next. Installing Internet Information Service IIS Scroll down in the feature list and select Web Server (IIS), and click Next. Select Web Server (IIS) Confirm your selection by clicking Add Features, … Add Features … click Next … Continue Add Features … and finally Install. Install features The installation will take a minute. Close the window now. Close installation of IIS You find the public IP address in the overview of the virtual machine. Use this IP address and try it out with your browser. You shouldn’t be able to access the IIS on port 80 yet, because we didn’t tell Azure yet to allow traffic through this port. Failed IIS test We will now open port 80 by navigating to Networking in the virtual machine. We can see here that we allow traffic on port 3389, so we can login, but we can’t see port 80. Click on Add inbound port rule. {% include articleAd. html %} Inbound port rules of VM {% include articleAd. html %} Set as Source Service Tag and as Source service tag Internet. This means that the traffic can come from outside the VNet. The destination port that we allow for this virtual machine is port 80. Configure inbound port rule Now, let’s test the public IP address from our browser again, and you should be allowed to access the IIS on port 80. Accessing IIS Managing Disks: When we create a virtual machine, we get two disks, one for the Operating System (C:), and one temporary disk (D:). The temporary disk is really what its name suggests. Once we stop the VM, the disks get deallocated. When we start the VM again, we get a fresh (D:)-disk and whatever we have stored there is gone. VM with OS- and temp- disk Let’s add another disk and attach it to our virtual machine by navigating to Disks for the VM, and click on Create and attach a new disk. Choose a name, Storage type, and Size. Create and attach a new disk Now, switch back to the VM and inform the OS about the new disk as well. Click on File and Storage Services in Server Manager, … File and Storage Services … select Disks, … Adding disk 1 … right-click on the new disk and select Initialize. Initialize new disk Right-click once again and chose New Volume…. Create new volume {% include articleAd. html %} Almost done. Click Next, … Add new disk … … and choose a drive letter that you want to use. I stick to F. Choose drive letter for new volume Name your new volume. I forgot this and kept New Volume. Name new volume The new volume will be set up now. This process takes about a minute or two. Finally click Close. Processing creation of new volume Check now in the Explorer if the new drive letter F was added. Added new drive Attach new Network Interface: When creating virtual machine, you get one network interface. In some use cases, you will want another network interface for different clients with different network security rules. I will demonstrate now how to add a new network interface. Create and attach network interface Choose a name and. The subnet will already be set to the one where your VM is running in. We let the network security section as is. Configure new network interface Vóila, the new network interface was created and attached to your VM. VM with two network interfaces {% include articleAd. html %} Changing the Size of a VM: In the menu of your virtual machine, select Size. Make sure you have stopped the VM first. Otherwise you won’t be able to re-size the VM. Change VM size When you stopped the VM, you will get some more sizes to choose from. Select a size … Select a VM size … and click on Resize. Resize VM You have now changed the size of your VM, and you can start it again. Notice: Whenever you restart the VM, the temporary disk will be re-allocated. Custom Image: Let’s just say that our virtual machine is set up, and we now want to spin up some more of it. Remember that we installed teh Internet Information Service (IIS) on it. We open the tool System Preparation Tool that is located under C:\Windows\System32. We select Generalize which will ensure that users and other custom configurations will be ignored. We will also select Shutdown. System Preparation Tool In the portal, we also click on Stop to de-allocate the disks. In case you haven’t set a static IP address, but kept the dynamic IP address (default), you will also get a new IP address. If you want to keep the IP address that you have now, you can switch from dynamic to static by clicking the checkbox. Remember that you will be charged for a public IP address in use. Stop VM {% include articleAd. html %} Now we click on Capture. Capture VM For the purpose of this demo, and for the AZ-303 exam, select No, capture only a managed image. Finally, set a name for your custom image and click on Create. Capture only a managed image We can now create a VM from our custom image. What we will get is a Windows Server 2016 Datacenter with the IIS already running. Custom image Click on Create … Create VM from custom image … and fill out the other parameters as briefly described in the top of this AZ-303 preparation. Configure VM Once the new VM was created, we can access it from anywhere with the public IP address that you can find in the overview for this VM. As you can see, without installing the IIS first, we can access it directly. Testing IIS on custom VM Useful links:  Quickstart: Create a Windows virtual machine in the Azure portal Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 37,
    "url": "/azure-service-endpoints/",
    "title": "How to configure Azure Storage Accounts to Allow Access from Specific Subnets",
    "body": "2020/12/25 - Sometimes we store items in a storage account and want to restrict the access to certain services or clients. I will demonstrate how to restrict the access to a subnet where a Windows Server 2016 Datacenter VM is running. Service Endpoints in Azure is part of the AZ-303 exam for becoming an Azure Solution Architect. Watch Service Endpoints in Azure in preparation for the AZ-303 exam When we create an Azure Storage Account, and store items there, we can access them by using the URL that is provided to us. The traffic is then going over the internet. If we want to restrict the access to certain clients, we can route the traffic over the Azure backbone by using a service connection. It’s more secure and less latency. Diagram of Service Endpoints in Azure In preparation to this step-by-step guide, I already provisioned a few resources that we will need.  Storage Account with container and an image Windows Server 2016 Datacenter Virtual Machine in VNet/subnet Azure Bastion and Public IP addressService Endpoint Resource Overview As you can see I have one image stored in the storage account. Content of container in Azure Storage Account {% include articleAd. html %} To show you that the traffic is going over the internet for now, I create an URL with a SAS token as the containers access level is private per default. Create URL with SAS token for item in container in Azure Storage Account When pasting the URL into the browser of my workstation, you can see that it’s perfectly accessible. Accessing item in container in Azure Storage Account from workstation I’m now going to select Service endpoints in the virtual network of the Windows Server 2016 Datacenter VM. Service endpoints menu in virtual network Click on Add to create a service endpoint and select the service Microsoft Storage and the subnet of the Windows Server 2016 Datacenter VM. Adding a service endpoint to subnet After creating the service endpoint for the subnet, you should see an entry in the overview of Service Endpoints. Overview of Service Endpoints We head now over to the storage account, and select Networking. As you see, there is no virtual network selected for now which means that the content isn’t restricted to a location yet. To change this we select networks. Starting restricting access to networks Now we can click on Add existing virtual network and select the subnet in which the VM is we would like to give access. Restricting access to subnet for Azure Storage Account As we now have restricted the access to the Windows Server 2016 Datacenter VM, I am not longer allowed to access the content of the storage account from my own workstation. No access to Azure Storage Account I use Azure Bastion to login to the Windows Server 2016 Datacenter VM. Login to VM with Azure Bastion {% include articleAd. html %} Vóila. We have access from the subnet where this VM is provisioned to. Access to Azure Storage Account Useful links:  Configure Azure Storage firewalls and virtual networks Virtual Network service endpoints Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 38,
    "url": "/azure-custom-routes/",
    "title": "How to Create Custom Routes in Azure",
    "body": "2020/12/24 - Custom Routes, or user defined routing, is part of the az-303 certification for becoming an Azure Solution Architect. In this video I tell why you would want a custom route, and then demonstrate how to create one based on a use case. Watch Azure Custom Routes in preparation for the AZ-303 exam Pre-provisioned setup: {% include articleAd. html %} I have provisioned a virtual network with the default IP address range 10. 0. 0. 0/16. Within this range I created 4 subnets, subnetA, subnetB, subnetC, and AzureBastionSubnet, all with a small IP address range of /29. Azure Bastion needs at least a range of /27, and we use it to login to the virtual machines that I created inside the subnets. All VMs are of the same type Windows Server 2016 Datacenter. On the virtual machine that I named c-vm, I installed the Internet Information Service IIS. Pre setup of custom routes Use Case: Here’s want we can do, but probably shouldn’t be allowed to. We send a GET request from a-vm to c-vm to access the IIS directly on port 80. Connection from a-vm to c-vm {% include articleAd. html %} Imagine that we have to protect the workload or data that is running on c-vm. Every package that is going into this virtual machine can potentially be harmful and damage what’s stored there. If we can’t trust a-vm, maybe it’s a better idea to not access c-vm directly. a-vm sending harmful packages to c-vm What we can do instead is to inspect the traffic to another virtual machine b-vm that c-vm trusts. This b-vm can run software that checks all incoming traffic before forwarding it to c-vm. Using another VM to inspect packages The virtual machine a-vm will still send its traffic to c-vm. To be able to get b-vm inspect the traffic, we will re-route the traffic coming from subnetA where the VM a-vm is running, to b-vm that can do its work before forwarding all packages to c-vm. To keep it simple, we will let b-vm forward all traffic to c-vm without inspecting the packages first. We will create a route table with a route that applies for the traffic within subnetA, subnetB, and subnetC. Bastion can’t be part of this route. Otherwise we couldn’t use it as a jump host anymore. Diagram for Azure Route Table Demo: To demonstrate that we can (for now) access the IIS that is running on c-vm, I used Azure Bastion to login to a-vm, and send a request to the private IP address of c-vm. This works fine as expected as we haven’t done anything yet. Accessing IIS from a-vm {% include articleAd. html %} I will now re-route the traffic to go through b-vm by first creating an Azure Route table. Create Azure Route table The only parameters we need to set here is the resource group, region, and a name. Then we click on Create. Configure Azure Route table We can now create a route which needs an Address prefix. It’s the IP address range for that the route will apply to. In our case we set 10. 0. 1. 0/27 which includes all the subnets except the one for Bastion. Configuring a route 1 As Next hop address, we set the private IP address of b-vm. Configuring a route 2 After we have created a route, we should see it in the route table. {% include articleAd. html %} Route table with one route Right now we have created a route table and a route. What’s left is to associate the route to subnet subnetA where the VM a-vm is running. Associate subnet to route If we would test again, we wouldn’t be able to access c-vm from a-vm because we haven’t told b-vm what to do yet. The VM b-vm shall forward all traffic to the IP address that was originally requested from the client, in our case a-vm. We do this in the IP configurations of the VM b-vm. Forward traffic in IP configurations All is set now, and we can try to send a request again from a-vm to c-vm. The traffic is now going through b-vm. Sending a request vi b-vm Useful links:  Virtual network traffic routing Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 39,
    "url": "/azure-vnet-peering/",
    "title": "How to Peer Virtual Networks in Azure",
    "body": "2020/12/23 - When we have two services running in two different virtual networks, they cannot communicate. To fix this, both VNet’s have to be peered. Virtual Network Peering is part of the AZ-303 exam for becoming an Azure Solution Architect. Watch Virtual Network Peering in Azure in preparation for the AZ-303 exam Virtual network peering is also possible across subscriptions and tenants. In this post I will focus on VNet’s that are in the same subscription as this is part of the AZ-303 exam. {% include articleAd. html %} Use case: I provisioned two virtual networks with two subnets and two virtual machines of type Windows Server 2016 Datacenter. Both VMs have only a private IP address. The one VM vm2 has the Internet Information Service (IIS) up and running. When we now would login to vm1, and try to send a request to vm2 on port 80, we will get disappointed. vm1 doesn’t know about the other network. We’ll try this out in a minute. vm1 sends request to another network to vm2 What we need to do is to peer both virtual networks witch each other. In this case we can do this easily, and I will show you soon how. We can peer the networks because they have different IP address ranges and don’t overlap. That’s very important. Virtual network peering is only possible when the IP address ranges don’t overlap. Diagram of VNet peering Let’s now set the scene first. Preparation: I have already created two virtual networks with two subnets and two virtual machines of type Windows Server 2016 Datacenter as shown in the resource overview. Resource overview I want to show you first that both networks don’t know about each other at this point. We take a look at the IP address of vm2 where the IIS is running, so we can test it from vm1. Virtual machine overview I login to vm1 and try the private IP address of vm2 in a browser. The result we get back is NOTHING as vm1 doesn’t know the other address. Try accessing VM from another network failed {% include articleAd. html %} Peering: To peer virtual networks, click on one of them … VNet overview … and select Peerings VNet peering Click on Add to configure and create a peering between two Azure virtual networks. Add Azure virtual networks Peering of two networks has two sides that we will name. I named the side where vm1 is as 1and2, stupid name I know - it’s just a name for the purpose of this demo :) Naming one side of VNet peering We scroll down a bit and name the other side 2and1, and set the other virtual network to vnet2. After clicking Create Azure will create resources in both virtual networks. Setting the other side of Vet peering As we can see is vnet1 now connected to vnet2. VNet peering overview of vnet1 {% include articleAd. html %} Taking a look on the other side as well we see that vnet2 is connected to vnet1. VNet peering overview of vnet2 Test: Finally, we can repeat the test from the beginning by sending a request from vm1 to vm2 where the IIS is running. Accessing VM from another network succeeded Useful links:  Virtual network peering Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 40,
    "url": "/azure-bastion/",
    "title": "How to Use Azure Bastion as a Jump Host",
    "body": "2020/12/20 - Knowing about Azure Bastion is part of the AZ-303 exam for becoming an Azure Solution Architect. Bastion is very useful in cases where you would normally spin up a jump host towards a Virtual Machine that you want to maintain. Using Azure Bastion means you won’t need to maintain a separate virtual machine (Jump Hos). Watch how to use Azure Bastion in preparation for the AZ-303 exam Before we look into Azure Bastion, we need a virtual network. Let’s create one. Creating a VNet The VNet comes already with a pre-defined subnet that we can change if we want to. As it’s not important for this demonstration, I leave it as is. Default subnet of an Azure Virtual Network {% include articleAd. html %} If we head over to the Security-tab, we can see (1) BastionHost. We need to enable it. The address range must be at least /27. I stick to the default for this demonstration. Azure Bastion needs also a public IP address, so we can connect to it from outside our virtual network. Configuring Virtual Network After we have created the VNet, we take a look at the subnets, and we can see that we got two. The default-subnet and one for Azure Bastion. This name of this subnet must be AzureBastionSubnet. This is important to remember in case where you set up a subnet for Azure Bastion manually. Azure Bastion Subnet Let’s now create a virtual machine within the default-subnet that we want to login to from Azure Bastion. I chose the Windows Server 2016 Datacenter, but you can choose Ubuntu or any other type if you want to. Create Windows Server 2016 Datacenter VM We need the RDP (Remote Desktop Protocol) port 3389. It’s the port for connecting to the machine. This entry will be opened in the Network Security Group (NSG), which is another Azure resource. We’ll take a look at it later, and change it a bit. NSG rules act like a firewall. Configuring RDP port Then, we select the Network-tab where we set the Public IP to None. We don’t want our VM to be open for everyone. We will also stick to the defaults for the NSG, and re-configuring it later. Configuring the VM Now as everything is in place, let’s take a look at the resources that got created.  Azure Bastion as our jump host Public IP address for Azure Bastion Windows Server 2016 Datacenter VM Network Security Group (NSG) Network Interface OS Disk for the Virtual Machine Virtual Network (VNet)Overview of all created Azure resources {% include articleAd. html %} We won’t use this resource directly to connect to our VM. First, we take a look at the NSG resource devreal-vm-nsg which is connected directly to the VM. NSGs can be connected to subnets as well. Overview of all created Azure resources 2 The VM allows traffic on port 3389 as we already know. The insecure setting now is that the VM allows packages from any source. To be more secure we should be more specific. Security is important and the reason why we set up Azure Bastion in the first place. NSG overwiew As the source we allow the IP addresses range of the AzureBastionSubnet-subnet. Configuring NSG source As the destination, we set the IP address and the port of our VM. Configuring NSG destination Here’s a better overview of what we have just configured. Overview of changed NSG rule Finally, we can connect to our VM. Click into the Virtual Machine and click on Connect. Then choose Bastion … give it your credentials that you have set when configuring the VM … Set credentials for VM {% include articleAd. html %} … and vóila, you have logged in to your Windows Server 2016 Datacenter VM without using a public IP address of the VM, but with Azure Bastion. Logged in to Windows Server 2016 Datacenter VM Useful links:  Azure Bastion Docs Exam AZ-303: Microsoft Azure Architect Technologies"
    }, {
    "id": 41,
    "url": "/azure-point-to-site-connection/",
    "title": "How to Establish a VPN Point to Site Connection in Azure",
    "body": "2020/12/17 - I will demonstrate how to establish a point to site connection in Azure, and connect from a Windows workstation to a virtual machine via its private IP address. Azure Point to Site Connection is part of the AZ-303 exam for becoming an Azure Solution Architect. Watch Azure Point to Site Connection in preparation for the AZ-303 exam Sometimes we need to have our workload running on a virtual machine with no public IP address. At the same time we want to connect to it from our workstation. In the picture below I created already a Windows 10 Client workstation in the West Europe region. In the Central US region I created a virtual network with another vm, Windows Server 2016 Datacenter. I did not assign a public IP address to it, so it has only a private IP address. I also installed the Internet Information Server (IIS) on it. Right now it’s only accessible from localhost and within this virtual network. {% include articleAd. html %} Pre-provisioned Azure resources Our goal is to create what’s described below.  Create a subnet gateway. The name SubnetGateway is important as it will be recognized as such of the virtual network gateway in the next step.  Create the virtual network gateway.  Generate the root certificate and client certificate.  Setup the point to site connection with the root certificate.  Establish a connection from the client workstation to the server. Architecture for point to site VPN connection We start by adding the subnet gateway. You find it under Subnets within your VNet. The name GatewaySubnet is important, and you can’t change it. I leave the address range as it but feel free to give it a smaller range i. e. /27. Creating Subnet Gateway Now that we have the subnet gateway in place, we can create a virtual network gateway. Create Virtual Network Gateway We set the gateway type as VPN, and the VPN type as Route-based. The subnet is set automatically to your subnet gateway. That’s why the name is important. Azure Virtual Network Configuration If we scroll down a bit a must not forget to name a public IP address that we need for establishing a VPN connection. We won’t use it directly for accessing the IIS. Azure Virtual Network Configuration Public IP address Now we need to create some certificates. First we need a root certificate. Your organization may already have one. Out of this root certificate, we create a client certificate that we need to have on the workstation. {% include articleAd. html %} First, login to the client workstation and open Powershell. Run the first command for the root certificate. $cert = New-SelfSignedCertificate -Type Custom -KeySpec Signature -Subject  CN=RootCertificate  -KeyExportPolicy Exportable -HashAlgorithm sha256 -KeyLength 2048 -CertStoreLocation  Cert:\CurrentUser\My  -KeyUsageProperty Sign -KeyUsage CertSignThen run the following command for creating the client certificate out of the root certificate. New-SelfSignedCertificate -Type Custom -DnsName P2SChildCert -KeySpec Signature -Subject  CN=ClientCertificate  -KeyExportPolicy Exportable -HashAlgorithm sha256 -KeyLength 2048 -CertStoreLocation  Cert:\CurrentUser\My  -Signer $certYou can see the result below. Creating self-signed certificates with PowerShell Search now for rootcert and right-click on it to open it with Notepad or any other text editor. Search for rootcert Read root certificate with Notepad Select the content of the root certificate so you can copy it. Copy content of root certificate We head back in to the Azure portal and to the virtual network gateway. In the menu is the Point to Site Connection that we will open. The Point to Site Connection will represent your workstation. Set the address pool of it and then the tunnel type IKEv2 and SSTP (SSL). Then, we set the value of our root certificate as shown below. Last, we download the VPN client on to our client workstation. I simply logged in to Azure from the client workstation and downloaded the VPN client from there. Configuring Point to Site Connection Extract the downloaded file and run it. It will install the VPN client on the workstation. Install VPN client Search for VPN settings and open it. VPN settings Now we can connect to the virtual network of the server. {% include articleAd. html %} Connect to virtual network I checked the private IP address of the virtual machine running the IIS, 10. 0. 0. 4. We open a browser, and vóila. We can access the IIS from our client workstation with a private IP address. Access IIS with private IP address Useful links:  Exam AZ-303: Microsoft Azure Architect Technologies About Point-to-Site VPN"
    }, {
    "id": 42,
    "url": "/azure-apim-at-norway/",
    "title": "Azure API Management at Norway",
    "body": "2020/12/10 - How are Norwegian companies like Vipps, SATS, Orkla, Statsbygg, and DNV GL using Azure API Management? What experiences do they have, and what do they think about the service? I wanted to know more, and organized an event with developers that use this service. In addition to that I invited the product manager for API Management Mioa Jiang to answer questions, but also to tell us about cool and new features {% include articleAd. html %} This event was split into 3 sections. In the first section the speakers told briefly about their experiences with APIM. In the second section we had Miao Jiang from Microsoft who told about what they were doing in the product team to help and support us developers. In the third section we had a short tech conversation where we asked questions like: “Why do we code policies in XML and C#”. If you want to know why, head over to the full episode of: Watch this DEVREAL episode on YouTube: Azure API Management at Norway {% include articleAd. html %} DEVREAL means Real Developers, Real Experiences: This event was a real success. 90 minutes, 8 speakers, and a lot of great insights from companies using Azure API Management, and from Microsoft. I got messages, comments, and direct feedback the days after, and everyone loved this so different format. Instead of having long sessions, we had short ones. Instead of talking about different services, we talked about the same one. Instead of pretending all speakers are experts, we focused on experiences and what we maybe didn’t do so well. Our one expert was the product manager of Azure API Management, and we could ask him questions, what we did. Nest Step: We will definitely continue in 2021 with more services, and more topics. If you have any suggestions, let me know. "
    }, {
    "id": 43,
    "url": "/azure-mvp/",
    "title": "How I became a Microsoft Azure MVP",
    "body": "2020/12/03 - I’ve always been amazed by public speakers. The confidence, calmness, and energy that some of them transfer over to the audience has always impressed me. Standing in front of 100 people and then pretend that it’s somehow normal, is a skill I wanted to learn for a very long time. I’m heading in the right direction. The MVP award confirmed it to me. The way that is behind me- was very bumpy. My journey started by the end of 2018. Microsoft Norway asked us in Vipps to talk about our work with Azure API Management. They wanted us to get on stage at Microsoft Build 2019. Even though I was scared to death, my immediate response was: “YES, of course!!!”. MS Build is with its over 30k participants one of the larges tech conferences in the world, held in Seattle. I committed, created my presentation, and performed on stage. I loved it. First thing I did when I came back home to Norway, was to create a local community where I can talk when I want about whatever I want. I created the Azure Cognitive Services User Group Norway. {% include articleAd. html %} First Nomination: Some months in to my community, I gave talks about QnA-Maker, and API Management. I also invited guest speakers so the community could grow. But I wasn’t very happy with it. My daily work was about infrastructure, not AI. Then, Microsoft Norway Community Lead Maxim Salnikov approached me and said that he will nominate me for the Microsoft MVP award. At that time I didn’t know what it was until I looked it up. That was big. My first reaction, WoW, very cool, and very nice. Of course I got motivated to keep my community going and growing, and it did. 3 month later, I was rejected. Naturally, I was a bit disappointed. Maxim advised me to keep going. We’ll try again. He later told me that my contributions were a bit too diversified. Azure API Management and AI doesn’t fit well together, and my contributions were not many back then. Well, I understood that, and I decided to keep going. Anyway, my goal was never to become a MVP. I wanted to become a confident, calm, and energetic speaker, so I continued. Second Nomination: The first change I made was to rename my community to Azure Meetup Oslo, nice and crispy. Now I could talk about anything that I was doing at work every day. It made it so much easier for me. Until Maxim nominated me again, I presented at conferences, various Norwegian User Groups, and I started this blog. I even posted some YouTube videos. I had more speaking engagements than ever, and I contributed more than I though I could handle. I got rejected, for the second time. At that point I was asking myself, what the heck. Why am I so focused on this award. It’s just an award. I was almmost giving up, all the time and effort I put into it, for nothing. When I got reasonable again, I was back on track again. I was not doing this for the award or anybody else. What I wanted was to become a confident, calm, and energetic speaker, so I continued, again. {% include articleAd. html %} Third Nomination: Maxim, me, and Tina (Community Pragram Manager Nordics &amp; Benelux) were having a meeting to find out what I was doing wrong. The outcome was that nothing really was wrong. What I heard between the lines was this: Seattle felt that I was doing this for the award itself, and they were right. I was doing it for the award itself. The MVP award is cool. Why shouldn’t I have this as a goal, so I kept going the same way, with just a little change. I tenfold my efforts. As my community grew, I created one more in New York and one more in Mumbai, so I could give one talk in the middle of the in Oslo, in the morning in New York, and in the evening in Mumbai. I asked Meetup organizers in the world to let me speak, and they did, what I am very grateful for. In addition to my speaking engagements, I blogged and created more YouTube content, created some pull requests in the Azure documentation, and I tok every opportunity to help the Azure community. I was and I am 100% committed to Azure. MVP: On December 1th I got this fantastic mail saying: “Congratulations 2020 - 2021 Microsoft MVP!”. I finally became a Microsoft Azure MVP, and I’m super happy. The best thing, I learned some valuable lessons. But first, chasing this award made me a lot better at work. I got totally passionate about Azure and infrastructure. {% include articleAd. html %} When Things Get Tough, 10X Your Efforts: This is what I learned. Do not chase a nearby goal, like becoming a MVP. Chase goals that you think you can’t reach, like becoming the worlds best public speaker, or travelling to Mars. To get there, you need to work harder than anybody else. Even though you probably never will reach your ultimate goal, you will come very far. Instead of watching television, work. Either way, the three letters that helped me the most: 10X. I will continue as before, just a lot more. "
    }, {
    "id": 44,
    "url": "/azure-pulumistack-in-bash/",
    "title": "Pulumi Stack Name in Bash Prompt",
    "body": "2020/10/31 - This post describes how we can add custom information to a bash prompt. Instead of using features for interacting with GitHub, Azure and my file system from within an IDE, I prefer to use my tools from a terminal. This approach forces me to learn, to understand, and to remember how a tool works. I also want to have certain information visible at all time. Examples are the branch name of a Git project, and the stack name of a Pulumi project. The script below adds those two information to the bash prompt. Put it in the . bashrc or . bash_profile and restart the terminal or read the file with source . bashrc. {% include articleAd. html %} # We use tput to define colors_GREEN=$(tput setaf 2)_YELLOW=$(tput setaf 3)_BLUE=$(tput setaf 4)_RED=$(tput setaf 1)_RESET=$(tput sgr0)_BOLD=$(tput bold)# Print stack namepulumiinfo() {    FILE=. /Pulumi. yaml    output=      if [ -f  $FILE  ]; then        output= (p. $(pulumi stack --show-name))     fi    echo $output}# Print git branchgitinfo() {    output=      if [ -d  . git  ]; then         output= (g. $(git rev-parse --abbrev-ref HEAD))     fi    echo $output}# Set custom bash promptexport PS1='${_BLUE}\w ${_RED}$(gitinfo)${_YELLOW}$(pulumiinfo) ${_GREEN} ${_BOLD}$ ${_RESET}'{% include articleAd. html %} Next steps: The problem here might be for some that it doesn’t print any information if we aren’t in the root directory of a Git or Pulumi project. Personally, I want to be reminded of that I’m not in the root directory, so this is fine for me. In addition we print some empty characters in cases where we don’t have any additional information. This is all details that can be implemented as well. "
    }, {
    "id": 45,
    "url": "/azure-iac-at-vipps/",
    "title": "Infrastructure as Code (IaC) in Azure",
    "body": "2020/10/17 - Infrastructure as code (IaC) is a hot topic, also at Vipps. This video is the recording of an internal event where development teams tell about their experiences with different technologies to deploy to Microsoft Azure. The video dives also into some newcomers like Pulumi, Farmer, and Bicep. Watch the full episode: Infrastructure as Code (IaC) in Azure. Learnings from Vipps Two years ago, we worked from this office that you can see in the picture above. We started with Azure from there. Most of our interactions with Azure at that time were right from the Portal which is a great tool for testing, and learning, and getting started. That’s what we did two years ago. We created resources more randomly than structured because we tested, and we learned, and we started Our journey with Azure. {% include articleAd. html %} However, the problems with this so-called ClickOps approach and not having infrastructure as code are many. For example, ClickOps gives us no history about previous changes. We cannot review changes before they are in production, and we can’t repeat deployments several times, so we will end up with slightly different environments in test and production. Infrastructure as code is also necessary because it gives us documentation. We need to know what we have deployed and we need to know how we configured our resources that we have deployed in a very structured way. It’s necessary because it’s required from us working in the finance industry. ClickOps was two years ago. Everything has changed since then. We all know now that infrastructure as code is The only way for the future as we can imagine it today. {% include articleAd. html %} Today, a few teams deploy their Azure resources with ARM, some by using APIs, and others by using tools that uses ARM or APIs. To put it differently, our teams deal with infrastructure in different ways- and there are good reasons for that. This video discusses those reasons. We created 5 small sessions for you. Each session is dedicated to one team and takes about 10 minutes. At the end of all sessions we have a short discussion on infrastructure as code in general. "
    }, {
    "id": 46,
    "url": "/azure-farmer-parameters/",
    "title": "Parameters in Farmer - IaC with Azure",
    "body": "2020/10/10 - This is part 2 of my learning adventure of Farmer for Azure resource deployments. This time, I wanted to look at parameters, variables, outputs and expressions. Passing Outputs to another Resource: I created a Web App with a dependency to a storage account. As shown below, the storage key kan simply be passed to the web application. let sa = storageAccount {  name  demo-sma75-sa }let webAppConfig = webApp {  name  demo-webapp   setting  storageKey  sa. Key}The generated ARM template shows us the storage key.  appSettings : [  {     name :  storageKey ,     value :  [concat('DefaultEndpointsProtocol=https;AccountName=demosma75sa;AccountKey=', listKeys('demosma75sa', '2017-10-01'). keys[0]. value)]   },Farmer knows that the Web Application needs to be deployed before the storage account, so we don’t need to explicitly declare this. However, you can specify this explicitly with depends_on. let webAppConfig = webApp {  name  demo-webapp   setting  storageKey  sa. Key  depends_on [ sa ]}depends_on [ sa ] gave me this error message. /Users/sma/git/farmer-demo1/Program. fs(12,5): error FS0041: No overloads match for method 'DependsOn'. Known types of arguments: WebAppConfig * StorageAccountConfig listAvailable overloads: - member WebAppBuilder. DependsOn : state:WebAppConfig * builder:CoreTypes. IBuilder -&gt; WebAppConfig // Argument 'builder' doesn't match - member WebAppBuilder. DependsOn : state:WebAppConfig * resource:CoreTypes. IArmResource -&gt; WebAppConfig // Argument 'resource' doesn't match - member WebAppBuilder. DependsOn : state:WebAppConfig * resourceName:CoreTypes. ResourceName -&gt; WebAppConfig // Argument 'resourceName' doesn't match [/Users/sma/git/farmer-demo1/FarmerApp. fsproj]I do not know F# yet, so this error might be obvious for others, but I have an idea how to solve this (part of a later post). For me it was just painful because my example is directly from the documentation. {% include articleAd. html %} Anyway, the storage key was successfully set under Application Settings. App Service setting with storage key Looking at the API for Web App we see all the configurations we can and have to set if we want to understand what happens and gets created. I. e. can we set app_insights_off to avoid creating an instance for us. Created Azure resources with Farmer for default WebApp No Support for Variables and Parameters: Farmer doesn’t support ARM variables or parameters. The reasons for that are:  Codebase gets more complex API surface area gets more complex Expressions capabilities inside ARM templates like concat inside a variable that depends on another variable - hard to do without increasing the complexityThe Farmer developers recommend to put Farmer as part of a build script to generate ARM templates, rather than committing into source control.  Simplifies the code base Instead of using the error prone and limited expression capabilities of ARM templates, you can use a proper programming language for conditional logic for creating the ARM template Deployments e. g. inside the Azure Portal are much easier to read because there are no placeholders or variables but just valuesHere’s the code for entire application open Farmeropen Farmer. Buildersopen Systemlet createWebApp theLocation =  let sa = storageAccount {    name  demo-sma-sa   }  let webapp = webApp {    name  demo-sma75-webapp     app_insights_off    setting  storageKey  sa. Key  }  arm {    // Our location we set previously    location theLocation    add_resource sa    add_resource webapp  }createWebApp Location. WestEurope|&gt; Deploy. execute  farmer-rg  Deploy. NoParametersNext Steps: This example was pretty basic, but it might show that we can pass parameters as input values and all created resources get the location set with the actual value rather then a reference. What interests me next is how I can deploy Azure App Configuration or Azure API Management with Farmer. Those resources are not part of Farmer yet. "
    }, {
    "id": 47,
    "url": "/azure-first-farmer-project/",
    "title": "Introduction to Farmer - IaC with Azure",
    "body": "2020/09/26 - As many companies move their services to the cloud, the way we interact with the cloud, the tooling, becomes more important. In Azure we are used to deploy with the Azure CLI, REST API, or with ARM. Then came Terraform which abstracted away a lot of the complexity that comes with ARM. A very new member of the Infrastructure asd Code (IaC) family is Farmer. This blog post the first one of a series of Farmer blog post where I will show how to install it and get started. I also will talk briefly about Azure DevOps integration. Basics: Farmer needs . NET Core 3. 1 or higher in order to work. I tried at first to use the Azure Cloud Shell, but I wasn’t able to execute my program with dotnet run at the end because the version was lower 3. 1. You will also need to have Azure CLI installed on your machine so that Farmer can perform deployments for you. Before we start, I like to make sure that I’m logged into the right Azure tenant and the right subscription. I don’t want to make the mistake of deploying to production. I test this with az account show. {% include articleAd. html %} To get started I executed the following statements: mkdir farmer-demo1; cd farmer-demo1dotnet new -i Farmer. Templatedotnet new Farmerdotnet runThis will create a basic Farmer application that writes an ARM template to output. json. open Farmeropen Farmer. Buildersopen Farmer. Deployopen Systemlet deployment = arm {  location Location. WestEurope}printf  Generating ARM template. . .  deployment |&gt; Writer. quickWrite  output printfn  all done! Template written to output. json The created ARM template output. json is empty. We haven’t specified anything yet. {  $schema :  https://schema. management. azure. com/schemas/2019-04-01/deploymentTemplate. json# ,  contentVersion :  1. 0. 0. 0 ,  outputs : {},  parameters : {},  resources : []}Adding DevOps: I will now re-create the Farmer application with --ci devops. This will add an azure-pipeline. yml-file for Azure DevOps to the project. I need to specify an --azureSubscription which in this case is the name of my service connection. {% include articleAd. html %} dotnet new Farmer --location WestEurope --ci devops --azureSubscription farmer-rg-sc --forceexport RESOURCE_GROUP_NAME=farmer-rgdotnet runThe Program. fs-file has been overwritten with --force. open Farmeropen Farmer. Buildersopen Systemlet deployment = arm {  // Our location we set previously  location Location. WestEurope}module Config =  // getEnv is only needed inside this module  let private getEnv name =    match Environment. GetEnvironmentVariable name with    | null -&gt; None    | name -&gt; Some name  // Read rg from env or set default value  let resourceGroupName =    getEnv  RESOURCE_GROUP_NAME  |&gt; Option. defaultValue  farmer-ci-deploy // Execute andf deploylet response =  deployment  |&gt; Deploy. tryExecute Config. resourceGroupName Deploy. NoParameters  |&gt; function  | Ok outputs -&gt; sprintf  Success! Outputs: %A  outputs  | Error error -&gt; sprintf  Rejected! %A  errorprintfn  Deployment finished with result: %s  responseWhen we executed the application with dotnet run a resource group farmer-rg was created. The ARM template was written to . farmer/farmer-deploy. json. We also got a new file azure-pipelines. yml that we can use to create a CI pipeline in Azure DevOps. trigger:- masterpool: vmImage: 'ubuntu-latest'steps:- task: AzureCLI@2 displayName: 'Deploy ARM template' inputs:  azureSubscription: 'farmer-rg-sc'  scriptType: 'bash'  scriptLocation: 'inlineScript'  inlineScript: 'dotnet run'Before running the Azure DevOps pipeline I need to add a service connection farmer-rg-sc with Contributer-role to my subscription. Deploying Something Not Useful: To see how simple it is -at least it’s what Farmer is telling the world- I added an Azure Maps resource to my Farmer application. The change in the code is as follows. // In F#, the code (demoMaps) needs to be declared above the code referencing it. let demoMaps = maps {  name  demo_maps   sku Maps. S0}let deployment = arm {  location Location. WestEurope  // Adding the newe resource  add_resource demoMaps}{% include articleAd. html %} The corresponding ARM template will get one additional resource Microsoft. Maps. Comparing only this limited F# application Program. fs with the printed ARM template farmer-deploy. json, we see that the F# application has 34 lines while the ARM template has 17. {  $schema :  https://schema. management. azure. com/schemas/2019-04-01/deploymentTemplate. json# ,  contentVersion :  1. 0. 0. 0 ,  outputs : {},  parameters : {},  resources : [  {    apiVersion :  2018-05-01 ,    location :  global ,    name :  demo_maps ,    sku : {     name :  S0    },    type :  Microsoft. Maps/accounts   } ]}Once committed to GitHub and connected to a new Azure DevOps pipeline, it gets automatically triggered and the new resource deployed to Azure. Azure DevOps Pipeline Output for Farmer ApplicationAzure Maps Created by Farmer Next Steps: Farmer was created to avoid the limitations ARM templates have such as verbose JSON, difficult-to-maintain stringly-typed code, and documentation that is behind. In the upcoming post, I will try to deploy a more advanced scenario and see how it goes, and how it feels to work with Farmer. "
    }, {
    "id": 48,
    "url": "/event-driven-infrastructure-with-app-configuration/",
    "title": "Event-Driven Infrastructure with App Configuration",
    "body": "2020/09/12 - Azure App Configuration is great for externalizing application configurations. But what if an application is our infrastructure? How could we dynamically update our infrastructure based on a change in Azure App Configuration? To give you an idea of what I have in mind … At Vipps we have two AKS clusters. Only one cluster is active at any given time. We use the second cluster to test AKS upgrades. In front of AKS is Azure API Management that can route traffic to AKS-blue or AKS-green. The information of what cluster is active and what is inactive can be stored in Azure App Configuration, and then being send to API Management that uses the value in a policy. In this post, I will show how to automate a switch from one AKS cluster to another cluster with Azure Event Grid. This scenario was a study that i did to find out how to use Azure App Configuration for an Event-Driven Infrastructure. {% include articleAd. html %} Agenda:  Overview Deploy App Configuration Deploy API Management Deploy Azure Automation Create Event Subscription Testing ResourcesOverview: {% include articleAd. html %} Before we start, I will give a high-level overview of the event flow between the services I used. The data of what cluster is active is stored in Azure App Configuration. Whenever I change this value, meaning I set the other AKS cluster as active, a change event is published to Azure Event Grid. Azure Automation subscribes to Event Grid and triggers an update in Azure API Management that routes the traffic to either AKS-blue or AKS-green. More information about Policies in Azure API Management in a previous post. {% include articleAd. html %} Event flow diagram of how Azure App Configuration events trigger Azure API Management deployments Deploy Azure App Configuration: We can deploy an instance of Azure App Configuration Service from Azure Cloud Shell with Azure CLI. To do so we select Bash as shown below. Azure Cloud Shell for Bash Before we start, we have to make sure that we are in the correct subscription. # Make sure you are in the correct subscriptionaz account show# Eventually switch the current subscriptionaz account set --subscription  YOUR-SUBSCRIPTION We can now deploy a new instance of Azure App Configuration Service.  Complete list of all Azure CLI commands for Azure App Configuration {% include articleAd. html %} # We'll put our resources into a new resource group. az group create --name  appc2apim-rg  --location  westeurope # You can have one Free instance per subscriptionaz appconfig create --name  appc2apim-appc  --location  westeurope  --resource-group  appc2apim-rg  --sku freeDeploy Azure API Management: To deploy an instance of Azure API Management we use PowerShell from within Cloud Shell. You can easily switch from Bash to PowerShell: Azure Cloud Shell Bash and PowerShell Now run the following command to create an instance of Azure API Management. This will take about 2 minutes. New-AzApiManagement -ResourceGroupName  appc2apim-rg  -Name  appc2apim-apim-service  -Location  westeurope  -Organization  &lt;ORGANIZATION&gt;  -AdminEmail  &lt;YOUR_EMAIL  --Sku  Consumption {% include articleAd. html %} Deploy Azure Automation: Now that we have Azure App Configuration and Azure API Management in place, we need to tie them together. First, we create an Azure Automation Account. Create Azure Automation Account We give it a name, subscription, a resource group. We also create a service principle. Configure Azure Automation Account We can see that a service principle was created. {% include articleAd. html %} Azure Automation Account Service Principle Create Runbook: When we first created our Automation Account, we will notice that we got three runbooks that we could use to get started. You can chose to delete those like I did. Default Runbooks Then I created a runbook with type PowerShell. This will be empty and we will write the code for it later. Create Runbook {% include articleAd. html %} Importing Az modules into Azure Automation Account: We need the Az. ApiManagement PowerShell Module to update named values in API Management. The named value that we are going to update is a key/value pair telling about what AKS cluster currently is active. We’ll get this from Azure App Configuration. Az. ApiManagement PowerShell Module Click import to make this module available. Importing Az. ApiManagement PowerShell Module We also need the Az. AppConfiguration PowerShell Module to read the key/value pair that is telling about the active cluster. Az. AppConfiguration PowerShell Module At this time the Az. AppConfiguration PowerShell Module does not provide a Get--function to read configurations from Azure App Configuration. This is of course a problem and requires to use the REST interface of App Configuration instead. Az. AppConfiguration Functions Available Create Webhook: To be able to trigger this runbook, we need a webhook that Azure Event Grid can request. Create Webhook in Runbook What we then get is a URL that we need to copy immediately and save somewhere. We will need it in the next section where we create an event subscription. {% include articleAd. html %} URL in Webhook in Runbook Deploy named value to Azure API Management: Now we will deploy a random value as named value to Azure API Management from our runbook. Copy the code into your runbook and test it. update-apim-nv-from-runbook. ps1 {% include articleAd. html %} Read from Azure App Configuration: As mentioned previously, Az. AppConfiguration PowerShell Module does not provide a Get--function to read configurations from Azure App Configuration yet. This requires from us to use the REST interface of App Configuration instead. In a previous post, I write about how to use Postman to read from Azure App Configuration. As we are using PowerShell in our runbook, we would need to convert the code from Javascript to PowerShell. Take a look at the code for reading a key/value from Azure App Configuration that came in as a parameter in powershell and update the same named value in Azure API Management. Create Event Subscription: The only service we are missing is an Event Subscription in Azure Event Grid. One way of creating it is from our Azure App Configuration service. Create Event Subscription in Azure App Configuration We need now the Webhook URL from the previous section that you need to set as the endpoint. In addition you will set a name for the topic. Configuring Event Subscription Testing: We create a named value in Azure API Management that we want to be updated. Named Value in Azure API Management We create a key/value pair that will triggers an event. Key in Azure App Configuration We see now a new job in the Runbook queue. Runbook Job in Queue Short time later, we see that the named value in Azure API Management was updated with the current time. Updated Named Value in Azure API Management Looking at the details of the event, we see our key from Azure App Configuration that triggered the chain. Input Event to Runbook {% include articleAd. html %} Next Step: We saw that we can keep infrastructure configurations in Azure App Configuration. A change will trigger an event which will then execute a Runbook. As a runbook just runs code, and we can implement whatever we want, we can re-configure whatever we want, also infrastructure-as in our case. Azure App Configuration is a quit new service, and it doesn’t provide a complete list of functions at the time of this writing. This means me need to call the REST interface of Azure App Configuration instead. Resources:  Introduction to Azure App Configuration Events in Azure App Configuration Introduction to Azure Event Grid Update Azure API Management Named Value from Runbook"
    }, {
    "id": 49,
    "url": "/azure-app-cofiguration-sync-github-actions/",
    "title": "Sync Azure App Configuration with GitHub Actions",
    "body": "2020/09/05 - One questions we might ask us when we move our properties files from an application to Azure App Configuration is how we can do this without introducing extra complexity when updating our configurations suddenly in a different way. GitHub Actions has an action that synchronizes properties files with Azure App Configuration automatically. It means that we can keep updating our configurations as before, in properties files that are under version control. This blog post is a preparation for my talk on Azure App Configuration and demonstrates this behavior i action. For this demonstration I chose a Spring Boot application that I used earlier for demonstration purposes. You will find the repository on GitHub (spaceship-azure-app-config-demo application). Demo Application The repository doesn’t have a properties file yet, so I will add one and set som random key/value pairs. {% include articleAd. html %} Adding properties file to repository Next is the GitHub workflow that we will set up. There are lots of predefined workflows to choose from. We are going to set it up ourselves. Starting GitHub Actions Workflow We are now in the editor with a workflow file. The file you see at first has lots of printings. I removed everything, and replaced the content with what you see below. I checkout the master branch, set a path for the files I just added, and configured then the GitHub Action Azure App Configuration Sync. This action supports the formats json, yaml, and properties. As most Java applications use properties files, I went with this format as well. You find a full list of input parameters for Azure App Configuration Sync on GitHub. We also need a connection string for the Azure App Configuration Service that we want to use. You can read how to create an instance of Azure App Configuration in my previous blog post. I copied the connection string from my running instance I already had in place and set it directly in the workflow file - NEVER DO THAT. Instead, set it as a GitHub secret. I just didn’t want to over-complicate this demonstration. GitHub Actions Workflow file for Azure App Configuration sync To test the workflow I have to trigger it with a commit. I added a new line and made some adjustments in the properties file that I then committed. {% include articleAd. html %} Adding entries in properties file to repository Here’s the logging data from the workflow. Everything looks good. Running GitHub Actions Workflow Finally checking the configuration data in my Azure App Configuration Service, and voilá, all three configuration entries have been copied over. Configurations in Azure App Configuration Next: The GitHub Action Azure App Configuration Sync gives us a convenient way of moving properties to Azure App Configuration while still keeping the way we update our configurations. We have some legacy Java applications that use properties files, and we wanted to start using Azure App Configurations. With this action, we can keep all configurations close to the application. Now, what happens if I make a change in one configuration in Azure App Configuration? Let’s say we change the title because it has a spelling error. We expect to have this reflected back in the properties. This is of course not possible with a GitHub Action. But it is possible with events in Azure App Configuration which I will cover in a next blog post. "
    }, {
    "id": 50,
    "url": "/jekyll-cookie-consent/",
    "title": "Cookie Consent on my Azure Blog",
    "body": "2020/08/29 - Today, I was asked how I integrated the cookie consent on my Azure Blog that is based on Jekyll. Jekyll transforms plain text into a static websites or blogs. I needed to add cookie consent to my Azure Blog because I wanted to add a Facebook comment plugin together with Google Analytics. Instead of helping this one person, I thought I may help others as well with this short post. Download the cookie consent code: Download the file cookie-consent. html and move it into the _include-folder of your Jekyll project. Placing the code for cookie consent: Add the line of code at the end of your &lt;body&gt; section Include cookie-consent. html Fix the downloaded code: The code for the cookie-consent requires two files, ga. js and chatbutton. js. Otherwise the build will fail. What I did was removing the code section entirely from cookie-consent. html. Remove code for cookie found {% include articleAd. html %} Add privacy page: The cookie-consent has a button More info that points to a privacy page. I add an empty /privacy. html-file to the root folder, and then added content that I got from PrivacyPolicyGenerator. com. You might also want to add the privacy page to the menu which can be done in the _config. yaml-file. "
    }, {
    "id": 51,
    "url": "/my-azure-week-34/",
    "title": "My Azure Week 34",
    "body": "2020/08/22 - This blog post is about my reflections on various topics around Azure, and what I have learned and worked on over the past week. The 10X Rule, and why I started to post Azure content on LinkedIn: I like the evenings sitting on the couch in front of the TV and relax. At the same time, I hate it. I hate it because I’m burning my time . Time that I never will get back. I will never get any smarter by watching television and doing nothing. I would rather like to burn money than time. What I really want is to become great with Azure, and build great services together with my team. So, I read the book “The 10X Rule” by Grant Cardone. First of all, I love this book. It tells the reader that success will come easy - if you follow the 10X rule. As I’m easy to convince, I gave it a shot and started to live 10X in one area - for now. Without going into the details, I started to post Azure related content on LinkedIn all day long - please connect with me on LinkedIn :) At first, it was easy to find content because I could just post what I already knew. I spend 1-2 hours in the evenings and prepared the content for the next day. Then it became harder finding good content that I’d like to share. I had to read articles, news, blog posts, and watch videos on YouTube to collect all the content I think has great value. To make it short, I learned a lot about Microsoft Azure over the past week. It’s also super fun to be able to share that new knowledge with others. I will definitely continue. {% include articleAd. html %} Preparation for my Azure App Configuration Workshop: Some months ago, I read about a service called Azure App Configuration. Somehow I got super interested in this service, and started to play with it. This week I committed myself to give a talk or hold a workshop about it at my own Azure community Azure Meetup Oslo. I spend some evenings to prepare some tasks that I will demonstrate. There’s still a lot to learn about the service and a lot to prepare. The date will be in September, right after my workshop about Azure API Management at NDC Minnesota. I will soon publish the exact date. Learning ARM: {% include articleAd. html %} ARM templates seemed to me always a bit weird. I think it’s because it feels so different than what I am used to. I’ve been using PowerShell for most of the tasks when managing resources in Azure. But this time, I wanted to -or had to- provision a NodeJS Web App on App Service with App Configuration that I deployed with ARM -so I throw myself into the unknown. I liked it. I think I liked it because I saw that it isn’t hard to learn. I continued to do more with ARM and experimented with Deployment Scripts for executing code from within ARM. The possibilities are endless which makes it so interesting and fun. You can read more about Deployment Scripts in my previous blog post. My very first NodeJS web app: We have a task in my team were we want to create a service that publishes some data as Json. After some discussions internally, we decided to create a NodeJS Web App on Azure App Service with Azure App Configuration. I’ve never worked with NodeJS before, so I spend each morning over the summer and studied NodeJS on Udemy (Udemy is an online course provider). What a great course! The first version of the service is running, and I am super happy with it. I have not just learned NodeJS, but I have also learned how much valuable 1-2 hours a day of studying is. It’s fun, I know more, I can share more, and I am more valuable to others. I will definitely continue with it. Conclusion: That was my very first week of reflecting actively over what I’ve done and learned last week. I aim for many more “episodes” the coming weeks where I will focus a bit more on Azure and its services. "
    }, {
    "id": 52,
    "url": "/azure-tagging/",
    "title": "Resource Tagging in Azure",
    "body": "2020/08/08 - Moving services from on-premise to Azure cloud requires effort, technical knowledge, and some experience to make a business secure, compliant, and efficient. This post will discuss why tagging of resources plays an important role to achieve these goals and how you can do this. {% include articleAd. html %} Click-Ops is Costly, Insecure, and it Puts Your Business at Risk: Many developers like myself working for the first time in Azure, love how easy it is to get started, and to see results almost immediately. The Azure Portal simplifies this process of learning about the many different Azure services. We click a few buttons and vóila - resources are deployed. At some point, we create resources for the real world like the official test and production environment. Did we everything well and can continue with new tasks? What happens with the resources that we played with? With Click-Ops, we can’t consistently re-create the same resources in different environments as we will make mistakes at some point and re-create the resources again and again. Do we delete the resources that we don’t need anymore? Maybe not always. I think this is ok. We are humans and we love to perform and rush to the next task. Still, it’s costly and we need to handle this somehow. My experience is that Click-Ops leads over time to Azure resources that nobody knows about, hence can or cannot be deleted. We don’t know without analyzing them. This is a problem, since analyzing eventually hundreds of resources is almost impossible if your business can’t tolerate downtime which might happen when you delete resources that you thought were not in use anymore. Analyzing them first is important but impossible at some point. The thing is that these arguments against Click-Ops are just the tip of the iceberg. Being able to consistently create resources requires code. With infrastructure as code, we can do more. We can tag our resources. I mean we could do this before, but good enough tagging can be time consuming. {% include articleAd. html %} Tagging as Part of Infrastructure as Code Will Make Your Business More Stable: As we get more experienced in Azure, we put more resource deployments into code. That code will contain tagging of resources. Tagging makes it possible to simplify resources associations, show costs per team, identify mission critical resources, classifies resources, and may make your business compliant. You may even save money because you set a tag saying that a given resource is just temporary. Resource naming and tagging decision guide descibes these arguments in more detail. My experience says that these following tags are important: owner, confidentiality, and temporary.  owner: Tells you whom to contact in case you have any questions.  confidentiality: Tells how to treat this resource. It may contain personal data that can’t be shared.  temporary: Tells about if this resource can be deleted soon. Conclusion: Tag every resource at least with the owner tag. I struggled with many resources because I didn’t even know whom to talk to. Analyzing a resource may only tell you half of the story. Knowing who is the owner of a resource will put you in a position of having control over all the resources at any time. "
    }, {
    "id": 53,
    "url": "/azure-app-configuration-devops/",
    "title": "Using App Configuration in Azure DevOps",
    "body": "2020/08/01 - Application deployments dependent often on environment specific data like the name of a resource group, location or flags for certain use cases. Azure DevOps has the concept of variables which is a list of key/value pairs stored together with the release pipeline. This blog post shows how to use key/value pairs that are stored in Azure App Configuration. Prerequisites:  DevOps Extension Azure App Configuration Service Connection with Service Principle for Azure DevOps with role App Configuration Data ReaderAzure DevOps with Variables: Traditionally, we have set environment specific values in Azure DevOps under variables as shown in the image below. These key/value pairs are then accessible as environment variables on the agent machine. This works technically of course fine. What I think is challenging is the fact that we don’t treat these configurations the same way as other configurations. In a Java application we store configurations in . properties files, in NodeJS Web Apps we store them in config. js files - all together with the application code that is under version control. Setting a variable as key/value pair in Azure DevOps I’m adding the Command Line Script task and print the environment variable myKey. Printing environment variable $myKey Here’s the result - myValue. Printed value from Azure DevOps Variables With this approach, we have the challenge of maintaining these variables in a developer-friendly way as they are not stored together with the. {% include articleAd. html %} Reading a Key/Value Pair in a Release Pipeline from Azure App Configuration: Instead of using variables in Azure DevOps, we can also store our application configuration inn Azure App Configuration. Instead of storing only pipeline related configurations, we would store all application configurations there. Azure App Configuration can easily synchronize with a GitHub repository. That means that all configuration is also under version control. More about this in a later post. Let’s nnow create a configuration entry with the key test and the value value. ![Creating a configuration entry in Azure App Configuration](https://cdn. svenmalvik. com/images/azure-devops-app-configuration-add-key-value. png)*Creating a key `test` with value `value` in Azure App Configuration* Now we choose the Azure DevOps task Azure App Configuration from the marketplace. This task is for downloading/reading from App Configuration. Azure App Configuration task in Azure DevOps When we configure the Azure App Configuration task, we need to provide a service connection to our Azure App Configuration service, the name, and a value for the key. The key can also include a wildcard, and would result in one or many configurations that would be set as environment variables on the agent machine. In this example I will be specific and choose the key test that we know we added to Azure App Configuration. Configuring Azure App Configuration task in Azure DevOps Now we a the task Command Line Script and print the key/environment variable $TEST. Printing environment variable from Azure App Configuration What we get might be an error. At least I got an error. The error is saying that we don’t have enough access rights to read from App Configuration. The service principle that is used by the service connection for Azure DevOps needs the role App Configuration Data Reader. Missing role of service principle for Azure App Configuration After I have added the missing role everything worked, and the value value is printed. Printed environment variable from Azure App Configuration Referencing Secrets from Azure Key Vault: Azure DevOps Variables support secrets, and so does App Configuration, indirectly via references to Azure Key Vault. The secret value gets then resolved by the Azure DevOps task, and is accessible within other tasks the same way as secrets in Azure DevOps Variables. What happens behind the scenes is that the Azure DevOps task (or App Configuration client) reads the reference to the secret in Key Vault, and then talks to Key Vault. That means that we need to add reader role to the service principle for Azure Key Vault as well. Next steps: I talked in the beginning about configurations that are close to the application code. What we normally would do to deploy configurations to App Configuration is to synchronize with the repository in GitHub. More about this in a later post. "
    }, {
    "id": 54,
    "url": "/azure-arm-deployscript/",
    "title": "Running Scripts from ARM Templates",
    "body": "2020/07/11 - Why would we want t execute code within an ARM template? Sometimes we need some value in an ARM template that we don’t want to copy and paste around, like secrets. Evgeny Borzenin describes in one of his blog posts how to create a password in ARM, and then create a database with this password. This post will show how we can use the deploymentScript in ARM in its purest form. Let’s list key vaults in a subscription. The most simple way is using the Azure CLI with az keyvault list. I will show how to use the deploymentScript in ARM to achieve the same, but 100 times more complicated. This post shall just shows what’s possible with this new feature. It’s still in preview, so it might disappear later, or come in a different form. We set the scene: # Set the subscription you will perform onaz account set -s  YOUR_SUBSCRIPTION  # Create identity to be able to execute code in deployment scriptaz identity create -g  sma-rg  -n  myUserAssignedIdentity # Read the principleId for the next stepprincipalId=$(az identity show -g sma-rg -n myUserAssignedIdentity --query principalId)# Assign contributor role on the identity you just createdaz role assignment create --assignee-object-id $principalId --role Contributor# Read the id of your identity. Yu will set this in the ARM templateYOUR_IDENTITY=$(az identity show -g sma-rg -n myUserAssignedIdentity --query id){% include articleAd. html %} The ARM template: In this ARM template we do not provision anything. This ARM template shows the deploymentScripts in its pure form. We use Azure CLI to list all Azure Key Vaults in our subscription. {   $schema :  https://schema. management. azure. com/schemas/2019-04-01/deploymentTemplate. json# ,   contentVersion :  1. 0. 0. 0 ,   parameters : {  },   variables : {},   resources : [    {       type :  Microsoft. Resources/deploymentScripts ,       apiVersion :  2019-10-01-preview ,       name :  myscript ,       location :  [resourceGroup(). location] ,       kind :  AzureCLI ,       identity : {         type :  UserAssigned ,         userAssignedIdentities : {           YOUR_IDENTITY : {          }        }      },       properties : {         azCliVersion :  2. 0. 80 ,         timeout :  PT30M ,         cleanupPreference :  OnSuccess ,         retentionInterval :  P1D ,         scriptContent :  result=$(az keyvault list); echo $result | jq -c '{Result: map({id: . id})}' &gt; $AZ_SCRIPTS_OUTPUT_PATH       }    }  ],   outputs : {     result : {       value :  [reference('myscript'). outputs] ,       type :  object     }  }}Execution: # We execute the ARM template and format the output as jsonaz deployment group create --name  deployscript-test  --resource-group  deployscript-test-rg  --template-file PATH_TO_ARM_FILE | jq . properties. outputs. result. value. ResultOutput: [ {   id :  /subscriptions/bfsjkdbfjkdsfbkjsdbkdsf/resourceGroups/some-rg/providers/Microsoft. KeyVault/vaults/some-kv ,   resourceGroup :  some-rg  }, {   id :  /subscriptions/bfsjkdbfjkdsfbkjsdbkdsf/resourceGroups/some-rg/providers/Microsoft. KeyVault/vaults/some-other-kv ,   resourceGroup :  some-rg  }]Conclusion: I executed inline code, but we can also execute a remote script. Instead of scriptContent, we would choose primaryScriptURI. "
    }, {
    "id": 55,
    "url": "/azure-apim-self-hosted-gateway/",
    "title": "Using Azure API Management APIs with Docker",
    "body": "2020/06/27 - We use Azure API Management in some cases for calling external services from Azure Kubernetes Service (AKS). Azure API Management acts in this case as a link between an internal service running on AKS and an external service running at a third-party. The third-party knows who we are, and has whitelisted our outgoing IP address which is the egress IP from Azure API Management. The problem is when redeploying Azure API Management. As we emphasize immutable infrastructure, this may happen at some point. Redeploying Azure API Management results then in a different IP address that the third-party has to whitelist again. This may take time and effort. Fortunately, Azure API Management has the concept of self-hosted gateways. This post will show how to use a self-hosted gateway with Docker. Self-hosted API Gateway without Round-Trip: The diagram below shows that instead of making the round-trip from a service running outside of Azure to Azure API Management and then to a backend service, we can go the direct route with a self-hosted API gateway. Azure API Management Gateway diagram {% include articleAd. html %} Deploying a self-hosted API gateway in Docker: I added two APIs to an Azure API Management instance that are public available without a subscription-key. Both APIs are hosted in the US. The Azure API Management instance is deployed in West Europe (Amsterdam). Adding APIs to Azure API Management We can simply test the endpoint in any browser. I send a request from my local machine in Norway to an Azure API Management instance that is running in West Europe (Amsterdam) which then forwards the request to a service in the US. This is a long journey with an unnecessary stop in the Netherlands. Let’s see how we can communicate directly with a self-hosted gateway. Round-Trip of a request The service in the US has whitelisted all IPs. It’s a public available service. In case it would only have whitelisted our IP address of this Azure API Management instance, we were in no trouble either. Would we then redeploy, and get a new instance, we would also get a new IP address that the service in the US would need to whitelist again. Testing an API against Azure API Management Here’s how we create a self-hosted gateway in the Azure Portal. We add only the APIs that we want to move outside Azure API Management. Creating an API Gateway What we get is a Docker image and a file with some key-value pairs that we can download. API Gateway configuration We put the downloaded file at a location from where we will run Docker. Running the API Gateway in Docker The container started successfully on port 80. The API Gateway is running on port 80 We can finally test the same API from localhost. The IP address that the service in the US would need to whitelist is the one from my local machine. That means that I can redeploy my Azure API Management instance as often as I want without notifying third-parties about a change in IP address. Testing an API against the local API Gateway Changing an API in the Portal: {% include articleAd. html %} The self-hosted gateway needs still to talk to Azure API Management to send metrics. Also, when we make a change in the API, we don’t need to create a new Docker image. All changes are communicated to the self-hosted gateway directly and take Immediately effect. Summary: A self-hosted gateway puts APIs closer to the services calling these APIs. It also makes working in an environment that emphasizes immutable Infrastructure, because we don’t depend on the egress IP address of Azure API Management. On the flip-side, using a self-hosted gateway will increase the complexity of a system. Resource:  Microsoft: Self-hosted gateway overview"
    }, {
    "id": 56,
    "url": "/azure-appservice-nodejs/",
    "title": "ARM for NodeJS Azure Web App with App Configuration Integration",
    "body": "2020/06/13 - Our Azure infrastructure has some configurations that our developers need to know like the name of the currently active AKS cluster and APIM instance. We store these configurations in an Azure App Configuration instance and expose them as an API through an Azure App Service Web App that is written in NodeJS. This post shows how we provision the NodeJS Web App with an ARM template. We can provision the App Service Plan and App Service from the portal, and then setup deployment of a GitHub repository for the NodeJS application. But I wanted it to be 100% automated without setting up anything, so I decided to try ARM templates. The ARM template explained: An ARM templates contains of 4 sections, parameters, variables, resources, and outputs. We will focus on only two of them. parameters and resources. {% include articleAd. html %} In parameters I defined a name for the site, a connectionString for the App Configuration Service, a repositoryUrl of the NodeJS application, and a branchName of the application that I want to deploy. In the resources section, I defined 4 resources. an App Service Plan that has the type Microsoft. Web/serverfarms, an App Service with type Microsoft. Web/sites, a configuration for the App Service with type Microsoft. Web/sites/config, and the hostname binding so we can reach the web app with type Microsoft. Web/sites/hostNameBindings. App Service Plan: You get one free App Service Plan with SKU B1 for one month and subscription, at least for now. If you automate the provisioning of the entire setup as described in this post, you could trigger it with an Azure Runbook if you want. App Service: The App Service depends on the App Service Plan. In ARM we can define this dependency that has to exist with dependOn. This example is a simplification and http only. You shouldn’t run this in production. This App Service section also describes 2 resources, sourcecontrols where I defined the GitHub repository, and config where I store the connectionString for Azure App Configuration. Since I chose type Custom for my connectionString, I can access the value from my NodeJS application with the prefix key CUSTOMCONNSTR_. The fully key would be CUSTOMCONNSTR_AppConfigConnString. The connectionString is stored as an environment variable that my NodeJS application can access with process. env. CUSTOMCONNSTR_AppConfigConnString. {% include articleAd. html %} App Service Configuration and hostname binding: In these resource, we configure our App Service. I exported these resources directly from the portal and made a few changes like the scmType which is in my case GitHub. NodeJS Application: The NodeJS application is in a separate GitHib repository that uses the azure/app-configuration module. Every commit to the branch that you defined when deploying the ARM template will deploy a new version and restart the application. Conclusion: This ARM template will deploy App Service Plan, App Service, and deploy the NodeJS application. az deployment group create --name  YOUR_WEBAPP  --resource-group  YOUR_RG  --template-file PATH_TO_YOUR_ARM_TEMPLATE"
    }, {
    "id": 57,
    "url": "/azure-appconfiguration-configserver/",
    "title": "Azure App Configuration Introduction &#35;3",
    "body": "2020/05/23 - After playing around with Azure App Configuration Service and how to read a configuration entry with REST, and then using feature flags in a Spring Boot application, I got hooked I must admit. I wanted to know if it’s possible to replace the Spring Cloud Config Server with Azure App Configuration without changing the client services. This post will explain every step I took to build a first version of an Azure Spring Boot Config Server. Starting point of this project was my previous post where I created a basic Spring Boot web application with feature flags. The pom. xml stayed pretty much the same. What’s different is everything else. Here’s an illustration about what I wanted to achieve. Instead of configuring a client service with -Dspring. cloud. config. uri=&lt;old_SPRING_CLOUD_CONFIG_SERVER&gt;, I wanted to replace just the address: -Dspring. cloud. config. uri=&lt;new_AZURE_CONFIG_SERVER&gt;. Motivation: {% include articleAd. html %} The challenge with Spring Cloud Config Server is its dependency to a Git repository which tend to have either no SLA, or an SLA of three nines which would allow for 8h 45m 56s downtime in a year. We experienced lots of problems related to the Java Config Repo which prevented our Spring Cloud Config Server to start which further prevented our services to start. In case of an incident a pretty awful situation. Replacing Spring Cloud Config Server with Azure App Configuration Spring Cloud Config Server - Simplified: The interesting part is how Spring Cloud Config Server serves configurations, and what endpoints it has. To find out, I took a look at what requests the clients send to the config server: http://&lt;old_SPRING_CLOUD_CONFIG_SERVER&gt;/&lt;CONTEXT_PATH&gt;/&lt;APPLICATION&gt;/&lt;PROFILE&gt;/&lt;LABEL&gt;/FILE.  Application represents the folder within the Java Configuration Repo.  Profile is the the profile the service - Config Server or Client Service - was started with.  Label is a Git-Hash, tag or branch.  File is the filename with the extension that you’d like to retrieve. All these information must somehow be captured in an Azure App Configuration instance, normally. In my case, the profile is the same as the label, so I ignored this information for now. Configuration: The new Azure Config Server can connect to one or many Azure App Configuration instances. Each team or application can have its own instance, cross service configurations could be in a dedicated Azure App Configuration instance. I will configure just one instance as I want to import all configurations of all of our Java Spring Services and all cross service configurations at once. his project is a proof of concept after all. spring. cloud. azure. appconfiguration. stores[0]. connection-string= ${APP_CONFIGURATION_CONNECTION_STRING}spring. cloud. azure. appconfiguration. stores[0]. label=testspring. cloud. azure. appconfiguration. cache-expiration=1s{% include articleAd. html %} Configurations in Azure App Configuration can be labeled with i. e. the name of the environment dev, test or production, or anything else. The new Azure Config Server will first run in the test environment. I set cache-expiration to one second to see changes faster, default is 30 seconds. I really don’t want to wait so long while testing and playing around. Model: The name of the one and only model is ConfigApiProperties. It has two members: // Configurations from Azure App Configurationprivate Map&lt;String, String&gt; config;// The filename that was requestedprivate String file;I ignored profile and label for now as I would start a new instance of the new Azure Config Server for every environment anyway. This makes sense where you have dedicated clusters for each and every environment. Controller: The controller defines the endpoint(s) the Azure Config Server needs to listen to. As I said previously, this is a first version, a proof of concept if you will. It accepts all profiles at the moment. All configurations will be labeled with test but should ideally be set automatically from the bootstrap configuration spring. cloud. azure. appconfiguration. stores[0]. label, something for later to implement - focusing on the core first. @GetMapping(value = {  /{application}/*/test/{file}  }, produces = MediaType. TEXT_PLAIN_VALUE)public String getMessage(@PathVariable String application, @PathVariable String file) {  // The core of the code you would put here will  // convert the HashMap ConfigApiProperties. config  // into one String with new lines so that the  // returning String looks like a real properties file. }Configuration Prefix in Azure App Configuration: Azure App Configuration let us define entries with different prefixes and labels. As I will import all configurations of all applications that have each many files defined. It probably is bad practice to even consider putting it all into one instance. I do it anyway. I will use the prefix to distinguish applications and files: /application/config. &lt;APPLICATION&gt;. &lt;FILE&gt;. . The default deliminator is a dot . . {% include articleAd. html %}  /application/ is the prefix that spring-cloud-azure-appconfiguration-config-web will prefix by default. This can’t be changed unless you patch the class.  config is the member of the ConfigApiProperties-model.  &lt;APPLICATION&gt; is the foldername of the requesting service within the Java Configuration Repo.  &lt;FILE&gt; is the filename being requested. Next Steps: The complete code - that I can’t share for now - has some flaws and performance issues if I can say that. I mean the Spring Cloud Config Server checks out an entire repository which can take minutes. The new Azure Config Service will read all configurations and filter then what’s get returned to the requesting service. Also is profile information missing at the moment. If you would like to get some more details about the code, please drop me a message. "
    }, {
    "id": 58,
    "url": "/azure-appconfiguration-feature-flags/",
    "title": "Using Feature Flags with Azure App Configuration",
    "body": "2020/05/16 - Sometimes we would like to test a new feature of an application. Or we would like to disable code junks because they are not fully implemented. Feature toggling, or feature flags make this possible. This post will discuss how I build a spaceship from scratch with Spring Boot and the support of Azure App Configuration to enable and disable features of my spaceship. Watch this post on YouTube: Azure App Configuration Introduction Agenda:  Few words to trunk based development and why we may consider feature flags How Azure App Configuration Service stores feature flags We build a spaceship with Spring Boot using feature flags{% include articleAd. html %} Few words on trunk based development: Trunk based development simply means to work as closely on the master branch as possible avoiding long-living feature branches. We will still have feature branches, but they will be merged as quickly as possible directly to the master branch. Trunk based development prefers many minor changes over few larger changes. The question then is, how can we add new features that are not fully implemented yet when we need to merge often. The answer is with feature flags. More information on trunk based development can be found at https://trunkbaseddevelopment. com. How Azure App Configuration Service stores feature flags: We will soon build a spaceship with Spring Boot. As spaceships tend to be quit complex systems, we won’t be able to finish the whole product in this post. In fact, we are just getting started for now, and will hide new features behind a feature flag that we will name beta. As in part one, we are going to work inside Azure Cloud Shell with Bash. Make sure you are in the right subscription and that you have access to your instance of Azure App Configuration. # Make sure you are in the correct subscriptionaz account show# Eventually switch the current subscriptionaz account set --subscription  YOUR-SUBSCRIPTION # Check if your spaceship config-store is still thereaz appconfig show --name  spaceship-appc  --resource-group  svenmalvik-rg When everything looks fine, we can deploy our beta flag that we will need later to hide new features of our spaceship.  NOTE: The appconfig feature command is still in preview. Azure App Configuration is in GA. # Creates a new feature flag without asking us for confirmation (--yes)az appconfig feature set --name  spaceship-appc  --feature  beta  --yesAzure App Configuration stores feature flags as json objects the same way as ordinary configurations. Running instance of Azure App Configuration Service The feature flag is disabled by default, and we have to explicitly enable it. We’ll do this later once we have our spaceship in place including a feature that we want to try out. {   id :  beta ,   description : null,   enabled : false,   conditions : {     client_filters : []  }}{% include articleAd. html %} We build a spaceship with Spring Boot using feature flags: I started by following the instructions on Create a Spring Boot app. The problem was that some instructions were wrong, and used very old libraries. So I created pull requests that were quickly merged by Microsoft into the master branch of the Azure Documentation. As a side note, that was super fun and super rewarding. Anyway, I simplified the example, updated the libraries, and put it on GitHub - spaceship-azure-app-config-demo. Before we start the spaceship, we need to set the connection-string of the App Configuration instance as an environment variable. I have a Mac, so I set it as shown below. # I showed how to get the connection-string in the previous postexport APP_CONFIGURATION_CONNECTION_STRING= Endpoint=https://spaceship-appc. azconfig. io;Id=UCUX-l9-s0:3mLEfWlVSlM29Y6SAecu;Secret=QTbtHe75woUi+UerdNVvJWB+E5XQZ9kdrm9xYIcwaVI= Before we discuss how feature flags are implemented into the spaceship, we will look at the behavior by starting it. # Maven 3. x and Java 8 requiredmvn clean install &amp;&amp; mvn spring-boot:runlocalhost:8080 is now showing us a sneak peak of the future. Spring Boot Web App with Azure App Configuration feature flag #1 Now, we are enabling the beta-feature, and then looking even further into the future. # Enabling the feature flagaz appconfig feature enable --name  spaceship-appc  --feature  beta  --yesSpring Boot Web App with Azure App Configuration feature flag #2 It’s one line that makes this happen featureManager. isEnabledAsync(). @GetMapping(value = {  ,  / ,  /welcome })public String mainWithParam(Model model) {  // We prefix our flag with featureManagement.   model. addAttribute( Beta , featureManager. isEnabledAsync( featureManagement. beta ). block());  return  welcome ;}Responsible for this simplistic code is the microsoft/spring-cloud-azure-java library that I defined in pom. xml. Conclusion: We have discussed the main point of feature flags in Azure App Configuration Service. We didn’t talk about filters. Feature filters let us enable a feature for only a subset of users. This is great for canary-testing/AB-testing. "
    }, {
    "id": 59,
    "url": "/azure-appconfiguration/",
    "title": "Azure App Configuration Introduction",
    "body": "2020/05/09 - We build this great application that we configure exactly the way it fits into our environments, and then we realize that changing a configuration isn’t as easy as we’d like to. This post introduces Azure App Configuration Service, a service that manages non-secret configurations. This first part of a serie discusses how to setup the service and how to use the REST interface for retrieving data. Watch this post on YouTube: Azure App Configuration Introduction Agenda:  We will provision Azure App Configuration with Azure CLI Test to get a config-entry with Postman Discuss other featuresDeploy Azure App Configuration with Azure CLI: We will deploy an instance of Azure App Configuration Service from Azure Cloud Shell with Azure CLI. To do so we select Bash as shown below. Azure Cloud Shell for Bash {% include articleAd. html %} Before we start, we have to make sure that we are in the correct subscription. # Make sure you are in the correct subscriptionaz account show# Eventually switch the current subscriptionaz account set --subscription  YOUR-SUBSCRIPTION We can now deploy a new instance of Azure App Configuration Service.  Complete list of all Azure CLI commands for Azure App Configuration # We'll put our resources into a new resource group. az group create --name  svenmalvik-rg  --location westeurope# You can have one Free instance per subscriptionaz appconfig create --name  spaceship-appc  --location westeurope --resource-group  svenmalvik-rg  --sku freeThe name of your instance must be globally unique, since it will get a public endpoint: https://svenmalvik-appc. azconfig. io. Running instance of Azure App Configuration Service Read a key-value from Azure App Configuration with Postman: Common practice to organize keys is into a hierarchical namespace by using a character delimiter, such as / or : that is based on component services, deployment regions. We could store the hostName of let’s say a Azure Container Registries (ACRs) with a key called docker:acr:hostName. To distinguish two ACRs, one for test and one for production, we could then label each configuration with test and prod. Before we can read anything, we need to set at least one configuration. We’ll do this also with Azure CLI in its most simplistic way. # Deploy a key-value pairaz appconfig kv set --name  spaceship-appc  --key  target  --value  space Let’s check it out in the portal. Key-Value pair in the portal of Azure App Configuration Service The REST interface for retrieving a key-value pair from Azure App Configuration is well described. In short, we are going to create a GET request to this address: https://spaceship-appc. azconfig. io/kv/target. Before we can send anything, we need to get a credential identifier and the secret that we will hide in a request header. All your configuration data stored in App Configuration is encrypted at rest and in transit. # It lists 4 entries (Primary/Secondary &amp; Read-Only/Write)az appconfig credential list --resource-group svenmalvik-rg --name spaceship-appcWe pick the primary / readOnly credential. We need the id and the value. Below is an example that I created previously. It won’t work for you as it won’t exist anymore. {% include articleAd. html %} . . . {   connectionString :  Endpoint=https://spaceship-appc. azconfig. io;Id=UCUX-l9-s0:3mLEfWlVSlM29Y6SAecu;Secret=QTbtHe75woUi+UerdNVvJWB+E5XQZ9kdrm9xYIcwaVI= ,   id :  UCUX-l9-s0:3mLEfWlVSlM29Y6SAecu ,   lastModified :  2020-05-08T10:00:51+00:00 ,   name :  Primary Read Only ,   readOnly : true,   value :  QTbtHe75woUi+UerdNVvJWB+E5XQZ9kdrm9xYIcwaVI= },. . . Open Postman and create a new GET request with your endpoint. I told that the id and value will be hidden in a header. To do so, we copy the code below (Click to get the code) into the Pre-request Script and replace my credential with your id, and my secret with your value. Pre-request Script in Postman Conclusion: Azure App Configuration complements Azure Key Vault by managing its configuration easier. A good example is by comparing settings across multiple environments as in the example below where we store the hostName of our Azure Container Registry for test and production. Comparing configurations in Azure App Configuration Another great feature of Azure App Configuration is feature flags. Feature flags are stored almost the same way as ordinary configurations. I’m going to dive into using feature flags in Spring Boot next week. "
    }, {
    "id": 60,
    "url": "/azure-apim-backup-restore/",
    "title": "Backup and Restore in Azure API Management",
    "body": "2020/05/02 - As infrastructure gets more complex, more parts will eventually break. This is even more true as we make frequently changes. Sometimes we upgrade the infrastructure, and other times we just shuffle things around to fulfill new requirements. One question is how we can do this without too much complexity. The safest but probably most expensive choice is by provisioning an entirely new infrastructure. We won’t make changes to the existing one, but instead apply changes to a new one and test before putting it into production. This post will show how we can provision Azure API Management and copy all data from a running instance over to another instance, and make sure that everything in regards to Azure API Management works as before. Watch this post on YouTube: Backup and Restore in Azure API Management Create Source and Target Instances of Azure API Management: Before we start taking a backup, we will deploy two instances of Azure API Management (apim-src and apim-dest), one we will take the backup from, and one we will restore the backup to. We put both instances in the same resource group so we can easily delete everything later. {% include articleAd. html %} # Create resource group for all resourcesNew-AzResourceGroup -Name  apim-rg  -Location  West Europe # Create source Azure API ManagementNew-AzApiManagement -ResourceGroupName  apim-rg  -Name  apim-src  -Location  West Europe  -Organization  svenmalvik. com  -AdminEmail  sven@malvik. de # Create target Azure API ManagementNew-AzApiManagement -ResourceGroupName  apim-rg  -Name  apim-dest  -Location  West Europe  -Organization  svenmalvik. com  -AdminEmail  sven@malvik. de Storage for the Backup: When taking a backup from Azure API Management, we need to provide a storage container where the backup will be stored. # Create storage account for backups$storageAccount = New-AzStorageAccount -ResourceGroupName  apim-rg  -Name  apimsvenmalviksa  -SkuName Standard_LRS -Location  West Europe # Create container for backupsNew-AzStorageContainer -Name  apim-backups  -Context $storageAccount. Context -Permission blobBackup and Restore with PowerShell: We can now run the backup command. We take two backups. One for the source instance of Azure API Management, and one for the target instance. The reason I’m doing this is because I tend to mix parameters easily. Instead of taking a backup from the source, I eventually take a backup from the target and restore it to the source. If this happens and I overwrote the source, I would still have the backup that I can restore if I have to.  NOTE: Backup is not possible in Consumption. # Take backup from sourceBackup-AzApiManagement -ResourceGroupName  apim-rg  -Name  apim-src  -StorageContext $storageAccount. Context -TargetContainerName  apim-backups  -TargetBlobName  apim-src-backup # Take backup from targetBackup-AzApiManagement -ResourceGroupName  apim-rg  -Name  apim-dest  -StorageContext $storageAccount. Context -TargetContainerName  apim-backups  -TargetBlobName  apim-dest-backup In the final step, we just restore the backup. # Restore backupRestore-AzApiManagement -ResourceGroupName  apim-rg  -Name  apim-dest  -StorageContext $storageAccount. Context -SourceContainerName  apim-backups  -SourceBlobName  apim-src-backup Azure API Management is now restored in a different instance. Depending on your infrastructure, you might need to make some adjustments.  NOTE: Be careful with hostnames in Named Values. In case you are preparing an entire new cluster, you might need to change them. {% include articleAd. html %} Conclusion: Taking a backup and restore takes time. I have experienced everything between 30 minutes to 1 hours where the backup is much faster than the restore. When we take a backup, the instance of Azure API Management gets in a state where we can’t apply changes. The same is true for restore. It means for us that we have to run backup and restore while nobody is working and deploying changes. It’s fine in production because developers will only apply changes during daytime when they can get help from colleagues in case they deploy a bug. The test environment is different because developers deploy changes also at night to this environment. In case they deploy a bug, it won’t hurt so much and the developer who introduced the bug normally doesn’t need to hurry to fix it like in a production environment. Whenever we take a backup and restore it - during the day or at night, we communicate a freeze-time, so every developer knows that Azure API Management won’t be available for some time. To be very honest, this is very painful to us, and it’s the reason one must consider to treat Azure API Management as a shared resource that doesn’t need to be re-created just because you decided to emphasize immutable infrastructure. "
    }, {
    "id": 61,
    "url": "/azure-cdn-with-ssl/",
    "title": "Serving Website Images from Azure CDN with SSL",
    "body": "2020/04/25 - In this post I will show you step by step how to serve images on a website from Azure CDN with SSL enabled. My blog has a couple of Azure API Management posts that I previously posted to LinkedIn. When I launched this website, I copied all these posts in here but kept the images in LinkedIn. My website is hosted on GitHub pages. I could have posted all the images also to GitHub and serve them directly from there, and everything would be work just fine. Well, since I work a lot with Azure, I thought it would be a great Idea to try out Azure Content Delivery Network (CDN) with SSL. {% include articleAd. html %} Agenda:  Create Azure Storage Account Create Azure CDN Create Custom Domain cdn. svenmalvik. com Enable SSL and create certificateCreate Azure Storage Account: We start by searching Storage Account from within the Azure portal, and click the Create button. Create Azure Storage Account I put the storage account in a new resource group called svenmalvikdotcom-rg so I can delete the entire resource group in case I change my mind later, and decide to keep the images at GitHub. I’m also unsure about how many visits this blog will have, and how the cost will be in a year. More about Azure CDN billing. I also choose Storage V2 for images as recommended in the Azure Storage Account documentation.  NOTE: Microsoft recommends using a general-purpose v2 storage account. I set the Access tier to cool since it is optimized for storing data that is infrequently accessed, like this blog :smile:. Create Azure Storage Account Basics {% include articleAd. html %} In the Networking-section I choose Public endpoint (all networks) because I want my images access directly from this website. In case I’d chosen Private endpoint, I would need to put a public available service like Application Gateway or Front door in front. Create Azure Storage Account Networking Now that we have a Storage Account, the next thing is to create a container where we put all images. I could have chosen Blob, but since I’m not sure if I also will put static pages there, I choose Container that is accessible by anybody. Azure Storage Account Container I can now upload my images, and have them publicly available and ready to use. The overview of the storage account gives us the endpoint for retrieving the images. Azure Storage Account Images Create Azure CDN: Azure storage account is a great place for storing my images, but not so great for serving them globally from a websites where performance matters and where user experience is everything. I chose to try Azure Content Delivery Network (CDN) that reduces load time, save bandwidth, and speed responsiveness. From the menu in the storage account, we can click on Azure CDN and fill out the fields as suggested. There are 3 parameters that are interesting. Pricing tier: I selected “Standard Microsoft” because it seems to have better a more advanced rules engine. Compare Azure CDN product features  CDN endpoint name: It’s the host for accessing the images. We will later create a CNAME that will point to this address.  Origin hostname: The address where your images live. This field has already the correct value, if you added the CDN from the menu in the storage account. Create Azure CDN {% include articleAd. html %} After some minutes we can try to retrieve an image from the storage account via Azure CDN. We use the &lt;CDN endpoint name&gt;. azureedge. net&lt;PATH TO IMAGE IN STORAGE ACCOUNT&gt;. Azure CDN Image request Create Custom Domain: The endpoint we just used to retrieve the image can at some point change. I might later choose to put the images at another place, simply because there are other services that are better suited for my purpose. To have this possibility later, I will create the custom domain cdn. svenmalvik. com for retrieving my images. First, I create a CNAME entry in the portal of my domain provider and point it to my newly created CDN endpoint. CNAME to CDN We will now create a custom domain from the CDN endpoint menu and fill in the CNAME we just created. Azure CDN Custom DomainAdd Azure CDN Custom Domain We also set Custom domains HTTPS to On and choose CDN managed. Azure partnered with DigiCert which means that we get certificates for free. We know that nothing is free, and that the costs are baked into the usage of CDN. Anyway, it makes it very simple for us to enable SSL. This process takes a while to finish. In my case it took about an hour. Request SSL Certificate for Azure CDN Custom Domain We can now test to retrieve the image with https. Secure Image Request from Azure CDN Now that everything works, we can change all URLs in on all websites. In case you wonder about the code, I use Jekyll that renders Markdown files to html files. Changing website code Finally, we can test the website and check that the images get fetched from the CDN with SSL enabled. svenmalvik. com image in browser Conclusion: I showed how to use Azure CDN with SSL enabled for retrieving images from a website. I did everything from the portal which of course is not the way it should be done. If you have some experience with Azure CLI, PowerShell or ARM, you should use one of them instead to fully automate the steps. "
    }, {
    "id": 62,
    "url": "/azure-apim-policies/",
    "title": "Understanding Policies in Azure API Management",
    "body": "2020/04/18 - Policies are the heart of Azure API Management. They let us change the behavior of our APIs in a very flexible manner. Before I dive in to policies, I will discuss the core concept of Azure API Management. At the end, I’ll go through some examples. Agenda:  What Azure API Management Policies are Core Concept of Azure API Management How to define Azure API Management Policies Examples Aggregated Azure API Management PolicyWhat Azure API Management Policies are: Azure API Management Policies let you change the behavior of APIs through a combination of XML and C#. They are executed on the request or response of an API. Since we are dealing with code, we are very flexible in what we can change. We can for instance check for a certain header in a request before forwarding the request to the backend. We can also prevents API usage spikes by limiting call rate, or mock responses for endpoints that are not implemented yet but important for certain test scenarios. Before we start implementing some examples, it is important to understand where we can apply a policy. In short, we can apply a policy globally, on a product-level, one for every API, and a policy for each endpoint. If you haven’t worked with Azure API Management yet, it’s a great time to discuss the core concept of Azure API Management before continuing. Otherwise, you can skip the following chapter. {% include articleAd. html %} Core Concept of Azure API Management: Many APIs are specified in Swagger-files like the Conference API. This API bundles those endpoints - we call them Operation in Azure API Management - that together make up the conference service - in this case the API bundles endpoints like /sessions, /topics, /speakers, and some more. Companies like Vipps, a Norwegian payment service and where I work, have many APIs, and not all its costumers need access to all of them. The Vipps App needs access to APIs that are specifically developed for it. Merchants that want to use Vipps as a payment service for their customers need some other services than the Vipps App. To make this distinction, and to provide clients access to only a subset of available APIs, Azure API Management has the concept of Products. To use a product, a User/Client has to Subscribe to a Product. Core Concept of Azure API Management When it comes to Azure API Management policies, we can define them at every level. Every endpoint/operation can define its own policy and change requests and responses. The same is true for all APIs, and products. We can also define a policy that applies to all requests and responses. How to write Azure API Management Policies: An Azure API Management Policy defines 4 sections, inbound, backend, outbound, and on-error. As the diagram below shows, changes to the request are implemented in the inbound section. Changes to the request before forwarded to the backend service in the backend section, and responses can be changed in the outbound section. In case the backend can’t be reached, and a timeout happens, the on-error section is triggered. It’s probably a good idea to handle errors as well. Azure API Management Policy Definition The following code shows a bare policy where you can add headers to requests and responses, or validate requests and responses, or convert a response body from xml to json. These are just a few out of many examples of Azure API Management Policies. &lt;policies&gt; &lt;inbound&gt;&lt;!-- Change the Request --&gt; &lt;/inbound&gt; &lt;backend&gt;  &lt;!-- Change the Request before forwarded to the backend service --&gt; &lt;/backend&gt; &lt;outbound&gt;  &lt;!-- Change the Response --&gt; &lt;/outbound&gt; &lt;on-error&gt;  &lt;!-- Change the Response in case of an error like a timeout --&gt; &lt;/on-error&gt;&lt;/policies&gt;You can change a policy directly in the portal. In the example below, we change the policy of the endpoint GetTopics of the Conference API. Open API Management Policy in Azure portal Examples: Before we go on and discuss how to debug a policy, let’s discuss some examples first. We will use the Echo API. Examples 1: Mocking an Endpoint: In the following code snippet, I added a mock response to the inbound section of the Retrieve headers endpoint. &lt;inbound&gt;  &lt;mock-response status-code= 200  content-type= application/json  /&gt;&lt;/inbound&gt;Examples 2: Adding header to API response: Let’s now add a header to the outbound section of the Echo API. That means that any calls to this API will have the header in its response. Adding header to API response in Azure API Management Examples 3: Adding rate limiting on product-level in Azure API Management: On the product-level, we will protect our backend from excessive calls. Adding rate limiting on product-level in Azure API Management {% include articleAd. html %} Examples 4: Adding global policy: The global policy applies to all endpoints. I have added an ip filter to the inbound section telling that only I am allowed to send requests. Adding global policy to Azure API Management Aggregated Azure API Management Policy: Earlier, I told about endpoint-, API-, product- and global-policies. When I define policies at each level, how does the complete policy look like? What gets overwritten or not? First of all, what gets overwritten or not is up to the developer. We take a look at the inbound-section to explain what I mean. &lt;policies&gt; &lt;inbound&gt;  &lt;base/&gt; &lt;!-- The upper level gets inserted here --&gt;  &lt;!-- Change the Request --&gt;  &lt;base/&gt; &lt;!-- The upper level gets inserted here --&gt; &lt;/inbound&gt;&lt;/policies&gt;&lt;/base&gt; can be defined either before or after your code, but not twice. In case you don’t define &lt;/base&gt;, nothing will be inserted. We can imagine that implementing code in each section at every level might result in many lines of code. To get the complete Azure API Management Policy for your endpoint - or another level - we can aggregate them by calculating it from within the Azure portal. Calculate complete Azure API Management Policy &lt;policies&gt;  &lt;inbound&gt;    &lt;!--base: Begin Api scope--&gt;    &lt;!--base: Begin Product scope--&gt;    &lt;!--base: Begin Global scope--&gt;    &lt;ip-filter action= allow &gt;      &lt;address-range from= 51. 175. 196. 188  to= 51. 175. 196. 188  /&gt;    &lt;/ip-filter&gt;    &lt;!--base: End Global scope--&gt;    &lt;!--base: End Product scope--&gt;    &lt;!--base: End Api scope--&gt;  &lt;/inbound&gt;  &lt;backend&gt;    &lt;!--base: Begin Api scope--&gt;    &lt;!--base: Begin Product scope--&gt;    &lt;!--base: Begin Global scope--&gt;    &lt;forward-request /&gt;    &lt;!--base: End Global scope--&gt;    &lt;!--base: End Product scope--&gt;    &lt;!--base: End Api scope--&gt;  &lt;/backend&gt;  &lt;outbound&gt;    &lt;!--base: Begin Api scope--&gt;    &lt;set-header name= echoTest  exists-action= append &gt;      &lt;value&gt;true&lt;/value&gt;    &lt;/set-header&gt;    &lt;set-header name= X-My-Sample  exists-action= override &gt;      &lt;value&gt;This is a sample&lt;/value&gt;    &lt;/set-header&gt;    &lt;!--base: End Api scope--&gt;    &lt;jsonp callback-parameter-name= ProcessResponse  /&gt;  &lt;/outbound&gt;  &lt;on-error /&gt;&lt;/policies&gt;{% include articleAd. html %} Conclusion: There’re many places we can define policies. It’s therefore extra important to be careful with how much we put into them. I’ve seen aggregated policies that had hundreds of lines of code. This is a hard situation when working in an environment with many developers and many APIs where APIs are shared across many products. We have covered the basics of policies, and hopefully this post has given you an idea of how they work in Azure API Management. Reach out to me in case you have questions or you are interested in a talk or workshop about Azure API Management. "
    }, {
    "id": 63,
    "url": "/azure-apim-with-eventhub/",
    "title": "Logging in Azure API Management",
    "body": "2020/04/11 - This post is a complete step-by-step guide on how to send logs from Azure API Management to Azure Event Hub with PowerShell. We start by creating an instance of APIM, Event Hubs Namespace together with an Event Hub, and finish by watching incoming events with help of a VS Code Plugin. Watch this post on YouTube: Logging from Azure API Management to Azure Event Hub Agenda:  Deploy Azure API Management Add API Deploy Azure Event Hub Add logger to APIM Install Azure Event Hub Plugin in VSCode Connecting to Azure: There are many ways we can use to connect to Azure like using Azure CLI, Azure Cloud Shell, or PowerShell. In this post, I’m using Azure Cloud Shell from within VS Code, but it doesn’t really matter if we just focus on logging from APIM to Event Hub. Azure Cloud Shell in Azure Portal Create Resource Group: I create a resource group where I will put all the resources. This way I can easily delete all together once I don’t need it anymore without being unsure whether I can delete a resource or not. # Create Resource GroupNew-AzResourceGroup -Name  apim101-rg  -Location  West Europe Deploy Azure API Management: I have previously created 5 posts about different ways of provisioning Azure API Management. Check them out in case you want to go with another option that with PowerShell. I want to log requests from an API that we first need to deploy. A simple way of doing that is by importing a Swagger-file that specifies an online API like the the Conference API.  # Deploy new instance of Azure API ManagementNew-AzApiManagement -ResourceGroupName  apim101-rg  -Name  svenmalvik-apim  -Sku  Consumption  -Capacity 0 -Location  West Europe  -Organization  svenmalvik. com  -AdminEmail  sven@malvik. de # The context tells us what instance of APIM we're working with$apimCtx = New-AzApiManagementContext -ResourceGroupName  apim101-rg  -ServiceName  svenmalvik-apim # Add Conference API to the APIM instanceImport-AzApiManagementApi -Context $apimCtx -SpecificationFormat  Swagger  -SpecificationUrl  https://conferenceapi. azurewebsites. net?format=json  -Path  conf  -ApiId  confapi We have an instance of Azure API Management up and running, and we have an API with a backend deployed. We can now check if everything works as expected by clicking APIs in the menu of the instance from within the Azure portal. Test API in Azure API Management Deploy Azure Event Hub: I’m using Azure Event Hub to send logs to. Check out the Azure Event Hub documentation for more details. I will first create an Azure Event Hubs namespace. An Event Hubs namespace provides a unique scoping container in which I will create an event hub. # Create Event Hub namespaceNew-AzEventHubNamespace -ResourceGroupName  apim101-rg  -Name  svenmalvik-eh-ns  -Location  West Europe  -SkuName  Basic  -SkuCapacity 1# Create Event HubNew-AzEventHub -ResourceGroupName  apim101-rg  -NamespaceName  svenmalvik-eh-ns  -Name  svenmalvik-eh Add Azure API Management EventHub logger: Now that we have Azure API Management and Azure Event Hub in place, we need to tell APIM where to send logs to. We do this by creating a logger. We can add as many loggers to Azure API Management as we want. We could use one logger for sending logs to Event Hub and another logger for sending logs to Azure Application Insights. # Add Access to Event Hubs namespaceNew-AzEventHubAuthorizationRule -ResourceGroupName  apim101-rg  -NamespaceName  svenmalvik-eh-ns  -AuthorizationRuleName  svenmalvik-eh-auth-rule  -Rights @( Listen ,  Send )# Get the connectionString to the Event Hubs namespace$ehConnection = (Get-AzEventHubKey -ResourceGroupName  apim101-rg  -NamespaceName  svenmalvik-eh-ns  -AuthorizationRuleName  svenmalvik-eh-auth-rule ). PrimaryConnectionString# Create Azure API Management Event Hub loggerNew-AzApiManagementLogger -Context $apimCtx -LoggerId  svenmalvik-logger  -Name  svenmalvik-logger  -ConnectionString  $ehConnection;EntityPath=svenmalvik-eh Add Event Hub logger to API policy: We haven’t talked about policies in Azure API Management. Policies are a powerful capability of the system that allow the publisher to change the behavior of the API through configuration. Policies are a collection of Statements that are executed sequentially on the request or response of an API. You will find more information about Azure API Management policies in the documentation.  We can either deploy a policy with PowerShell, or we open the policy for our API in the portal and add the logger from there. For simplicity reason and to focus on adding the logger, I will add the logger from within the Azure portal. Azure API Management API policy Add the xml code you see below to the inbound-section of the policy. &lt;!-- Create API policy and add Event Hub logger to API --&gt;&lt;log-to-eventhub logger-id ='svenmalvik-logger'&gt;  @( string. Join( , , DateTime. UtcNow, context. Deployment. ServiceName, context. RequestId, context. Request. IpAddress, context. Operation. Name) )&lt;/log-to-eventhub&gt;Install Azure Event Hub Plugin in VS Code: We have set up everything we needed, and the only remaining task we have to do now is to test if logging to the Event Hub is working. For that, I will install the Azure Event Hub Explorer plugin to VS Code. VS Code Plugin Azure Event Hub Explorer Configure now the plugin to manage the newly created Event Hub and start monitoring. Configure Azure Event Hub Explorer When we now send a request to the API, we’ll need to wait some seconds for the plugin to read from the Event Hub. Azure Event Hub Explorer &gt; Start monitoring event hubAzure Event Hub Explorer &gt; Created partition receiver [1] for consumerGroup [$Default]Azure Event Hub Explorer &gt; Created partition receiver [0] for consumerGroup [$Default]Azure Event Hub Explorer &gt; Message Received: 4/8/2020 5:33:09 PM,svenmalvik-apim. azure-api. net,00a166ad-beb4-4b1a-bc56-8faf699eca6e,51. 175. 196. 188,GetTopics Azure Event Hub Explorer &gt; Stop monitoring event hub Conclusion: There were a lot of steps involved in setting up everything from the ground to logging to Azure Event Hub, and I hope this post could help you. Let me know if you have any questions regarding one of the previous steps or some other questions about Azure API Management, and I will try to answer them. Extra:  Logging all headers and the body of a request from Azure API Management to Azure Event Hub"
    }, {
    "id": 64,
    "url": "/azure-apim-deploy-with-terraform/",
    "title": "Azure API Management with Terraform",
    "body": "2020/04/04 - Terraform is a popular tool for managing infrastructure resources. I counted about 120 supported providers. Azure is one of them. In this episode we will provision Azure API Management with Terraform. After downloading and installing Terraform, we will create a folder with a configuration file telling that we use Azure as our provider, and telling it what we want to deploy. We do this either in HashiCorp Configuration Language (HCL) which ends with . tf, or as Json. We will use the HCL language as it’s easier to read, and because we get more documentation and examples we might use. Take a look at this terraform-file for creating a resource group and deploying API Management. provider  azurerm  {  subscription_id =  YOUR_SUBSCRIPTION_ID   tenant_id    =  YOUR_TENANT_ID }resource  azurerm_resource_group   rg  {  name   =  test-rg   location =  westeurope }resource  azurerm_api_management   rg  {  name        =  test-apim   location      =  ${azurerm_resource_group. rg. location}   resource_group_name =  ${azurerm_resource_group. rg. name}   publisher_name   =  YOUR NAME   publisher_email   =  YOUR_EMAIL   sku_name      =  Developer_1 }We notice that the SKU we deploy is one unit of Developer, not Consumption. The latest version of Terraform doesn’t support this yet, and probably many other configurations either. In this case, we could create a pull request and add Consumption in this section in the Terraform project. const (	// SkuTypeBasic Basic SKU of Api Management. 	SkuTypeBasic SkuType =  Basic 	// SkuTypeDeveloper Developer SKU of Api Management. 	SkuTypeDeveloper SkuType =  Developer 	// SkuTypePremium Premium SKU of Api Management. 	SkuTypePremium SkuType =  Premium 	// SkuTypeStandard Standard SKU of Api Management. 	SkuTypeStandard SkuType =  Standard )When first starting to use Terraform, you need to run terraform init to tell Terraform to scan the code, figure out what providers you’re using, and download the code for them. Then we run terraform plan to create an execution plan. Besides syntax check, the execution plan specifies what actions Terraform will take to achieve the desired state defined in the configuration, and the order in which the actions occur. terraform plan We see lots of + prior to configurations which means Terraform will add these features, not change. Terraform is great when we would like to know what will change before we will change anything.  Finally, we need to apply the plan with terraform apply to make any changes in Azure. terraform apply We have now deployed a new instance of API Management to our Azure subscription. New instance of API Management There is one more important information we need to know about, the Terraform state file. When Terraform created our resource group and deployed an APIM instance, it also wrote data into a state file which we can see with terraform show. terraform show Terraform must store state about your managed infrastructure and configuration. This state is used by Terraform to map real world resources to your configuration, keep track of metadata, and to improve performance for large infrastructures. The state file is used for performance improvements, dependency management and syncing between teams. Conclusion: One big advantage of Terraform is better performance because it can store the current state of your resources. In a team of many developers that maintains a large infrastructure and where all work within the same terraform project and the same state-file(s), Terraform doesn’t need to request the values from the provider- it already has all data it needs. Another great thing with Terraform is simple declarative language where we describe what we want instead of imperatively coding how we deploy. The one drawback I can see in relation to Azure API Management is missing features like the Consumption plan. Whatever tool we use to manage cloud, the tool will always be a bit behind of what’s possible in the cloud. In case of Terraform, we can “just” create a pull request and add missing features. "
    }, {
    "id": 65,
    "url": "/azure-apim-deploy-with-arm/",
    "title": "Azure API Management with ARM",
    "body": "2020/03/28 - Deploying an ARM template (Azure Resource Management)-template from GitHub is the simplest way of provisioning an instance of API Management, BUT - there are a couple of things we need to be aware of. Deploy Azure API Management with ARM from GitHub: The Microsoft Azure API Management Product Team has provided some ARM templates with a nice button that let us with a click load some settings into Azure. What’s missing are some parameters like email address, name and SKU that we have to set manually. We want to automate this of course, and we’ll do that in a minute. First, we’ll look at how this manual process works. Azure API Management Templates Let’s Deploy to Azure, and see what happens. Create Azure API Management in the portal Since we have used a public available ARM template, we need to set some parameters. An interesting observation is that the default SKU is Developer. We know that from previous deployments. But if we want to change it to Consumption, we’ll see that it’s not available. This template is from 2017 where Consumption was not available. What I’ve done now is to fork the repo and made some changes in the ARM template. azuredeploy. json I’ve not only added two SKUs, but I’ve also added 0 to skuCount as an allowed value. 0 is the value we have to set for Consumption. Deploying from my fork svenmalvik/azure-quickstart-templates/101-azure-api-management-create will make it possible to choose Consumption as well. I’ve set Consumption as default. To fully automated the deployment of the ARM template, we need to set some more default values like email and name.  Deploy Azure API Management with ARM from a local machine: Instead of clicking a nice blue button on GitHub, I was wondering if I just can apply the ARM template with default values and without any interactions. The code below deploys the remote ARM template that doesn’t need our attention. # Create resource groupNew-AzResourceGroup -Name  apim-with-arm-rg  -Location  West Europe # Deploy remote ARM templateNew-AzResourceGroupDeployment -ResourceGroupName  apim-with-arm-rg  -TemplateUri https://raw. githubusercontent. com/svenmalvik/azure-quickstart-templates/master/101-azure-api-management-create/azuredeploy. jsonDeploy Azure API Management with remote ARM template Conclusion: Working with ARM templates is a bit more work that we’ve seen in a previous post where we deployed API Management with the Azure PowerShell module. The advantage with ARM is its completeness. There are certain configurations like setting a custom domain that we can’t do with PowerShell today and where ARM fits perfectly. "
    }, {
    "id": 66,
    "url": "/azure-apim-deploy-with-powershell/",
    "title": "Azure API Management with PowerShell",
    "body": "2020/03/21 - We use a lot of PowerShell to provision the Azure infrastructure that powers Vipps AS today. PowerShell is actually a great choice for using working with APIM since it great supported. The PowerShell for Azure is actually using the REST API, so you can expect to get the same support. In case you would like to see the REST API in action for provisioning API Management, you can follow the link. I will use PowerShell to provision an instance of API Management today. Let’s start by connecting to our Azure account by executing this PowerShell code: Connect-AzAccount -SubscriptionId  &lt;SUBSCRIPTION_ID&gt;  -Tenant  &lt;TENANT_ID&gt; You will be redirected to Microsoft within your browser to login. When everything is correct, you can proceed in your PowerShell editor. Whenever we provision a resource, we need to add it to a resource group. In case you didn’t create one previously, you run this code: New-AzResourceGroup -Name  apim-rg  -Location  West Europe It’s always a good idea to tag your resources. We’ll cover this in a later post. Deploying API Management: Now it’s time to deploy an instance by executing this PowerShell code: New-AzApiManagement -ResourceGroupName  apim-rg  -Name  apim-service  -Location  West Europe  -Organization  &lt;ORGANIZATION&gt;  -AdminEmail  sven@malvik. de The deployment takes about 2 minutes. In case we’d deployed with SKU Developer, we’d need to wait up to an hour. You can verify this by going into your portal and navigate to your new instance.  Importing an API: It’s not part of this post, but I really want to show it because it’s very simple as well. What you need is a Swagger-file. There are many other options of creating an API, but that is part of a later post as well. I will use the public available Conference API and put the link to it in a variable. $SwaggerfileUrl =  https://conferenceapi. azurewebsites. net?format=json We need to create a context. We are basically telling what instance of APIM we want to use. Specify the resource group and the name of your instance. $apimContext = New-AzApiManagementContext -ResourceGroupName  apim-rg  -ServiceName  apim-service Finally, we can import the API by defining the url of our swagger file, a path that a request will use to reach the API, and an ApiId that you can choose yourself. Import-AzApiManagementApi -Context $apimContext -SpecificationFormat  Swagger  -SpecificationUrl $SwaggerfileUrl -Path  conference  -ApiId  conferenceAPI Click for the final PowerShell-code Conclusion: We used PowerShell to create an instance of API Management. As mentioned above, PowerShell is actually a great tool for working with API Management. But there are lots of other options to choose of when provisioning APIM. "
    }, {
    "id": 67,
    "url": "/azure-apim-deploy-with-rest/",
    "title": "Azure API Management with REST",
    "body": "2020/03/14 - Today, we will provision Azure API Management by using Postman as an API client, sending plain web requests to Azure. We already provisioned an APIM instance in the last post from within the Azure Portal. This is the fastest way of getting an instance up and running to try out APIM. But if you want to put an instance into production, we should be able to automate this process. Provisioning with REST can be one step in that direction. Create a Service Principal with the Azure CLI: Whenever we send a request to Azure, we need to set an Authorization token in the header. We get this token by creating a Service Principal. Let’s first login. We use the Azure CLI for that. The Json response gives us two information that we need. Id which is our subscriptionId and the tenantId. The Json response gives us two information that we need. Id which is our subscriptionId and the tenantId. az login Then, we create the service principal and give it a name. Create service principal We got now also the password of the service principal that we’ll need for retrieving the access token. 2 Different Ways of Retrieving an Access Token: We will need Postman, so great if you can download and install Postman first. Otherwise, cURL works just fine of course. It’s just less work because I will share a pre-made collection of requests with you. When you have installed Postman, you can simply load a collection of requests into Postman. You should now see this in Postman. Postman Collection Click on the Settings icon of the “Azure REST”-collection in the top-right corner for setting the parameters like TenantId, ClientId (AppId), ClientSecret (Password) and SubscriptionId.  Postman Environment Variables We can now send the first request for retrieving an access token. Azure Access Token in Postman There we are. Actually, there is a simpler way of retrieving an access token through the Azure CLI directly. This works fine in case you just want to try out some API endpoints. az account get-access-token It’s now time to create an instance of API Management. Create an instance of API Management with Postman: Create a new request inside the Azure REST collection in Postman by copying the example request from the API Management documentation. Create a PUT request with the following url. Remember to replace the values. https://management. azure. com/subscriptions/YOUR_SUBSCRIPTIONID/resourceGroups/YOUR_RESOURCEGROUP/providers/Microsoft. ApiManagement/service/YOUR_APIM_INSTANCE_NAME?api-version=2019-01-01 Then, add an Authorization header with the following bearer token Bearer The bearer token gets picked up by Postman when we retrieve the access token. Take a look at the “Test” pane of this request. You could also paste in the access token directly of course. Last, put this json payload inside the body: {  properties : {   publisherEmail :  YOUR_EMAIL ,   publisherName :  YOUR_NAME  },  sku : {   name :  Consumption ,   capacity : 0 },  location :  West Europe ,  tags : {   Owner :  YOUR_NAME  }}Let’s now send the request. Postman send request That was a success and we can see the result in the portal. Created Azure API Management instance from Postman Conclusion: Provisioning an instance of API Management with REST is a pretty straightforward process. The only complicated task was to create a service principal (spn). This spn is not configured yet, and we should do this, but it’s content for another post. "
    }, {
    "id": 68,
    "url": "/azure-apim-deploy-with-portal/",
    "title": "Azure API Management from the Portal",
    "body": "2020/03/07 - We will provision Azure API Management. Creating an instance of it is just a click in the Azure Portal. We’ll do it once to show how easy it is before we move forward to some other ways that enable us to automate it. The first thing we will do is to “Create a resource”, type “Api Management” and click the resource that is shown in the drop down menu. Search Azure API Management in the Portal Then click create. Select Azure API Management in the Portal You will now see the pane where you set some important parameters. Azure API Management Form Chose the subscription you want to provision you instance to and a resource group. We will talk about resource groups later because they are interesting when it comes to global services that we spin up. They also need the resource group which gets a region. The most important parameter is the Pricing Tier (SKU). The default value is Developer. In case you just want to try out the service, Consumption is a good choice as we only pay per request, and we don’t need to delete it when we need a longer break. It’s also a good choice in case you are impatient. Creating an instance takes about a minute compared to the other choices that take up to an hour.  Do want to monitor your instance? If you just want to play with Azure API Management as we do, we probably don’t need it. We will save some money not enabling it for now. We got now a our first instance of Azure API Management! Azure API Management Overview You know already all values that we see in the Overview of it. There is just one value that is new “Gateway URL”. It’s the Url that we the clients will use to access APIs. Let’s try it out. Response from a test call to Azure API Management We have no API yet, so we won’t get a meaningful result back. But we will get to that part in a bit. For now we are just happy and wonder how we can provision an instance with either real code or with a proper REST call. Conclusion: We have now created an instance of Azure API Management that does nothing. But it seems to work. Before we will dive into all the menus on the left side, we should look at some better options to create an instance. Options that we can use to automate our set up. "
    }, {
    "id": 69,
    "url": "/azure-apim-key-parameters/",
    "title": "Azure API Management Key Parameters",
    "body": "2020/02/29 - This post will start to discuss provisioning API Management. The simplest way of doing so is simply by signing into the portal and create it - we’ll do so in a minute - but this is not the only way we can and should provision API Management. There are other ways that are more effective depending on your environment. Before we can do all this, we need first take a look at some key parameters when creating an instance. Explain those API-M parameters that are key. : The most important parameter you need to set when provisioning API-M is the type of instance you want to provision, SKU. SKU stands for Stock Keeping Unit. There are 5 different SKUs to choose of. Azure API Management SKU Developer and Premium are pretty similar. Both can be put into an own private virtual network. It means we can set up a network security group and filter network traffic based on rules we set. We could for example say that we only allow traffic from another defined virtual network where an Application Gateway lives. We will talk about this service later, but in short, it is a load balancer operating on layer-7 with a public ip address. The main differences between those two SKUs is the capacity and the scaling option. Scaling is missing in the developer SKU -why would we need that :) Basic and Standard are also similar to each other -besides the capacity. What the basic SKU is missing is AAD integration. AAD stands for Azure Active Directory which is Microsoft’s cloud-based identity and access management service. It helps your employees to sign in and access resources. The newest SKU is Consumption which is a pretty good type when developing on your own. It runs on a shared infrastructure. It’s really nice for trying out your APIs for example where we pay only per request. Since it’s a shared type, provisioning takes only a few minutes compared to the other SKUs where we can watch an entire one hour conference-talk while waiting. But the real benefit comes in production in case where you have to handle spikes. Azure API Management will scale for you. It’s the perfect plan for low traffic APIs that might handle high-traffic sometimes. What does Capacity mean in this context?: Capacity is an indicator of load on an API Management instance. It reflects resources usage (CPU, memory) and network queue lengths. It’s an important metric that you must keep an eye on in the Azure Monitor. The default value when provisioning is “1” unit of the chosen SKU, so you might consider more units for production. It really depends on your load. If this metric shows a value above 60% load over approximately 30 minutes, Microsoft recommends to consider to scale up. This can take up to 45 minutes. What about the other parameters?: Name, Location, Organization, ResourceGroupName, Tag and some more are self explaining. But there are a few more like VirtualNetwork, AssignIdentity and CustomHostnameConfiguration that are interesting, and we will discuss all of them in detail in a later post. We ignore them for now and configure them later.  Conclusion: We got all the parameters we need to for provisioning an API-M instance. SKU was the most important parameter, the default is Developer which is a bit more expensive than Consumption. In the next post, we will provision an instance in 3 different ways and discuss advantages and disadvantages before we start to do some exciting stuff with it. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});


    
function lunr_search(term) {
    $('#lunrsearchresults').show( 1000 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
</script>
<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>




<form class="bd-search hidden-sm-down" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
<input type="text" class="form-control text-small"  id="lunrsearch" name="q" value="" placeholder="Type keyword and enter..."> 
</form>
            </ul>
        </div>
    </div>
    </nav>

    <!-- Search Results -->
    <div id="lunrsearchresults">
        <ul class="mb-0"></ul>
    </div>

    <!-- Content -->
    <main role="main" class="site-content">
        
<div class="container d-none d-md-block" style="margin-bottom: 10px; text-align: center;">
	<script type="text/javascript" language="javascript" src="https://www.anrdoezrs.net/placeholder-46382047?target=_top&mouseover=N"></script>
</div>
<div class="container d-md-none" style="margin-bottom: 10px; text-align: center;">
    <script type="text/javascript" language="javascript" src="https://www.anrdoezrs.net/placeholder-46383864?target=_top&mouseover=N"></script>
</div>

<div class="container">

<div class="jumbotron jumbotron-fluid mb-3 pl-0 pt-0 pb-0 bg-white position-relative">
		<div class="h-100 tofront">
			<div class="row  justify-content-between ">
				<div class=" col-md-6  pr-0 pr-md-4 pt-4 pb-4 align-self-center">
					<p class="text-uppercase font-weight-bold">
                        <span class="catlist">
						
                          <a class="sscroll text-dark" href="https://www.svenmalvik.com/categories.html#azure api management">azure api management</a><span class="sep">, </span>
                        
                        </span>
					</p>
					<h1 class="display-4 mb-4 article-headline">Logging in Azure API Management</h1>
					<div class="d-flex align-items-center">
                        
                        <img class="rounded-circle" src="https://www.svenmalvik.comhttps://cdn.svenmalvik.com/images/svenmalvik.jpg" alt="Sven Malvik" width="70"/>
                        
						<small class="ml-3"> Sven Malvik <span><a target="_blank" href="https://www.linkedin.com/in/svenmalvik/" class="btn btn-outline-success btn-sm btn-round ml-1">Connect</a></span>
                            <span class="text-muted d-block mt-1">Apr 11, 2020 · <span class="reading-time">
  
  
    6 mins read
  
</span>
    </span>
						</small>
					</div>
				</div>
                
				<div class="col-md-6 pr-0 align-self-center">
					<img class="rounded" src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-video-1.jpg" alt="Logging in Azure API Management">
				</div>
                
			</div>
		</div>
	</div>
</div>





<div class="container-lg pt-4 pb-4">
	<div class="row justify-content-center">
        
        
        <!-- Share -->
		<div class="col-lg-2 pr-4 mb-4 col-md-12">
			<div class="sticky-top sticky-top-offset text-center">
				<div style="text-align: left;">
					<I style="font-size: 0.8em; color: #999;">Ad</I>
					<br>
					<a href="https://www.kqzyfj.com/click-100299205-13350263?url=https%3A%2F%2Fwww.apress.com%2Fde%2Fbook%2F9781484244432%3Futm_medium%3Daffiliate%26utm_source%3Dcommission_junction%26utm_campaign%3D3_nsn6445_product_PID%25zp%26utm_content%3Dde_05032018%23otherversion%3D9781484244432&cjsku=9781484244432" target="_top">
						Beginning Azure Functions</a><img src="https://www.awltovhc.com/image-100299205-13350263" width="1" height="1" border="0"/>
				</div>
				<div>
					<a href="https://www.anrdoezrs.net/click-100299205-13350263?url=https%3A%2F%2Fwww.apress.com%2Fde%2Fbook%2F9781484244432%3Futm_medium%3Daffiliate%26utm_source%3Dcommission_junction%26utm_campaign%3D3_nsn6445_product_PID%25zp%26utm_content%3Dde_05032018%23otherversion%3D9781484244432&cjsku=9781484244432" target="_top"><img src="https://covers.springernature.com/books/jpg_width_153_pixels/9781484244432.jpg" border="0" alt="Beginning Azure Functions"/></a><img src="https://www.awltovhc.com/image-100299205-13350263" width="1" height="1" border="0"/>
				</div>
				<div class="text-muted mt-3">
					Share this
				</div>
				<div class="share d-inline-block">
					<!-- AddToAny BEGIN -->
					<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
						<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
						<a class="a2a_button_facebook"></a>
						<a class="a2a_button_twitter"></a>
					</div>
					<script async src="https://static.addtoany.com/menu/page.js"></script>
					<!-- AddToAny END -->
				</div>
			</div>
		</div>
        
        
		<div class="col-md-12 col-lg-8">
            
            <!-- Article -->
			<article class="article-post">                
			<p><em>This post is a complete step-by-step guide on how to send logs from Azure API Management to Azure Event Hub with PowerShell. We start by creating an instance of APIM, Event Hubs Namespace together with an Event Hub, and finish by watching incoming events with help of a VS Code Plugin.</em></p>

<hr />

<p><a href="https://www.youtube.com/watch?v=xS_KGuCXVVw"><img src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-video-1.jpg" alt="Logging from Azure API Management to Azure Event Hub" title="Logging from Azure API Management to Azure Event Hub" /></a><em>Watch this post on YouTube: Logging from Azure API Management to Azure Event Hub</em></p>

<h2 id="agenda">Agenda</h2>

<ul>
  <li>Deploy Azure API Management</li>
  <li>Add API</li>
  <li>Deploy Azure Event Hub</li>
  <li>Add logger to APIM</li>
  <li>Install Azure Event Hub Plugin in VSCode</li>
</ul>

<hr />

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5867637072125128" data-ad-slot="6992142934"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<h2 id="connecting-to-azure">Connecting to Azure</h2>
<p>There are many ways we can use to connect to Azure like using <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest">Azure CLI</a>, <a href="https://docs.microsoft.com/en-us/azure/cloud-shell/overview">Azure Cloud Shell</a>, or PowerShell. In this post, I’m using Azure Cloud Shell from within <a href="https://code.visualstudio.com/">VS Code</a>, but it doesn’t really matter if we just focus on logging from APIM to Event Hub.</p>

<p><img src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-0.png" alt="Azure Cloud Shell in Azure Portal" title="Azure Cloud Shell in Azure Portal" /><em>Azure Cloud Shell in Azure Portal</em></p>

<h2 id="create-resource-group">Create Resource Group</h2>

<p>I create a resource group where I will put all the resources. This way I can easily delete all together once I don’t need it anymore without being unsure whether I can delete a resource or not.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create Resource Group</span>
New-AzResourceGroup -Name <span class="s2">"apim101-rg"</span> -Location <span class="s2">"West Europe"</span>
</code></pre></div></div>

<h2 id="deploy-azure-api-management">Deploy Azure API Management</h2>

<p>I have previously created 5 posts about different ways of provisioning Azure API Management. Check them out in case you want to go with another option that with PowerShell.</p>

<p>I want to log requests from an API that we first need to deploy. A simple way of doing that is by importing a Swagger-file that specifies an online API like the the <a href="https://conferenceapi.azurewebsites.net?format=json">Conference API</a>.</p>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5867637072125128" data-ad-slot="6992142934"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Deploy new instance of Azure API Management</span>
New-AzApiManagement -ResourceGroupName <span class="s2">"apim101-rg"</span> -Name <span class="s2">"svenmalvik-apim"</span> -Sku <span class="s2">"Consumption"</span> -Capacity 0 -Location <span class="s2">"West Europe"</span> -Organization <span class="s2">"svenmalvik.com"</span> -AdminEmail <span class="s2">"sven@malvik.de"</span>

<span class="c1"># The context tells us what instance of APIM we're working with</span>
<span class="nv">$apimCtx</span> <span class="o">=</span> New-AzApiManagementContext -ResourceGroupName <span class="s2">"apim101-rg"</span> -ServiceName <span class="s2">"svenmalvik-apim"</span>

<span class="c1"># Add Conference API to the APIM instance</span>
Import-AzApiManagementApi -Context <span class="nv">$apimCtx</span> -SpecificationFormat <span class="s2">"Swagger"</span> -SpecificationUrl <span class="s2">"https://conferenceapi.azurewebsites.net?format=json"</span> -Path <span class="s2">"conf"</span> -ApiId <span class="s2">"confapi"</span>
</code></pre></div></div>
<p>We have an instance of Azure API Management up and running, and we have an API with a backend deployed. We can now check if everything works as expected by clicking APIs in the menu of the instance from within the Azure portal.</p>

<p><img src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-1.png" alt="Test API in Azure API Management" title="Test API in Azure API Management" /><em>Test API in Azure API Management</em></p>

<h2 id="deploy-azure-event-hub">Deploy Azure Event Hub</h2>

<p>I’m using Azure Event Hub to send logs to. Check out the <a href="https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-about">Azure Event Hub documentation</a> for more details.</p>

<p>I will first create an Azure Event Hubs namespace. An Event Hubs namespace provides a unique scoping container in which I will create an event hub.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create Event Hub namespace</span>
New-AzEventHubNamespace -ResourceGroupName <span class="s2">"apim101-rg"</span> -Name <span class="s2">"svenmalvik-eh-ns"</span> -Location <span class="s2">"West Europe"</span> -SkuName <span class="s2">"Basic"</span> -SkuCapacity 1

<span class="c1"># Create Event Hub</span>
New-AzEventHub -ResourceGroupName <span class="s2">"apim101-rg"</span> -NamespaceName <span class="s2">"svenmalvik-eh-ns"</span> -Name <span class="s2">"svenmalvik-eh"</span>
</code></pre></div></div>

<h2 id="add-azure-api-management-eventhub-logger">Add Azure API Management EventHub logger</h2>

<p>Now that we have Azure API Management and Azure Event Hub in place, we need to tell APIM where to send logs to. We do this by creating a logger. We can add as many loggers to Azure API Management as we want. We could use one logger for sending logs to Event Hub and another logger for sending logs to Azure Application Insights.</p>

<div class="language-powershell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Add Access to Event Hubs namespace</span>
New-AzEventHubAuthorizationRule -ResourceGroupName <span class="s2">"apim101-rg"</span> -NamespaceName <span class="s2">"svenmalvik-eh-ns"</span> -AuthorizationRuleName <span class="s2">"svenmalvik-eh-auth-rule"</span> -Rights @<span class="o">(</span><span class="s2">"Listen"</span>, <span class="s2">"Send"</span><span class="o">)</span>

<span class="c1"># Get the connectionString to the Event Hubs namespace</span>
<span class="nv">$ehConnection</span> <span class="o">=</span> <span class="o">(</span>Get-AzEventHubKey -ResourceGroupName <span class="s2">"apim101-rg"</span> -NamespaceName <span class="s2">"svenmalvik-eh-ns"</span> -AuthorizationRuleName <span class="s2">"svenmalvik-eh-auth-rule"</span><span class="o">)</span>.PrimaryConnectionString

<span class="c1"># Create Azure API Management Event Hub logger</span>
New-AzApiManagementLogger -Context <span class="nv">$apimCtx</span> -LoggerId <span class="s2">"svenmalvik-logger"</span> -Name <span class="s2">"svenmalvik-logger"</span> -ConnectionString <span class="s2">"</span><span class="nv">$ehConnection</span><span class="s2">;EntityPath=svenmalvik-eh"</span>
</code></pre></div></div>

<h2 id="add-event-hub-logger-to-api-policy">Add Event Hub logger to API policy</h2>

<p>We haven’t talked about policies in Azure API Management. Policies are a powerful capability of the system that allow the publisher to change the behavior of the API through configuration. Policies are a collection of Statements that are executed sequentially on the request or response of an API. You will find more information about <a href="https://docs.microsoft.com/en-us/azure/api-management/api-management-policies">Azure API Management policies</a> in the documentation.</p>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5867637072125128" data-ad-slot="6992142934"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></p>

<p>We can either deploy a policy with PowerShell, or we open the policy for our API in the portal and add the logger from there. For simplicity reason and to focus on adding the logger, I will add the logger from within the Azure portal.</p>

<p><img src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-3.png" alt="Azure API Management API policy" title="Azure API Management API policy" /><em>Azure API Management API policy</em></p>

<p>Add the xml code you see below to the <code class="highlighter-rouge">inbound</code>-section of the policy.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">&lt;!-- Create API policy and add Event Hub logger to API --&gt;</span>
<span class="nt">&lt;log-to-eventhub</span> <span class="na">logger-id =</span><span class="s">'svenmalvik-logger'</span><span class="nt">&gt;</span>
    @( string.Join(",", DateTime.UtcNow, context.Deployment.ServiceName, context.RequestId, context.Request.IpAddress, context.Operation.Name) )
<span class="nt">&lt;/log-to-eventhub&gt;</span>
</code></pre></div></div>

<h2 id="install-azure-event-hub-plugin-in-vs-code">Install Azure Event Hub Plugin in VS Code</h2>

<p>We have set up everything we needed, and the only remaining task we have to do now is to test if logging to the Event Hub is working. For that, I will install the <code class="highlighter-rouge">Azure Event Hub Explorer</code> plugin to VS Code.</p>

<p><img src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-4.png" alt="VS Code Plugin Azure Event Hub Explorer" title="VS Code Plugin Azure Event Hub Explorer" /><em>VS Code Plugin Azure Event Hub Explorer</em></p>

<p>Configure now the plugin to manage the newly created Event Hub and start monitoring.</p>

<p><img src="https://cdn.svenmalvik.com/images/azure-apim-with-eventhub-5.png" alt="Configure Azure Event Hub Explorer" title="Configure Azure Event Hub Explorer" /><em>Configure Azure Event Hub Explorer</em></p>

<p>When we now send a request to the API, we’ll need to wait some seconds for the plugin to read from the Event Hub.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Azure Event Hub Explorer &gt; Start monitoring event hub
Azure Event Hub Explorer &gt; Created partition receiver [1] for consumerGroup [$Default]
Azure Event Hub Explorer &gt; Created partition receiver [0] for consumerGroup [$Default]
Azure Event Hub Explorer &gt; Message Received:
"4/8/2020 5:33:09 PM,svenmalvik-apim.azure-api.net,00a166ad-beb4-4b1a-bc56-8faf699eca6e,51.175.196.188,GetTopics"
Azure Event Hub Explorer &gt; Stop monitoring event hub
</code></pre></div></div>

<script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<p><ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-5867637072125128" data-ad-slot="6992142934"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></p>
<h2 id="conclusion">Conclusion</h2>

<p>There were a lot of steps involved in setting up everything from the ground to logging to Azure Event Hub, and I hope this post could help you. Let me know if you have any questions regarding one of the previous steps or some other questions about Azure API Management, and I will try to answer them.</p>

<h2 id="extra">Extra</h2>

<ul>
  <li><a href="https://gist.github.com/svenmalvik/f86a80e252fe502cb55d3f4fa97d4e08">Logging all headers and the body of a request from Azure API Management to Azure Event Hub</a></li>
</ul>
                
			</article>
			
			<!-- Tags -->
			<div class="mb-4">
				<span class="taglist">
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="https://www.svenmalvik.com/tags.html#featured">featured</a>
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="https://www.svenmalvik.com/tags.html#azure">azure</a>
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="https://www.svenmalvik.com/tags.html#azure api management">azure api management</a>
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="https://www.svenmalvik.com/tags.html#azure event hub">azure event hub</a>
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="https://www.svenmalvik.com/tags.html#azure application insights">azure application insights</a>
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="https://www.svenmalvik.com/tags.html#powershell">powershell</a>
				
				</span>
			</div>

 
            <!-- Mailchimp Subscribe Form -->
            
			<div class="border p-5 bg-lightblue">
				<div class="row justify-content-between">
					<div class="col-md-6 mb-2 mb-md-0">
						<h5 class="font-weight-bold">Join Newsletter</h5>
						 Get the latest updates right in your inbox. I never spam!
					</div>
					<div class="col-md-6">
						<div class="row">
                            <form action="http://eepurl.com/hnE_Zf" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate w-100" target="_blank" novalidate>
                            <div class="mc-field-group">
							
								<input type="email" placeholder="Enter e-mail address" name="EMAIL" class="required email form-control w-100" id="mce-EMAIL" autocomplete="on" required>
							
							
								<button type="submit" value="Subscribe" name="subscribe" class="heart btn btn-success btn-block w-100 mt-2">Subscribe</button>
							
                            </div>
                            </form>
						</div>
					</div>
				</div>
			</div>
            
            
            
             <!-- Author Box -->
                				
				<div class="row mt-5">
					<div class="col-md-2 align-self-center">
                         
                        <img class="rounded-circle" src="https://www.svenmalvik.comhttps://cdn.svenmalvik.com/images/svenmalvik.jpg" alt="Sven Malvik" width="90"/>
                         
					</div>
					<div class="col-md-10">		
                        <h5 class="font-weight-bold">Written by Sven Malvik </h5>
											
					</div>
				</div>				
                
            
            <!-- Comments -->
            
                <!--  Don't edit anything here. Set your disqus id in _config.yml -->

<div id="comments" class="mt-5">
    <div id="disqus_thread">
    </div>
    <script type="text/javascript">
        var disqus_shortname = 'demowebsite'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>
    Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>
</div>
            

					<!-- All Stories -->
			<div class="d-none d-md-block col-md-12 main-loop mt-3">

				<h4 class="font-weight-bold spanborder"><span>Latest Stories</span></h4>
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/event-driven-infrastructure-with-app-configuration/">Event-Driven Infrastructure with App Configuration</a>
		</h2>
		<p class="excerpt">
		Azure App Configuration is great for externalizing application configurations. But what if an application is our infrastructure? How coul...
		</p>

		<small class="text-muted">
			Sep 12, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/event-driven-infrastructure-with-app-configuration/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/appc-apim-autmation-eventgrid-logos.png" alt="Event-Driven Infrastructure with App Configuration">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-policies/">Understanding Policies in Azure API Management</a>
		</h2>
		<p class="excerpt">
		Policies are the heart of Azure API Management. They let us change the behavior of our APIs in a very flexible manner. Before I dive in t...
		</p>

		<small class="text-muted">
			Apr 18, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-policies/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-policies-0.png" alt="Understanding Policies in Azure API Management">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-deploy-with-powershell/">Azure API Management with PowerShell</a>
		</h2>
		<p class="excerpt">
		We use a lot of PowerShell to provision the Azure infrastructure that powers Vipps AS today. PowerShell is actually a great choice for us...
		</p>

		<small class="text-muted">
			Mar 21, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-deploy-with-powershell/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-logo.jpg" alt="Azure API Management with PowerShell">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-policy-debugging/">How To Debug Policies in Azure API Management. A Step-by-Step Guide.</a>
		</h2>
		<p class="excerpt">
		In this post I want to briefly go through the Azure API Management extension for VSCode and how we can debug policies. It’s one of the qu...
		</p>

		<small class="text-muted">
			Jan 16, 2021
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-policy-debugging/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-policy-debugging-cover.jpg" alt="How To Debug Policies in Azure API Management. A Step-by-Step Guide.">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-introduction/">Introduction to Azure API Management</a>
		</h2>
		<p class="excerpt">
		Azure API Management (APIM) is a way to create consistent and modern API gateways for existing backend services. It provides an interface...
		</p>

		<small class="text-muted">
			Jan 25, 2021
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-introduction/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-introduction.jpg" alt="Introduction to Azure API Management">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-backup-restore/">Backup and Restore in Azure API Management</a>
		</h2>
		<p class="excerpt">
		As infrastructure gets more complex, more parts will eventually break. This is even more true as we make frequently changes. Sometimes we...
		</p>

		<small class="text-muted">
			May 02, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-backup-restore/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-backup-restore.jpg" alt="Backup and Restore in Azure API Management">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-key-vault/">How to Reference Key Vault Secrets in Azure API Management</a>
		</h2>
		<p class="excerpt">
		In an enterprise, an Azure API Management instance is often shared by many teams and many developers. The developers may all have access ...
		</p>

		<small class="text-muted">
			Feb 05, 2021
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-key-vault/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-kv-secrets.jpg" alt="How to Reference Key Vault Secrets in Azure API Management">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-function-msi/">How to Secure Azure Functions App with Azure API Management</a>
		</h2>
		<p class="excerpt">
		How to use an Azure Managed Identity to authenticate against an Azure Functions app that is exposed through Azure API Management. Our Fun...
		</p>

		<small class="text-muted">
			Feb 02, 2021
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-function-msi/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-function-identity.jpg" alt="How to Secure Azure Functions App with Azure API Management">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-vm/">How To Manage Azure Virtual Machines</a>
		</h2>
		<p class="excerpt">
		I will go through the first steps for managing Virtual Machines. We will create a Windows VM, start the Internet Information Service IIS,...
		</p>

		<small class="text-muted">
			Dec 26, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-vm/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/az-303/azure-vm.jpg" alt="How To Manage Azure Virtual Machines">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-deploy-with-terraform/">Azure API Management with Terraform</a>
		</h2>
		<p class="excerpt">
		Terraform is a popular tool for managing infrastructure resources. I counted about 120 supported providers. Azure is one of them. In this...
		</p>

		<small class="text-muted">
			Apr 04, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-apim-deploy-with-terraform/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-logo.jpg" alt="Azure API Management with Terraform">
		</a>
	</div>

</div>

	
				
				
				
					<div class="d-flex justify-content-between main-loop-card mb-3">
	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
		<a class="text-dark" href="https://www.svenmalvik.com/azure-cdn-with-ssl/">Serving Website Images from Azure CDN with SSL</a>
		</h2>
		<p class="excerpt">
		In this post I will show you step by step how to serve images on a website from Azure CDN with SSL enabled. My blog has a couple of Azure...
		</p>

		<small class="text-muted">
			Apr 25, 2020
		</small>
	</div>

	
	<div class="col-md-5 pr-0 text-right">
		<a href="https://www.svenmalvik.com/azure-cdn-with-ssl/">
		<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-cdn-with-ssl.jpg" alt="Serving Website Images from Azure CDN with SSL">
		</a>
	</div>

</div>

	
				
				
			
			</div>

			<div class="d-md-none col-md-12 main-loop mt-3">
		
				<h4 class="font-weight-bold spanborder"><span>Latest Stories</span></h4>
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/event-driven-infrastructure-with-app-configuration/">Event-Driven Infrastructure with App Configuration</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/event-driven-infrastructure-with-app-configuration/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/appc-apim-autmation-eventgrid-logos.png" alt="Event-Driven Infrastructure with App Configuration">
		</a>
		
		
		<p class="excerpt">
		Azure App Configuration is great for externalizing application configurations. But what if an application is our infrastructure? How coul...
		</p>

		<small class="text-muted">
			Sep 12, 2020
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-policies/">Understanding Policies in Azure API Management</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-policies/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-policies-0.png" alt="Understanding Policies in Azure API Management">
		</a>
		
		
		<p class="excerpt">
		Policies are the heart of Azure API Management. They let us change the behavior of our APIs in a very flexible manner. Before I dive in t...
		</p>

		<small class="text-muted">
			Apr 18, 2020
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-deploy-with-powershell/">Azure API Management with PowerShell</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-deploy-with-powershell/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-logo.jpg" alt="Azure API Management with PowerShell">
		</a>
		
		
		<p class="excerpt">
		We use a lot of PowerShell to provision the Azure infrastructure that powers Vipps AS today. PowerShell is actually a great choice for us...
		</p>

		<small class="text-muted">
			Mar 21, 2020
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-policy-debugging/">How To Debug Policies in Azure API Management. A Step-by-Step Guide.</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-policy-debugging/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-policy-debugging-cover.jpg" alt="How To Debug Policies in Azure API Management. A Step-by-Step Guide.">
		</a>
		
		
		<p class="excerpt">
		In this post I want to briefly go through the Azure API Management extension for VSCode and how we can debug policies. It’s one of the qu...
		</p>

		<small class="text-muted">
			Jan 16, 2021
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-introduction/">Introduction to Azure API Management</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-introduction/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-introduction.jpg" alt="Introduction to Azure API Management">
		</a>
		
		
		<p class="excerpt">
		Azure API Management (APIM) is a way to create consistent and modern API gateways for existing backend services. It provides an interface...
		</p>

		<small class="text-muted">
			Jan 25, 2021
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-backup-restore/">Backup and Restore in Azure API Management</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-backup-restore/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-backup-restore.jpg" alt="Backup and Restore in Azure API Management">
		</a>
		
		
		<p class="excerpt">
		As infrastructure gets more complex, more parts will eventually break. This is even more true as we make frequently changes. Sometimes we...
		</p>

		<small class="text-muted">
			May 02, 2020
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-key-vault/">How to Reference Key Vault Secrets in Azure API Management</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-key-vault/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-kv-secrets.jpg" alt="How to Reference Key Vault Secrets in Azure API Management">
		</a>
		
		
		<p class="excerpt">
		In an enterprise, an Azure API Management instance is often shared by many teams and many developers. The developers may all have access ...
		</p>

		<small class="text-muted">
			Feb 05, 2021
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-function-msi/">How to Secure Azure Functions App with Azure API Management</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-function-msi/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-function-identity.jpg" alt="How to Secure Azure Functions App with Azure API Management">
		</a>
		
		
		<p class="excerpt">
		How to use an Azure Managed Identity to authenticate against an Azure Functions app that is exposed through Azure API Management. Our Fun...
		</p>

		<small class="text-muted">
			Feb 02, 2021
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-vm/">How To Manage Azure Virtual Machines</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-vm/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/az-303/azure-vm.jpg" alt="How To Manage Azure Virtual Machines">
		</a>
		
		
		<p class="excerpt">
		I will go through the first steps for managing Virtual Machines. We will create a Windows VM, start the Internet Information Service IIS,...
		</p>

		<small class="text-muted">
			Dec 26, 2020
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-apim-deploy-with-terraform/">Azure API Management with Terraform</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-apim-deploy-with-terraform/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-apim-logo.jpg" alt="Azure API Management with Terraform">
		</a>
		
		
		<p class="excerpt">
		Terraform is a popular tool for managing infrastructure resources. I counted about 120 supported providers. Azure is one of them. In this...
		</p>

		<small class="text-muted">
			Apr 04, 2020
		</small>
	</div>


</div>

	
				
				
				
					<div class="main-loop-card mb-3">

	<div class="pr-3">
		<h2 class="mb-1 h4 font-weight-bold">
			<a class="text-dark" href="https://www.svenmalvik.com/azure-cdn-with-ssl/">Serving Website Images from Azure CDN with SSL</a>
		</h2>

		
		<a href="https://www.svenmalvik.com/azure-cdn-with-ssl/">
			<img class="w-100" src="https://cdn.svenmalvik.com/images/azure-cdn-with-ssl.jpg" alt="Serving Website Images from Azure CDN with SSL">
		</a>
		
		
		<p class="excerpt">
		In this post I will show you step by step how to serve images on a website from Azure CDN with SSL enabled. My blog has a couple of Azure...
		</p>

		<small class="text-muted">
			Apr 25, 2020
		</small>
	</div>


</div>

	
				
				
			
			</div>

			<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5867637072125128"
     data-ad-slot="6992142934"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
            
		</div>


        
        
	</div>
</div>


<!-- Aletbar Prev/Next -->
<div class="alertbar">
    <div class="container">
        <div class="row prevnextlinks small font-weight-bold">
          
            <div class="col-md-6 rightborder pl-0">
                <a class="text-dark" href="https://www.svenmalvik.com/azure-apim-deploy-with-terraform/"> <img height="30px" class="mr-1" src="https://cdn.svenmalvik.com/images/azure-apim-logo.jpg">  Azure API Management with Terraform</a>
            </div>
          
          
            <div class="col-md-6 text-right pr-0">
                <a class="text-dark" href="https://www.svenmalvik.com/azure-apim-policies/"> Understanding Policies in Azure API Management  <img height="30px" class="ml-1" src="https://cdn.svenmalvik.com/images/azure-apim-policies-0.png"> </a>
            </div>
          
        </div>
    </div>
</div>

    </main>


    <!-- Scripts: popper, bootstrap, theme, lunr -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

    <script src="https://www.svenmalvik.com/assets/js/theme.js"></script>


    <!-- Footer -->
    <footer class="bg-white border-top p-3 text-muted small">
        <div class="container">
        <div class="row align-items-center justify-content-between">
            <div>
                Sven Malvik - Microsoft Azure MVP
            </div>
        </div>
        </div>
    </footer>

    <!-- All this area goes before </body> closing tag --> 

    <style>
    #cookie-notice {padding: 0.5rem 1rem; display: none; text-align: center; position: fixed; bottom: 0; width: calc(100% - 2rem); background: #222; color: rgba(255,255,255,0.8);}
    #cookie-notice a {display: inline-block; cursor: pointer; margin-left: 0.5rem;}
    @media (max-width: 767px) {
        #cookie-notice span {display: block; padding-top: 3px; margin-bottom: 1rem;}
        #cookie-notice a {position: relative; bottom: 4px;}
    }
</style>
<div id="cookie-notice"><span>We would like to use third party cookies and scripts to improve the functionality of this website.</span><a id="cookie-notice-accept" class="btn btn-primary btn-sm">Approve</a><a href="/privacy-policy" class="btn btn-primary btn-sm">More info</a></div>
<script>
    function createCookie(name,value,days) {
        var expires = "";
        if (days) {
            var date = new Date();
            date.setTime(date.getTime() + (days*24*60*60*1000));
            expires = "; expires=" + date.toUTCString();
        }
        document.cookie = name + "=" + value + expires + "; path=/";
    }
    function readCookie(name) {
        var nameEQ = name + "=";
        var ca = document.cookie.split(';');
        for(var i=0;i < ca.length;i++) {
            var c = ca[i];
            while (c.charAt(0)==' ') c = c.substring(1,c.length);
            if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length,c.length);
        }
        return null;
    }
    function eraseCookie(name) {
        createCookie(name,"",-1);
    }

    if(readCookie('cookie-notice-dismissed')=='true') {
        console.log("Don't read further")
    } else {
        document.getElementById('cookie-notice').style.display = 'block';
    }
    document.getElementById('cookie-notice-accept').addEventListener("click",function() {
        createCookie('cookie-notice-dismissed','true',31);
        document.getElementById('cookie-notice').style.display = 'none';
        location.reload();
    });

</script>
</body>

</html>
